<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深度学习环境配置2——windows下的torch=1.2.0环境配置</title>
      <link href="/2025/02/06/windows-xia-de-torch-1.2.0-huan-jing-pei-zhi/"/>
      <url>/2025/02/06/windows-xia-de-torch-1.2.0-huan-jing-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h3 id="一、Anaconda安装"><a href="#一、Anaconda安装" class="headerlink" title="一、Anaconda安装"></a>一、Anaconda安装</h3><p><strong>Anaconda的安装主要是为了方便环境管理，可以同时在一个电脑上安装多种环境，不同环境放置不同框架：pytorch、tensorflow、keras可以在不同的环境下安装，只需要使用conda create –n创建新环境即可。</strong></p><h4 id="1、Anaconda的下载"><a href="#1、Anaconda的下载" class="headerlink" title="1、Anaconda的下载"></a>1、Anaconda的下载</h4><p>同学们可以选择安装新版Anaconda和旧版的Anaconda，安装步骤没有什么区别。</p><p><strong>旧版本anaconda的下载：</strong><br><strong>新版本的Anaconda没有VSCODE，如果大家为了安装VSCODE方便可以直接安装旧版的Anaconda，百度网盘连接如下。也可以装新版然后分开装VSCODE。</strong><br>链接: <a href="https://pan.baidu.com/s/12tW0Oad_Tqn7jNs8RNkvFA">https://pan.baidu.com/s/12tW0Oad_Tqn7jNs8RNkvFA</a> 提取码: i83n</p><p><strong>新版本anaconda的下载：</strong><br>如果想要安装最新的Anaconda，首先登录Anaconda的官网：<a href="https://www.anaconda.com/distribution/">https://www.anaconda.com/distribution/</a>。直接下载对应安装包就可以。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/ccda457f3e2c14fa490e5dee510e15ff.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/ccda457f3e2c14fa490e5dee510e15ff.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/79729ea1f6363089a7b848e2bbb41119.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/79729ea1f6363089a7b848e2bbb41119.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>一般是下载64位的，下载完成后打开。</p><h4 id="2、Anaconda的安装"><a href="#2、Anaconda的安装" class="headerlink" title="2、Anaconda的安装"></a>2、Anaconda的安装</h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b04e1b9b3c820f4212c77e872f721ff0.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b04e1b9b3c820f4212c77e872f721ff0.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>选择安装的位置，可以不安装在C盘。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/cf41baaf1550d7d707c56da7997bf467.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/cf41baaf1550d7d707c56da7997bf467.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>我选择了Add Anaconda to my PATH environment variable，这样会自动将anaconda装到系统的环境变量中，配置会更加方便一些。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/34a7c27d1eb9256186f88e6e610ffbd5.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/34a7c27d1eb9256186f88e6e610ffbd5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>等待安装完之后，Anaconda的安装就结束了。</p><h3 id="二、Cudnn和CUDA的下载和安装"><a href="#二、Cudnn和CUDA的下载和安装" class="headerlink" title="二、Cudnn和CUDA的下载和安装"></a>二、Cudnn和CUDA的下载和安装</h3><p><strong>我这里使用的是torch&#x3D;1.2.0，官方推荐的Cuda版本是10.0，因此会用到cuda10.0，与cuda10.0对应的cudnn是7.4.1。</strong></p><h4 id="1、Cudnn和CUDA的下载"><a href="#1、Cudnn和CUDA的下载" class="headerlink" title="1、Cudnn和CUDA的下载"></a>1、Cudnn和CUDA的下载</h4><p><strong>网盘下载：</strong><br>链接: <a href="https://pan.baidu.com/s/1znYSRDtLNFLufAuItOeoyQ">https://pan.baidu.com/s/1znYSRDtLNFLufAuItOeoyQ</a><br>提取码: 8ggr</p><p><strong>官网下载：</strong><br>cuda10.0官网的地址是：<br><a href="https://developer.nvidia.com/cuda-10.0-download-archive?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal">cuda10.0官网地址</a><br>cudnn官网的地址是：需要大家进去后寻找7.4.1.5。<br><a href="https://developer.nvidia.com/cudnn">cudnn官网地址</a></p><p>下载完之后得到这两个文件。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/829e732c6e6228e02d96c3b7bd115d9b.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/829e732c6e6228e02d96c3b7bd115d9b.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/8d273ca827020e1e079a78743bd000c5.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/8d273ca827020e1e079a78743bd000c5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p><h4 id="2、Cudnn和CUDA的安装"><a href="#2、Cudnn和CUDA的安装" class="headerlink" title="2、Cudnn和CUDA的安装"></a>2、Cudnn和CUDA的安装</h4><p>下载好之后可以打开exe文件进行安装。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/c1fa30103f2316fc350436a8815d54e0.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/c1fa30103f2316fc350436a8815d54e0.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>这里选择自定义。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/1bf16ce7629339969e0830a1630bd182.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/1bf16ce7629339969e0830a1630bd182.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="不"><br>然后直接点下一步就行了。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/d833eb6e1fa90ca9f621eb1072fe25aa.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/d833eb6e1fa90ca9f621eb1072fe25aa.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>安装完后在C盘这个位置可以找到根目录。<br>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0<br>然后大家把Cudnn的内容进行解压。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/0ae6fdd762c2435ef118a642b341d4ba.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/0ae6fdd762c2435ef118a642b341d4ba.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>把这里面的内容直接复制到C盘的根目录下就可以了。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/a88d013177374fcfecfec1e3865e3c5e.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/a88d013177374fcfecfec1e3865e3c5e.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p><h3 id="三、配置torch环境"><a href="#三、配置torch环境" class="headerlink" title="三、配置torch环境"></a>三、配置torch环境</h3><h4 id="1、pytorch环境的创建与激活"><a href="#1、pytorch环境的创建与激活" class="headerlink" title="1、pytorch环境的创建与激活"></a>1、pytorch环境的创建与激活</h4><p>Win+R启动cmd，在命令提示符内输入以下命令：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create –n pytorch python=3.6</span><br></pre></td></tr></table></figure><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate pytorch</span><br></pre></td></tr></table></figure><p>这里一共存在两条指令：<br>前面一条指令用于创建一个名为pytorch的环境，该环境的python版本为3.6。<br>后面一条指令用于激活一个名为pytorch的环境。</p><h4 id="2、pytorch库的安装"><a href="#2、pytorch库的安装" class="headerlink" title="2、pytorch库的安装"></a>2、pytorch库的安装</h4><p>由于我们所有的操作都要在对应环境中进行，所以在进行库的安装前需要先激活环境。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">activate pytorch </span><br></pre></td></tr></table></figure><p>此时cmd窗口的样子为：<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/e67dbf5cfc4f4125fedbffcb3bd85b77.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/e67dbf5cfc4f4125fedbffcb3bd85b77.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p><h5 id="a、官方推荐安装方法（推荐）"><a href="#a、官方推荐安装方法（推荐）" class="headerlink" title="a、官方推荐安装方法（推荐）"></a>a、官方推荐安装方法（推荐）</h5><p>打开pytorch的官方安装方法：<br><a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a><br>官网推荐的安装代码如下，我使用的是Cuda10的版本，不太懂为什么要写3个&#x3D;才能正确定位，两个&#x3D;会定位到cuda92的whl：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># CUDA 10.0</span><br><span class="line">pip install torch===1.2.0 torchvision===0.4.0 -f https://download.pytorch.org/whl/torch_stable.html</span><br></pre></td></tr></table></figure><p>这是pytorch官方提供的指令，用于安装torch和torchvision。</p><h5 id="b、先下载whl后安装"><a href="#b、先下载whl后安装" class="headerlink" title="b、先下载whl后安装"></a>b、先下载whl后安装</h5><p>需要注意的是，直接这样安装似乎特别慢，因此我们可以进入如下网址:<br><a href="https://download.pytorch.org/whl/torch_stable.html">https://download.pytorch.org/whl/torch_stable.html</a><br>找到自己需要的轮子下载。下载的时候使用迅雷下载就行了，速度还是比较快的！<br><img src="https://i-blog.csdnimg.cn/blog_migrate/08b8a756b9d7d214ce81f10bb5b73758.png#pic_center" class="lazyload placeholder" data-srcset="https://i-blog.csdnimg.cn/blog_migrate/08b8a756b9d7d214ce81f10bb5b73758.png#pic_center" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"  /><br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/737ffc86979d1e7ceda0d98b5ddcef41.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/737ffc86979d1e7ceda0d98b5ddcef41.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>下载完成后找到安装路径：<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/1eae8e7fae0ea98cc5559e6287059451.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/1eae8e7fae0ea98cc5559e6287059451.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>在cmd定位过来后利用文件全名进行安装就行了！<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/32c32f513e9be037243f885cd6f4ef11.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/32c32f513e9be037243f885cd6f4ef11.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>这里我也传一个百度网盘的版本。<br>链接: <a href="https://pan.baidu.com/s/14-QVk7Kb_CVwaVZxVPIgtw">https://pan.baidu.com/s/14-QVk7Kb_CVwaVZxVPIgtw</a><br>提取码: rg2e<br><strong>全部安装完成之后重启电脑。</strong></p><h4 id="3、其它依赖库的安装"><a href="#3、其它依赖库的安装" class="headerlink" title="3、其它依赖库的安装"></a>3、其它依赖库的安装</h4><p>但如果想要跑深度学习模型，还有一些其它的依赖库需要安装。具体如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scipy==1.2.1</span><br><span class="line">numpy==1.17.0</span><br><span class="line">matplotlib==3.1.2</span><br><span class="line">opencv_python==4.1.2.30</span><br><span class="line">torch==1.2.0</span><br><span class="line">torchvision==0.4.0</span><br><span class="line">tqdm==4.60.0</span><br><span class="line">Pillow==8.2.0</span><br><span class="line">h5py==2.10.0</span><br></pre></td></tr></table></figure><p>如果想要更便捷的安装可以在桌面或者其它地方创建一个requirements.txt文件，复制上述内容到txt文件中。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/7f76e6ad79f6bed1e2f4676b627354d3.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/7f76e6ad79f6bed1e2f4676b627354d3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>使用如下指令安装即可。<strong>下述指令中，requirements.txt前方的路径是我将文件放在桌面的路径，各位同学根据自己的电脑修改。</strong></p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install -r C:\Users\33232\Desktop\requirements.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="4、安装较慢请注意换源"><a href="#4、安装较慢请注意换源" class="headerlink" title="4、安装较慢请注意换源"></a>4、安装较慢请注意换源</h4><p>需要注意的是，如果在pip中下载安装比较慢可以换个源，可以到用户文件夹下，创建一个pip文件夹，然后在pip文件夹里创建一个txt文件。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/28006284902c6a57318e718daccee1a8.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/28006284902c6a57318e718daccee1a8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>修改txt文件的内容，并且把后缀改成ini</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = http://pypi.mirrors.ustc.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">use-mirrors =true</span><br><span class="line">mirrors =http://pypi.mirrors.ustc.edu.cn/simple/</span><br><span class="line">trusted-host =pypi.mirrors.ustc.edu.cn</span><br></pre></td></tr></table></figure><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/783a72953baad1fd9de83303701cbaf8.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/783a72953baad1fd9de83303701cbaf8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/8bd41332dee625e1c6e182608acb9a29.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/8bd41332dee625e1c6e182608acb9a29.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br><strong>全部安装完成之后重启电脑。</strong></p><h3 id="四、安装VSCODE"><a href="#四、安装VSCODE" class="headerlink" title="四、安装VSCODE"></a>四、安装<a href="https://so.csdn.net/so/search?q=VSCODE&spm=1001.2101.3001.7020">VSCODE</a></h3><p><strong>我个人喜欢VSCODE，所以就安装它啦。其它的编辑软件也可以，个人喜好罢了。</strong></p><h4 id="1、下载安装包安装（推荐）"><a href="#1、下载安装包安装（推荐）" class="headerlink" title="1、下载安装包安装（推荐）"></a>1、下载安装包安装（推荐）</h4><p><strong>最新版本的Anaconda没有VSCODE因此可以直接百度VSCODE进行安装。</strong></p><h5 id="a、VSCODE的下载"><a href="#a、VSCODE的下载" class="headerlink" title="a、VSCODE的下载"></a>a、VSCODE的下载</h5><p>直接加载VSCODE的官网<a href="https://code.visualstudio.com/">https://code.visualstudio.com/</a>，点击Download for Windows即可下载。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/f69abbceb271a9dc5d12142e76df4ebc.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/f69abbceb271a9dc5d12142e76df4ebc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p><h5 id="b、VSCODE的安装"><a href="#b、VSCODE的安装" class="headerlink" title="b、VSCODE的安装"></a>b、VSCODE的安装</h5><p>首先同意协议，点一下步。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/a80d57bcc63ffc394fb5b59aed099347.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/a80d57bcc63ffc394fb5b59aed099347.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>其他里面的几个勾要打起来，因为这样就可以右键文件夹用VSCODE打开，非常方便。下一步。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4156c82700455d0ab65ea5bb8f68eeb3.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4156c82700455d0ab65ea5bb8f68eeb3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>继续下一步安装即可。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/6523e522b685fc8512cacaedfb1934d8.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/6523e522b685fc8512cacaedfb1934d8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p><p><strong>安装完成后在左下角更改自己的环境就行了。</strong><br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4a6e8c3ce2dec68836338fdcc57a0dc1.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4a6e8c3ce2dec68836338fdcc57a0dc1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p><h4 id="2、anaconda上安装"><a href="#2、anaconda上安装" class="headerlink" title="2、anaconda上安装"></a>2、anaconda上安装</h4><p>打开anaconda，切换环境。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/361dd496e006335bd418e8b03e91354e.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/361dd496e006335bd418e8b03e91354e.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"><br>安装VSCODE，安装完就可以launch一下了，之后就可以把VScode固定到任务栏上，方便打开。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/f781c276062dded3ab0d4c9f37aef3bf.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/f781c276062dded3ab0d4c9f37aef3bf.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> CUDA </tag>
            
            <tag> cudnn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vscode配置latex环境</title>
      <link href="/2024/12/29/visual-studio-code/"/>
      <url>/2024/12/29/visual-studio-code/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>LaTeX</strong> 作为一种强大的排版系统，对于理工科，特别是公式比较多的数学专业（秃头专业），其重要性自不必多说，不在本文探讨范围之内。</p><p>而选择一个比较好的编译器是很重要的，至少对笔者而言是如此。笔者前期使用的是<strong>TeXstudio</strong>进行文档的编译的，但是其编译速度比较慢，并且页面不是很美观。最让人头疼的是，当公式比较长的时候，使用的括号就比较多，但<strong>Texstudio</strong>的代码高亮功能实在是…（它对于括号根本就没有高亮，头秃）</p><p>而<strong>Visual Studio Code</strong>呢？话不多说，直接上图！<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/5b90636b6875472ff796fe988e98826e.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/5b90636b6875472ff796fe988e98826e.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="展示图"></p><p>可以看到，它不仅能够对代码高亮，不同级别括号用不同颜色标注了，颜值也很高。且 vscode 最突出的特点就是其强大的插件功能，每个使用者都能够根据自己的需求和想法下载相应的插件，从而将之配置为高度个性化的编辑器。可以这么说，每个使用者的 vscode 都不一样，为其专属定制编辑器。</p><p>笔者配置了好久，找了很多资料，很多博主也只是贴上了配置代码，没有详细的介绍说明。为了让更多人能够有一个比较清晰的了解，以此可以随时对自己的配置代码进行更改，故笔者写下了此文。希望能够对大家有所帮助。</p><p>注 1： 本文使用图片均为笔者自身编辑器截图或笔者朋友的编辑器截图（经过对方同意），且所有引用在文中或文末注明了来源，其余均为原创内容（代码不算哈哈哈）。</p><p>注 2： 若您的 vscode 页面和笔者所用图片中展示的页面有略微不同，均为笔者所安装的其余插件以及其余设置所致，并不影响本文中所说的所有配置，您无需担心，只需按照图片中所指向图标进行配置即可。</p><p>注 3： 文末有完整的个人配置代码（有的地方需要更改路径，有具体说明）。</p><h2 id="1-TeX-Live-下载与安装"><a href="#1-TeX-Live-下载与安装" class="headerlink" title="1 TeX Live 下载与安装"></a>1 TeX Live 下载与安装</h2><p>笔者选用的 Tex 系统是 TeX Live ，如果您想了解 TeX Live 和 MiKTeX 的区别，可以查看此篇文章：<a href="https://www.cnblogs.com/liuliang1999/p/12656706.html">https://www.cnblogs.com/liuliang1999/p/12656706.html</a></p><p>接下来是 TeX Live 的<strong>下载与安装说明</strong>：</p><p>① 通过网址 ：<a href="http://tug.org/texlive/acquire-iso.html">http://tug.org/texlive/acquire-iso.html</a> 进入 ISO 下载页面，点击图示红框圈画位置进入随机的镜像网站。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b238c6ecae7799a007459ab0cacddfdc.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b238c6ecae7799a007459ab0cacddfdc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="下载网址"><br>② 可以看到的是，笔者进入了清华大学镜像网站，点击红框圈画链接进行 TeX Live 下载。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4cea74b28cf59bd59bd28cb03bdcb6e4.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4cea74b28cf59bd59bd28cb03bdcb6e4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="下载"></p><p>③ 如果<strong>下载速度过慢</strong>，可以返回前一页面，进行重新点击，随机进入另一镜像网站进行下载尝试，直到下载速度在您的可接受范围内即可。或者在前一页面，点击 <strong>“mirror list”</strong> 进入镜像列表</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/2a9a2b2fa4447587774d4f2f4eb1c9fb.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/2a9a2b2fa4447587774d4f2f4eb1c9fb.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="mirror list"></p><p>然后手动选择某一镜像网站进行下载：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/45f4adf32411091223ef279f96fda7ed.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/45f4adf32411091223ef279f96fda7ed.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="镜像列表选择"></p><p>④ 找到下载好的压缩包，右键，在打开方式中选择**“Windows 资源管理器”**打开</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/db2bbda5fb583717e095af7edf5465a6.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/db2bbda5fb583717e095af7edf5465a6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="资源管理器打开"></p><p>⑤ 找到 <strong>“install-tl-windows”</strong> 文件，为了后面不必要的麻烦，右键<strong>以管理员身份运行</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b666c4f9426f2fdf0a4a69bc86413ada.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b666c4f9426f2fdf0a4a69bc86413ada.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="以管理员身份运行"></p><p>⑥ 会先出现下图，无需理会，等会儿会消失</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/94aa279e1d0f6a59c34d95f4e85e0666.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/94aa279e1d0f6a59c34d95f4e85e0666.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="出现狮子"></p><p>⑦ **基本更改：**出现下图后，需要进行路径的更改；由于 TeX Live 自带的 TeXworks 不怎么好用，并且此文主要将 vscode 作为 LaTeX 的编辑器，故而取消 <strong>安装 TeXworks 前端</strong>的选项，再点击安装</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/5382a34df2373e3c3febc4172ad4af1d.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/5382a34df2373e3c3febc4172ad4af1d.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="修改路径"></p><p>⑧ <strong>个性化安装：</strong> 如果您需要个性化程度高的话，那么可以点击上图左下角的 <strong>Advancde</strong> ，根据您的需要进行相应的更改，但<strong>建议</strong>在不明白各个选项的作用时，不要对其进行修改，以免后期使用产生奇怪的问题。要注意的是，<strong>Adjust searchpath</strong> 这个选项一定要选中，将之添加到环境变量，否则后期手动添加比较麻烦；<br>而对于我们大部分人来说，只需要更改下图框选出的部分即可，也就是上图所完成的功能，再点击<strong>安装</strong>即可</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/64e11c5a3bfce6dae1620833aa528df6.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/64e11c5a3bfce6dae1620833aa528df6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="advanced"></p><p>⑨ **进行安装：**接着就会出现下图，具体的安装指标已在下图标明，可根据其数字来判断安装所需时间。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/22a9567ff88b850c6de3365fd1bd570e.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/22a9567ff88b850c6de3365fd1bd570e.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="安装ing"></p><p>当上面标示的时间安装完之后，会出现一些配置文件的安装运行写入，进行等待即可，几分钟左右：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4bd5a634521b8a18328976fa6884d688.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4bd5a634521b8a18328976fa6884d688.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="安装后续"></p><p>当出现下图所示弹窗时，说明安装完毕，点击关闭即可。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/dd26e23808c26c27614803e4fbca04ca.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/dd26e23808c26c27614803e4fbca04ca.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="欢迎进入"></p><p>⑩ <strong>检查安装是否正常：</strong> 按win + R 打开<strong>运行</strong>，输入<code>cmd</code>，打开命令行窗口；然后输入命令<code>xelatex -v</code> ，如下图</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4042a6e9ec2aa56e6b1442fa1d4c96a0.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/4042a6e9ec2aa56e6b1442fa1d4c96a0.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="安装检查"></p><p>如上图所示，若输出了一些版本信息，则安装正常。</p><h2 id="2-vscode下载与安装"><a href="#2-vscode下载与安装" class="headerlink" title="2 vscode下载与安装"></a>2 vscode下载与安装</h2><p>官网下载： <a href="https://code.visualstudio.com/">Click here to download Visual Studio Code</a>.</p><p>点进去之后就可以进行下载了。具体安装过程与常见的软件安装过程一致，这里就不作赘述。笔者只对几个要点进行提及：</p><p>① 记得<strong>修改安装路径</strong></p><p>② 根据个人想法可以选择是否在开始菜单文件夹创建 vscode 的快捷方式</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b52103381640e671ae6421fd329a600e.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b52103381640e671ae6421fd329a600e.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p><p>③ 一定要选上”添加到PATH”这个选项，能省很多麻烦。其余如图所示，自行选择。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/c721d489a01c6fde012b9777eaae64ea.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/c721d489a01c6fde012b9777eaae64ea.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="在这里插入图片描述"></p><p>安装好之后，打开 vscode，应如下图页面所示：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/56e8910ef21f541e6a699bb00f0a4f57.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/56e8910ef21f541e6a699bb00f0a4f57.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="启动页面"></p><h2 id="3-中文语言环境配置"><a href="#3-中文语言环境配置" class="headerlink" title="3 中文语言环境配置"></a>3 中文语言环境配置</h2><p>vscode的中文环境需要下载插件来进行支持。如下图所示：</p><p>① 点击拓展图标，打开拓展；</p><p>② 输入”Chinese”，选择第一个Chinese (Simplified) Language Pack for Visual Studio Code插件；</p><p>③ 点击”install”进行安装，等待安装完成；</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/e74e7680283789d9bec131c5f69234d7.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/e74e7680283789d9bec131c5f69234d7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="下载中文插件"></p><p>④ 点击页面右下角跳出窗口中的”Restart now”，进行 vscode 重启。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/02a0f5f7d9a509bab220dfc4fd2b26b9.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/02a0f5f7d9a509bab220dfc4fd2b26b9.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="vscode重启"></p><p>⑤ 完成中文环境配置，显示如下：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/57e75ca8310629f3fc4e2daf27cc8610.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/57e75ca8310629f3fc4e2daf27cc8610.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="中文环境启动页面"></p><h2 id="4-LaTeX的支持插件-LaTeX-Workshop安装"><a href="#4-LaTeX的支持插件-LaTeX-Workshop安装" class="headerlink" title="4 LaTeX的支持插件 LaTeX Workshop安装"></a>4 LaTeX的支持插件 LaTeX Workshop安装</h2><p>① 点击拓展图标，打开拓展；</p><p>② 输入”latex workshop”，选择第一个LaTeX Workshop插件；</p><p>③ 点击”install”进行安装，等待安装完成；</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/254d1f24e8a90b349a77958b5c192d4d.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/254d1f24e8a90b349a77958b5c192d4d.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="latex workshop安装"></p><p>④ 若在安装完该插件之后在 vscode 页面右下角跳出如下弹窗，无需在意，只是提醒该插件已经更新到了8.11.1版本。若您想要了解新版本增加的功能，可以点击”Change log”进行查看；若不想了解，点击 “Disable this message” 即可。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/c96cdbe7e01da3ff326da9df306918d1.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/c96cdbe7e01da3ff326da9df306918d1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="弹窗"></p><h2 id="5-打开LaTeX环境设置页面"><a href="#5-打开LaTeX环境设置页面" class="headerlink" title="5 打开LaTeX环境设置页面"></a>5 打开LaTeX环境设置页面</h2><p>① 点击设置图标</p><p>② 点击设置</p><p>③ 转到 UI 设置页面</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/2ee6e759bdd67de85e8380d332db1a1a.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/2ee6e759bdd67de85e8380d332db1a1a.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="打开设置"></p><p>④ 点击下图 1 处打开 json 文件，进入代码设置页面</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b8d742a52940e90d31777f7efd9943f1.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/b8d742a52940e90d31777f7efd9943f1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="json设置"></p><p>注 4 ： UI 设置页面和代码设置页面均为设置页面，其功能是一样的。不同的是，UI 设置页面交互能力较强，但一些设置需要去寻找，比较麻烦；而代码设置页面虽然相对 UI 而言不那么直观，但却可以对自己想要的功能直接进行代码编写，且代码设置可以直接克隆别人的代码到自己的编辑器中，从而直接完成相应设置，比较便捷。</p><p>注 5 ： 可以直接按Ctrl + ，进入设置页面。</p><h2 id="6-LaTeX环境的代码配置"><a href="#6-LaTeX环境的代码配置" class="headerlink" title="6 LaTeX环境的代码配置"></a>6 LaTeX环境的代码配置</h2><h3 id="6-1-LaTeX配置代码展示"><a href="#6-1-LaTeX配置代码展示" class="headerlink" title="6.1 LaTeX配置代码展示"></a>6.1 LaTeX配置代码展示</h3><p>先给出效果图：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/43a5acbf6be4a170f4a9dbdbbcff2209.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/43a5acbf6be4a170f4a9dbdbbcff2209.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="LaTeX代码配置"></p><p>LaTeX 配置代码如下（不包含外部 pdf 查看器设置）：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;latex-workshop.latex.autoBuild.run&quot;: &quot;never&quot;,</span><br><span class="line">    &quot;latex-workshop.showContextMenu&quot;: true,</span><br><span class="line">    &quot;latex-workshop.intellisense.package.enabled&quot;: true,</span><br><span class="line">    &quot;latex-workshop.message.error.show&quot;: false,</span><br><span class="line">    &quot;latex-workshop.message.warning.show&quot;: false,</span><br><span class="line">    &quot;latex-workshop.latex.tools&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;xelatex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;xelatex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;pdflatex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;pdflatex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;latexmk&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;latexmk&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;-pdf&quot;,</span><br><span class="line">                &quot;-outdir=%OUTDIR%&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;bibtex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;bibtex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;latex-workshop.latex.recipes&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;XeLaTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;xelatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;PDFLaTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;pdflatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;BibTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;bibtex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;LaTeXmk&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;latexmk&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;xelatex -&gt; bibtex -&gt; xelatex*2&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;xelatex&quot;,</span><br><span class="line">                &quot;bibtex&quot;,</span><br><span class="line">                &quot;xelatex&quot;,</span><br><span class="line">                &quot;xelatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;pdflatex -&gt; bibtex -&gt; pdflatex*2&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;pdflatex&quot;,</span><br><span class="line">                &quot;bibtex&quot;,</span><br><span class="line">                &quot;pdflatex&quot;,</span><br><span class="line">                &quot;pdflatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">    ],</span><br><span class="line">    &quot;latex-workshop.latex.clean.fileTypes&quot;: [</span><br><span class="line">        &quot;*.aux&quot;,</span><br><span class="line">        &quot;*.bbl&quot;,</span><br><span class="line">        &quot;*.blg&quot;,</span><br><span class="line">        &quot;*.idx&quot;,</span><br><span class="line">        &quot;*.ind&quot;,</span><br><span class="line">        &quot;*.lof&quot;,</span><br><span class="line">        &quot;*.lot&quot;,</span><br><span class="line">        &quot;*.out&quot;,</span><br><span class="line">        &quot;*.toc&quot;,</span><br><span class="line">        &quot;*.acn&quot;,</span><br><span class="line">        &quot;*.acr&quot;,</span><br><span class="line">        &quot;*.alg&quot;,</span><br><span class="line">        &quot;*.glg&quot;,</span><br><span class="line">        &quot;*.glo&quot;,</span><br><span class="line">        &quot;*.gls&quot;,</span><br><span class="line">        &quot;*.ist&quot;,</span><br><span class="line">        &quot;*.fls&quot;,</span><br><span class="line">        &quot;*.log&quot;,</span><br><span class="line">        &quot;*.fdb_latexmk&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;latex-workshop.latex.autoClean.run&quot;: &quot;onFailed&quot;,</span><br><span class="line">    &quot;latex-workshop.latex.recipe.default&quot;: &quot;lastUsed&quot;,</span><br><span class="line">    &quot;latex-workshop.view.pdf.internal.synctex.keybinding&quot;: &quot;double-click&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注 6 ： 若您不想要配置外部查看器以及了解内部查看和外部查看之间切换操作，可以直接复制上述代码至 json 文件中，即可完成 LaTeX 的配置，从而可以对 LaTeX 代码进行编译。</p><p>注 7 ： 根据 json 文件编写规则，每个代码语句（除了代码块儿最后一句）都需要加上英文状态下的<code>,</code>，否则就会报错；而每个代码块儿的最后一句是不需要加上<code>,</code>的。从上文整个代码块儿可以看出此规则。</p><p>如果您日后需要在上述代码之后再添加其他代码，请记得在最后一句</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.internal.synctex.keybinding&quot;: &quot;double-click&quot;</span><br></pre></td></tr></table></figure><p>后添加上<code>,</code>，即变为</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.internal.synctex.keybinding&quot;: &quot;double-click&quot;,</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>其中的<code>......</code>为您添加的其余代码。</p><p><strong>切记！</strong></p><h3 id="6-2-LaTeX配置代码解读"><a href="#6-2-LaTeX配置代码解读" class="headerlink" title="6.2 LaTeX配置代码解读"></a>6.2 LaTeX配置代码解读</h3><p>如果您对此不感兴趣，可以跳过该小节。下面进行代码<strong>注释解读</strong>：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.latex.autoBuild.run&quot;: &quot;never&quot;</span><br></pre></td></tr></table></figure><p>设置何时使用默认的(第一个)编译链自动构建 LaTeX 项目，即什么时候自动进行代码的编译。有三个选项：</p><ol><li><strong>onFileChange</strong>：在检测任何依赖项中的文件更改(甚至被其他应用程序修改)时构建项目，即当检测到代码被更改时就自动编译tex文件；</li><li><strong>onSave</strong> : 当代码被保存时自动编译文件；</li><li><strong>never</strong>: 从不自动编译，即需编写者手动编译文档</li></ol><p>此项笔者设置为<strong>never</strong>。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.showContextMenu&quot;: true</span><br></pre></td></tr></table></figure><p>启用上下文LaTeX菜单。此菜单默认状态下停用，即变量设置为<strong>false</strong>，因为它可以通过新的 LaTeX 标记使用（新的 LaTeX 标记能够编译文档，将在下文提及）。只需将此变量设置为<strong>true</strong>即可恢复菜单。即此命令设置是否将编译文档的选项出现在鼠标右键的菜单中。</p><p>下图展示两者区别，左边为设置<strong>false</strong>情况，右边为设置<strong>true</strong>情况。可以看到的是，设置为<strong>true</strong>时，菜单中多了两个选项，其中多出来的第一个选项为进行tex文件的编译，而第二个选项为进行正向同步，即从代码定位到编译出来的 pdf 文件相应位置，下文会进行提及。<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/80cef33dcac33ac0e86c82c101461f3b.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/80cef33dcac33ac0e86c82c101461f3b.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="无"><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/1bfedcbe76bb0f0ee3a27db3f6e4d538.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/1bfedcbe76bb0f0ee3a27db3f6e4d538.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="有"><br>笔者觉得菜单多了此选项较方便，故此项笔者设置为<strong>true</strong></p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.intellisense.package.enabled&quot;: true</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>设置为<strong>true</strong>，则该拓展能够从使用的宏包中自动提取命令和环境，从而补全正在编写的代码。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.message.error.show&quot;  : false,</span><br><span class="line">&quot;latex-workshop.message.warning.show&quot;: false</span><br></pre></td></tr></table></figure><p>这两个命令是设置当文档编译错误时是否弹出显示出错和警告的弹窗。因为这些错误和警告信息能够从终端中获取，且弹窗弹出比较烦人，故而笔者设置均设置为<strong>false</strong>。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.latex.tools&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;xelatex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;xelatex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;pdflatex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;pdflatex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;latexmk&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;latexmk&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;-pdf&quot;,</span><br><span class="line">                &quot;-outdir=%OUTDIR%&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;bibtex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;bibtex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p>这些代码是定义在下文 recipes 编译链中被使用的编译命令，此处为默认配置，不需要进行更改。其中的<code>name</code>为这些命令的标签，用作下文 recipes 的引用；而<code>command</code>为在该拓展中的编译方式。</p><p>可以更改的代码为，将编译方式: pdflatex 、 xelatex 和 latexmk 中的<code>%DOCFILE</code>更改为<code>%DOC</code>。<code>%DOCFILE</code>表明编译器访问没有扩展名的根文件名，而<code>%DOC</code>表明编译器访问的是没有扩展名的根文件完整路径。这就意味着，使用<code>%DOCFILE</code>可以将文件所在路径设置为中文，但笔者不建议这么做，因为毕竟涉及到代码，当其余编译器引用时该 tex 文件仍需要根文件完整路径，且需要为英文路径。笔者此处设置为<code>%DOCFILE</code>仅是因为之前使用 TeXstudio，导致路径已经是中文了。</p><p>更多详情可以访问 github 中 LaTeX-Workshop 的 Wiki: <a href="https://github.com/James-Yu/LaTeX-Workshop/wiki/Compile#placeholders">Click here for more details about this.</a></p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.latex.recipes&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;XeLaTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;xelatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;PDFLaTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;pdflatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;BibTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;bibtex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;LaTeXmk&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;latexmk&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;xelatex -&gt; bibtex -&gt; xelatex*2&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;xelatex&quot;,</span><br><span class="line">                &quot;bibtex&quot;,</span><br><span class="line">                &quot;xelatex&quot;,</span><br><span class="line">                &quot;xelatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;pdflatex -&gt; bibtex -&gt; pdflatex*2&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;pdflatex&quot;,</span><br><span class="line">                &quot;bibtex&quot;,</span><br><span class="line">                &quot;pdflatex&quot;,</span><br><span class="line">                &quot;pdflatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p>此串代码是对编译链进行定义，其中<code>name</code>是标签，也就是出现在工具栏中的链名称；<code>tool</code>是<code>name</code>标签所对应的编译顺序，其内部编译命令来自上文<code>latex-workshop.latex.recipes</code>中内容。</p><p>定义完成后，能够在 vscode 编译器中能够看到的编译顺序，具体看下图：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/bfcdea57459bf5f1687f3a4c548e868a.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/bfcdea57459bf5f1687f3a4c548e868a.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="编译链"></p><p>可以看到的是，在编译链中定义的命令出现在了vscode右侧的工具栏中。</p><p>注 8 ： <strong>PDFLaTeX</strong> 编译模式与 <strong>XeLaTeX</strong> 区别如下：</p><blockquote><ol><li><p>PDFLaTeX 使用的是TeX的标准字体，所以生成PDF时，会将所有的非 TeX 标准字体进行替换，其生成的 PDF 文件默认嵌入所有字体；而使用 XeLaTeX 编译，如果说论文中有很多图片或者其他元素没有嵌入字体的话，生成的 PDF<br>文件也会有些字体没有嵌入。</p></li><li><p>XeLaTeX 对应的 XeTeX 对字体的支持更好，允许用户使用操作系统字体来代替 TeX 的标准字体，而且对非拉丁字体的支持更好。</p></li><li><p>PDFLaTeX 进行编译的速度比 XeLaTeX 速度快。</p></li></ol></blockquote><p>注 9 ： 编译链的存在是为了更方便编译，因为如果涉及到**.bib**文件，就需要进行多次不同命令的转换编译，比较麻烦，而编译链就解决了这个问题。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.latex.clean.fileTypes&quot;: [</span><br><span class="line">        //&quot;*.aux&quot;,</span><br><span class="line">       // &quot;*.bbl&quot;,</span><br><span class="line">        &quot;*.blg&quot;,</span><br><span class="line">        &quot;*.idx&quot;,</span><br><span class="line">        &quot;*.ind&quot;,</span><br><span class="line">        &quot;*.lof&quot;,</span><br><span class="line">        &quot;*.lot&quot;,</span><br><span class="line">        &quot;*.out&quot;,</span><br><span class="line">        &quot;*.toc&quot;,</span><br><span class="line">        &quot;*.acn&quot;,</span><br><span class="line">        &quot;*.acr&quot;,</span><br><span class="line">        &quot;*.alg&quot;,</span><br><span class="line">        &quot;*.glg&quot;,</span><br><span class="line">        &quot;*.glo&quot;,</span><br><span class="line">        &quot;*.gls&quot;,</span><br><span class="line">        &quot;*.ist&quot;,</span><br><span class="line">        &quot;*.fls&quot;,</span><br><span class="line">        &quot;*.log&quot;,</span><br><span class="line">        &quot;*.fdb_latexmk&quot;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p>这串命令则是设置编译完成后要清除掉的辅助文件类型，若无特殊需求，无需进行更改。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.latex.autoClean.run&quot;: &quot;onFailed&quot;</span><br></pre></td></tr></table></figure><p>这条命令是设置什么时候对上文设置的辅助文件进行清除。其变量有：</p><ol><li><strong>onBuilt</strong> : 无论是否编译成功，都选择清除辅助文件；</li><li><strong>onFailed</strong> : 当编译失败时，清除辅助文件；</li><li><strong>never</strong> : 无论何时，都不清除辅助文件。</li></ol><p>由于 tex 文档编译有时需要用到辅助文件，比如编译目录和编译参考文献时，如果使用<code>onBuilt</code>命令，则会导致编译不出完整结果甚至编译失败；</p><p>而有时候将 tex 文件修改后进行编译时，可能会导致 pdf 文件没有正常更新的情况，这个时候可能就是由于辅助文件没有进行及时更新的缘故，需要清除辅助文件了，而<code>never</code>命令做不到这一点；</p><p>故而笔者使用了<code>onFailed</code>，同时解决了上述两个问题。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.latex.recipe.default&quot;: &quot;lastUsed&quot;</span><br></pre></td></tr></table></figure><p>该命令的作用为设置 vscode 编译 tex 文档时的默认编译链。有两个变量：</p><ol><li><strong>first</strong> : 使用<code>latex-workshop.latex.recipes</code>中的第一条编译链，故而您可以根据自己的需要更改编译链顺序；</li><li><strong>lastUsed</strong> : 使用最近一次编译所用的编译链。</li></ol><p>笔者选择使用<strong>lastUsed</strong>。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.internal.synctex.keybinding&quot;: &quot;double-click&quot;</span><br></pre></td></tr></table></figure><p>用于反向同步（即从编译出的 pdf 文件指定位置跳转到 tex 文件中相应代码所在位置）的内部查看器的快捷键绑定。变量有两种：</p><ol><li><strong>ctrl-click</strong> ： 为默认选项，使用Ctrl&#x2F;cmd+鼠标左键单击</li><li><strong>double-click</strong> : 使用鼠标左键双击</li></ol><p>此处笔者使用的为<strong>double-click</strong>。</p><h2 id="7-tex文件编译"><a href="#7-tex文件编译" class="headerlink" title="7 tex文件编译"></a>7 tex文件编译</h2><h3 id="7-1-tex测试文件下载"><a href="#7-1-tex测试文件下载" class="headerlink" title="7.1 tex测试文件下载"></a>7.1 tex测试文件下载</h3><p>为了测试 vscode 功能是否比较完整，笔者编写了一份简单的 tex 文件，以此测试其是否支持中英文，能否编译目录，能否插入图片，能否进行引用，能否编译参考文献（编译bixtex文件）等功能。</p><p>测试所用的 tex 文件可以从 github 下载：<a href="https://github.com/Ali-loner/Ali-loner.github.io">Click here to download the LaTeX testfile for vscode</a></p><p><strong>下载步骤</strong>如图：<br><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/6aca9b730b7c4ee2946a88fbe6ac40ad.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/6aca9b730b7c4ee2946a88fbe6ac40ad.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="测试文件下载"><br>将之下载后，进行解压。</p><p>注 10 ： 若因网络原因无法连接到github导致无法下载，可以使用自己的tex文件进行测试，或者复制以下代码进行文档的简单编译测试，但其只能测试一部分功能：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">\documentclass[a4paper]&#123;article&#125;</span><br><span class="line">\usepackage[margin=1in]&#123;geometry&#125; % 设置边距，符合Word设定</span><br><span class="line">\usepackage&#123;ctex&#125;</span><br><span class="line">\usepackage&#123;lipsum&#125;</span><br><span class="line">\title&#123;\heiti\zihao&#123;2&#125; This is a test for vscode&#125;</span><br><span class="line">\author&#123;\songti Ali-loner&#125;</span><br><span class="line">\date&#123;2020.08.02&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\maketitle</span><br><span class="line">\begin&#123;abstract&#125;</span><br><span class="line">\lipsum[2]</span><br><span class="line">\end&#123;abstract&#125;</span><br><span class="line">\tableofcontents</span><br><span class="line">\section&#123;This is a section&#125;</span><br><span class="line">Hello world! 你好，世界 ！</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><h3 id="7-2-tex-测试文件编译"><a href="#7-2-tex-测试文件编译" class="headerlink" title="7.2 tex 测试文件编译"></a>7.2 tex 测试文件编译</h3><p><strong>① 打开测试文件所在文件夹</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/927b15521ea5f9c20d3ba6c426e098ba.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/927b15521ea5f9c20d3ba6c426e098ba.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="打开文件夹"></p><p><strong>② 点击选中 tex 文件</strong>，进行文件内容查看</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/6a28c240c45d77c6972a7e2fb6cd62a8.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/6a28c240c45d77c6972a7e2fb6cd62a8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="tex文件查看"></p><p><strong>③ 开始编译文件。</strong> 由于进行测试的文件中涉及参考文献的引用（<strong>.bib</strong>的编译），故而选择<code>xelatex -&gt; bibtex -&gt; xelatex*2</code>编译链。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/306b76bae450c39ddd5a7cea4074c84a.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/306b76bae450c39ddd5a7cea4074c84a.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="开始编译"></p><p>注 11 ： 为了更方便进行编译，可对其设置快捷键，设置快捷键步骤如下：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/24c26cd24b87c3f1e59568b8b8e8bb00.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/24c26cd24b87c3f1e59568b8b8e8bb00.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="快捷键绑定"></p><p>笔者将快捷键设置为Ctrl+Alt+R。</p><p><strong>选中tex文件的代码页面</strong>（若未选中，则无法进行编译），然后按下该快捷键，在编辑器页面上端进行编译链选择，如下图：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/cbaed92ca564f9dbbb4204e0d9c2fee7.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/cbaed92ca564f9dbbb4204e0d9c2fee7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="快捷键编译"></p><p><strong>④ 编译成功</strong></p><p>当发现页面下方出现 <strong>√</strong> 符号时，说明编译成功，相反，如果出现 <strong>×</strong> 符号，说明编译失败，就要找失败原因了。</p><p><strong>a.</strong> 左侧工具栏</p><p>当编译成功后，选中 tex 文件中任意的代码，以此来选中 tex 文件，然后进行图示操作。其中侧边栏所展现的就是上文提及的新的 LaTeX 标记。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/04f02e79054c25953a761251a72e8682.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/04f02e79054c25953a761251a72e8682.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="pdf查看"></p><p><strong>b.</strong> 快捷键</p><p>选中 tex 文件中任意的代码，然后按Ctrl+Alt+V，出现编译好的 pdf 页面。该快捷键为默认设置。若您想要更改，可以根据上文进行配置。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/518090c31940a4a61b55f75a31f7c923.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/518090c31940a4a61b55f75a31f7c923.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="编译成功"></p><p>注意到，现在编译的结果为内部查看器查看。</p><p><strong>⑤ 正向同步测试</strong>，即从代码定位到 pdf 页面相应位置。有以下三种方法：</p><p><strong>a.</strong> 使用侧边工具栏</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/20bc13379b5e1d69eecb53c98175e896.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/20bc13379b5e1d69eecb53c98175e896.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="正向同步1"></p><p><strong>b.</strong> 使用右键菜单</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/ac759bac5a92854811260f5ea5f56f0f.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/ac759bac5a92854811260f5ea5f56f0f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="正向同步2"><br><strong>c.</strong> 使用快捷键</p><p>选中需要跳转的代码所在行，按Ctrl+Alt+J，右侧就会跳转到相应行。这里的快捷键为默认设置，可自行通过上文方式设置为您想要的快捷键。</p><p><strong>⑥ 反向同步测试</strong>,即从 pdf 页面定位到代码相应位置</p><p>在编译生成的 pdf 上，选中想要跳转行，鼠标左键双击或ctrl+鼠标左键单击，跳转到对应代码。此处快捷键的选择为上文设置，若使用笔者的代码，则为鼠标左键双击。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/1bc30efe92862befcd35000da3b3eb93.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/1bc30efe92862befcd35000da3b3eb93.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="反向同步"></p><h2 id="8-SumatraPDF-安装设置（可选）"><a href="#8-SumatraPDF-安装设置（可选）" class="headerlink" title="8 SumatraPDF 安装设置（可选）"></a>8 SumatraPDF 安装设置（可选）</h2><p>您可自行选择是否需要设置此部分内容。</p><p>有的时候，由于想要看到 pdf 文件的完整展现效果，使用内置查看器已无法满足需求，这时可以使用外部查看器进行查看。</p><p>外部查看器的优势是能够看到 pdf 文件在查看器中的目录，可以实时进行跳转；且根据笔者使用来看，外部查看器展示出来的 pdf 默认会放大一些，使得字体变大，要更加让人舒服一些。</p><p>笔者选择 <strong>SumatraPDF</strong> 作为外部查看器，该软件的优点在于在具有 pdf 阅读功能的同时很轻量，安装包不到 10MB 大小，且支持双向同步功能。通过调整其与 vscode 的窗口位置，能够在拥有这些优势的同时，达到与内置 pdf 查看具有相同的效果。</p><h3 id="8-1-SumatraPDF下载与安装"><a href="#8-1-SumatraPDF下载与安装" class="headerlink" title="8.1 SumatraPDF下载与安装"></a>8.1 SumatraPDF下载与安装</h3><p>官网下载：<a href="https://www.sumatrapdfreader.org/download-free-pdf-viewer.html">Click here to download SumatraPDF</a></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/46ef16263fbbb2396ceb7029c1963a32.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/46ef16263fbbb2396ceb7029c1963a32.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="sumatraPDF"></p><p>其安装很简单，与通用软件安装过程一致，记得更改安装路径并记住，下文配置需要使用其路径。</p><h3 id="8-2-使用SumatraPDF查看的代码配置"><a href="#8-2-使用SumatraPDF查看的代码配置" class="headerlink" title="8.2 使用SumatraPDF查看的代码配置"></a>8.2 使用SumatraPDF查看的代码配置</h3><h4 id="8-2-1-代码展示"><a href="#8-2-1-代码展示" class="headerlink" title="8.2.1 代码展示"></a>8.2.1 代码展示</h4><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;latex-workshop.view.pdf.viewer&quot;: &quot;external&quot;,</span><br><span class="line">    &quot;latex-workshop.view.pdf.ref.viewer&quot;:&quot;auto&quot;,</span><br><span class="line">    &quot;latex-workshop.view.pdf.external.viewer.command&quot;: &quot;F:/SumatraPDF/SumatraPDF.exe&quot;, // 注意修改路径</span><br><span class="line">    &quot;latex-workshop.view.pdf.external.viewer.args&quot;: [</span><br><span class="line">        &quot;%PDF%&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;latex-workshop.view.pdf.external.synctex.command&quot;: &quot;F:/SumatraPDF/SumatraPDF.exe&quot;, // 注意修改路径</span><br><span class="line">    &quot;latex-workshop.view.pdf.external.synctex.args&quot;: [</span><br><span class="line">        &quot;-forward-search&quot;,</span><br><span class="line">        &quot;%TEX%&quot;,</span><br><span class="line">        &quot;%LINE%&quot;,</span><br><span class="line">        &quot;-reuse-instance&quot;,</span><br><span class="line">        &quot;-inverse-search&quot;,</span><br><span class="line">        &quot;code \&quot;F:/Microsoft VS Code/resources/app/out/cli.js\&quot; -r -g \&quot;%f:%l\&quot;&quot;, // 注意修改路径</span><br><span class="line">        &quot;%PDF%&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此代码仅为展示所用，让您进行查看，为下文解读之用。如需写入到 json 文件内，可直接完整复制文末笔者的个人配置到自己的编译器内。</p><h4 id="8-2-2-代码解读"><a href="#8-2-2-代码解读" class="headerlink" title="8.2.2 代码解读"></a>8.2.2 代码解读</h4><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.viewer&quot;: &quot;external&quot;</span><br></pre></td></tr></table></figure><p>设置默认的pdf查看器，有三种变量参数：</p><ol><li><strong>tab</strong> : 使用 vscode 内置 pdf 查看器；</li><li><strong>browser</strong> : 使用电脑默认浏览器进行 pdf 查看；</li><li><strong>external</strong> : 使用外部 pdf 查看器查看。</li></ol><p>此处选择 <strong>external</strong> 参数，使用外部查看器。</p><p>注 12 ： 此参数为下文进行pdf内部查看和外部查看进行切换的关键参数。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.ref.viewer&quot;:&quot;auto&quot;</span><br></pre></td></tr></table></figure><p>设置PDF查看器用于在 <strong>\ref</strong> 命令上的[View on PDF]链接，此命令作用于 <strong>\ref</strong> 引用查看。有三个参数变量：</p><ol><li><strong>auto</strong> : 由编辑器根据情况自动设置；</li><li><strong>tabOrBrowser</strong> : 使用vscode内置pdf查看器或使用电脑默认浏览器进行pdf查看；</li><li><strong>external</strong> : 使用外部pdf查看器查看。</li></ol><p>此处设置为<strong>auto</strong>。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.external.viewer.command&quot;: &quot;F:/SumatraPDF/SumatraPDF.exe&quot;// 注意修改路径</span><br></pre></td></tr></table></figure><p>使用外部查看器时要执行的命令，设置外部查看器启动文件<strong>SumatraPDF.exe</strong>文件所在位置，此处需要您根据自身情况进行路径更改，正常情况下只需更改磁盘盘符即可。</p><p><strong>请注意</strong>中间为 “ &#x2F; “ 而不是” \ “ ，不然会报错。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.external.viewer.args&quot;: [</span><br><span class="line">        &quot;%PDF%&quot;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p>此代码是设置使用外部查看器时，<code>latex-workshop.view.pdf.external.view .command</code>的参数。<code>%PDF%</code>是用于生成PDF文件的绝对路径的占位符。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.external.synctex.command&quot;: &quot;F:/SumatraPDF/SumatraPDF.exe&quot; // 注意修改路径</span><br></pre></td></tr></table></figure><p>此命令是将生成的辅助文件 <strong>.synctex.gz</strong> 转发到外部查看器时要执行的命令,设置其位置参数，您注意更改路径，此路径为 <strong>SumatraPDF.exe</strong> 文件路径。与上文相同。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&quot;latex-workshop.view.pdf.external.synctex.args&quot;: [</span><br><span class="line">        &quot;-forward-search&quot;,</span><br><span class="line">        &quot;%TEX%&quot;,</span><br><span class="line">        &quot;%LINE%&quot;,</span><br><span class="line">        &quot;-reuse-instance&quot;,</span><br><span class="line">        &quot;-inverse-search&quot;,</span><br><span class="line">        &quot;code \&quot;F:/Microsoft VS Code/resources/app/out/cli.js\&quot; -r -g \&quot;%f:%l\&quot;&quot;// 注意修改路径</span><br><span class="line">        &quot;%PDF%&quot;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p>设置当 <strong>.synctex.gz</strong> 文件同步到外部查看器时<code>latex-workshop.view.pdf.external.synctex</code>的参数。<code>%LINE%</code>是行号，<code>%PDF%</code>是生成PDF文件的绝对路径的占位符，<code>%TEX%</code>是当触发syncTeX被触发时，扩展名为 <strong>.tex</strong> 的 LaTeX 文件路径。</p><p>上面代码串中记得进行 <strong>Microsoft VS Code</strong> 路径修改，修改如下图:</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/43de3a7d084a4b2b2eae6a259ba24f33.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/43de3a7d084a4b2b2eae6a259ba24f33.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="路径修改"></p><h2 id="9-SumatraPDF-的使用"><a href="#9-SumatraPDF-的使用" class="headerlink" title="9 SumatraPDF 的使用"></a>9 SumatraPDF 的使用</h2><p>将完整代码复制到自己的 json 文件内后，即可使用 SumatraPDF作为自己的 pdf 外部查看器了。以下为具体操作：</p><p>① 点击编辑页面任意位置来选中 tex 文件；<br>② 按Ctrl+Alt+V，打开编译出的 pdf 文件；<br>③ 出现如下图页面。可以看到的是，原本内嵌输出的 pdf 变为了在 SumatraPDF 上查看，且侧面带有书签：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/e5003691bd206012a74ecddf6c7bfa82.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/e5003691bd206012a74ecddf6c7bfa82.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="sumatrapdf查看"></p><p>④ 为了出现和内嵌输出具有相同的效果，可以将 vscode 和 SumatraPDF 进行分屏，且根据需要关闭标签，如下图：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/57974febf6f2c77c5b9bb9e22235887d.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/57974febf6f2c77c5b9bb9e22235887d.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="分屏查看"></p><p>⑤ 且同样支持双向同步（正向同步和反向同步），其操作步骤与内嵌输出 pdf 时操作步骤相同，此处就不再赘述。查看效果图：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/6118b9cb1ea3e22d80a5a04edd5fb6a7.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/6118b9cb1ea3e22d80a5a04edd5fb6a7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="双向同步"></p><h2 id="10-pdf-内部查看与外部查看的切换"><a href="#10-pdf-内部查看与外部查看的切换" class="headerlink" title="10 pdf 内部查看与外部查看的切换"></a>10 pdf 内部查看与外部查看的切换</h2><p>以下展示由外部查看转为内部查看的操作，由内转外操作相同。</p><p>共有两种操作方式：<strong>UI界面设置</strong> 或 <strong>Json界面设置</strong> 。具体见下图：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/8fde188378a7f0d0d15e09941768c364.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/images/8fde188378a7f0d0d15e09941768c364.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="内外切换"></p><p>您可根据个人适应选择相应的方法。</p><h2 id="11-个人完整配置"><a href="#11-个人完整配置" class="headerlink" title="11 个人完整配置"></a>11 个人完整配置</h2><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> //------------------------------LaTeX 配置----------------------------------</span><br><span class="line">    // 设置是否自动编译</span><br><span class="line">    &quot;latex-workshop.latex.autoBuild.run&quot;:&quot;never&quot;,</span><br><span class="line">    //右键菜单</span><br><span class="line">    &quot;latex-workshop.showContextMenu&quot;:true,</span><br><span class="line">    //从使用的包中自动补全命令和环境</span><br><span class="line">    &quot;latex-workshop.intellisense.package.enabled&quot;: true,</span><br><span class="line">    //编译出错时设置是否弹出气泡设置</span><br><span class="line">    &quot;latex-workshop.message.error.show&quot;: false,</span><br><span class="line">    &quot;latex-workshop.message.warning.show&quot;: false,</span><br><span class="line">    // 编译工具和命令</span><br><span class="line">    &quot;latex-workshop.latex.tools&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;xelatex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;xelatex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;pdflatex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;pdflatex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;latexmk&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;latexmk&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-synctex=1&quot;,</span><br><span class="line">                &quot;-interaction=nonstopmode&quot;,</span><br><span class="line">                &quot;-file-line-error&quot;,</span><br><span class="line">                &quot;-pdf&quot;,</span><br><span class="line">                &quot;-outdir=%OUTDIR%&quot;,</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;bibtex&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;bibtex&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;%DOCFILE%&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    // 用于配置编译链</span><br><span class="line">    &quot;latex-workshop.latex.recipes&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;XeLaTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;xelatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;PDFLaTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;pdflatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;BibTeX&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;bibtex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;LaTeXmk&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;latexmk&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;xelatex -&gt; bibtex -&gt; xelatex*2&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;xelatex&quot;,</span><br><span class="line">                &quot;bibtex&quot;,</span><br><span class="line">                &quot;xelatex&quot;,</span><br><span class="line">                &quot;xelatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;pdflatex -&gt; bibtex -&gt; pdflatex*2&quot;,</span><br><span class="line">            &quot;tools&quot;: [</span><br><span class="line">                &quot;pdflatex&quot;,</span><br><span class="line">                &quot;bibtex&quot;,</span><br><span class="line">                &quot;pdflatex&quot;,</span><br><span class="line">                &quot;pdflatex&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    //文件清理。此属性必须是字符串数组</span><br><span class="line">    &quot;latex-workshop.latex.clean.fileTypes&quot;: [</span><br><span class="line">        &quot;*.aux&quot;,</span><br><span class="line">        &quot;*.bbl&quot;,</span><br><span class="line">        &quot;*.blg&quot;,</span><br><span class="line">        &quot;*.idx&quot;,</span><br><span class="line">        &quot;*.ind&quot;,</span><br><span class="line">        &quot;*.lof&quot;,</span><br><span class="line">        &quot;*.lot&quot;,</span><br><span class="line">        &quot;*.out&quot;,</span><br><span class="line">        &quot;*.toc&quot;,</span><br><span class="line">        &quot;*.acn&quot;,</span><br><span class="line">        &quot;*.acr&quot;,</span><br><span class="line">        &quot;*.alg&quot;,</span><br><span class="line">        &quot;*.glg&quot;,</span><br><span class="line">        &quot;*.glo&quot;,</span><br><span class="line">        &quot;*.gls&quot;,</span><br><span class="line">        &quot;*.ist&quot;,</span><br><span class="line">        &quot;*.fls&quot;,</span><br><span class="line">        &quot;*.log&quot;,</span><br><span class="line">        &quot;*.fdb_latexmk&quot;</span><br><span class="line">    ],</span><br><span class="line">    //设置为onFaild 在构建失败后清除辅助文件</span><br><span class="line">    &quot;latex-workshop.latex.autoClean.run&quot;: &quot;onFailed&quot;,</span><br><span class="line">    // 使用上次的recipe编译组合</span><br><span class="line">    &quot;latex-workshop.latex.recipe.default&quot;: &quot;lastUsed&quot;,</span><br><span class="line">    // 用于反向同步的内部查看器的键绑定。ctrl/cmd +点击(默认)或双击</span><br><span class="line">    &quot;latex-workshop.view.pdf.internal.synctex.keybinding&quot;: &quot;double-click&quot;,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    //使用 SumatraPDF 预览编译好的PDF文件</span><br><span class="line">    // 设置VScode内部查看生成的pdf文件</span><br><span class="line">    &quot;latex-workshop.view.pdf.viewer&quot;: &quot;external&quot;,</span><br><span class="line">    // PDF查看器用于在\ref上的[View on PDF]链接</span><br><span class="line">    &quot;latex-workshop.view.pdf.ref.viewer&quot;:&quot;auto&quot;,</span><br><span class="line">    // 使用外部查看器时要执行的命令。此功能不受官方支持。</span><br><span class="line">    &quot;latex-workshop.view.pdf.external.viewer.command&quot;: &quot;F:/SumatraPDF/SumatraPDF.exe&quot;, // 注意修改路径</span><br><span class="line">    // 使用外部查看器时，latex-workshop.view.pdf.external.view .command的参数。此功能不受官方支持。%PDF%是用于生成PDF文件的绝对路径的占位符。</span><br><span class="line">    &quot;latex-workshop.view.pdf.external.viewer.args&quot;: [</span><br><span class="line">        &quot;%PDF%&quot;</span><br><span class="line">    ],</span><br><span class="line">    // 将synctex转发到外部查看器时要执行的命令。此功能不受官方支持。</span><br><span class="line">    &quot;latex-workshop.view.pdf.external.synctex.command&quot;: &quot;F:/SumatraPDF/SumatraPDF.exe&quot;, // 注意修改路径</span><br><span class="line">    // latex-workshop.view.pdf.external.synctex的参数。当同步到外部查看器时。%LINE%是行号，%PDF%是生成PDF文件的绝对路径的占位符，%TEX%是触发syncTeX的扩展名为.tex的LaTeX文件路径。</span><br><span class="line">    &quot;latex-workshop.view.pdf.external.synctex.args&quot;: [</span><br><span class="line">        &quot;-forward-search&quot;,</span><br><span class="line">        &quot;%TEX%&quot;,</span><br><span class="line">        &quot;%LINE%&quot;,</span><br><span class="line">        &quot;-reuse-instance&quot;,</span><br><span class="line">        &quot;-inverse-search&quot;,</span><br><span class="line">        &quot;code \&quot;F:/Microsoft VS Code/resources/app/out/cli.js\&quot; -r -g \&quot;%f:%l\&quot;&quot;, // 注意修改路径</span><br><span class="line">        &quot;%PDF%&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>写在最后</strong> ： 笔者也只是一个初学者，文中如果出现错误的地方，欢迎您在评论区批评指正，笔者会虚心接受这些产生错误的地方，争取以后学得更扎实再编写这些文字。</p><p>另：若您感觉此文写得勉强还行，希望您能够不吝点赞，给笔者一点小小的激励，以此来进行更多更好的文字编写。非常感谢！！！</p><p>注：转载自<a href="https://zhuanlan.zhihu.com/p/166523064">https://zhuanlan.zhihu.com/p/166523064</a></p>]]></content>
      
      
      <categories>
          
          <category> YOLO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vscode </tag>
            
            <tag> latex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv8的训练自己的数据集</title>
      <link href="/2024/09/25/article-1/"/>
      <url>/2024/09/25/article-1/</url>
      
        <content type="html"><![CDATA[<h2 id="一、YOLOv8的简介"><a href="#一、YOLOv8的简介" class="headerlink" title="一、YOLOv8的简介"></a>一、YOLOv8的简介</h2><p>YOLO（You Only Look Once）系列算法因其高效、准确等特点而备受瞩目。由2023年Ultralytics公司发布了YOLO的<strong>最新版本YOLOv8是结合前几代YOLO的基础上的一个融合改进版</strong>。</p><p>本文YOLOv8网络结构&#x2F;环境搭建&#x2F;数据集获取&#x2F;训练&#x2F;推理&#x2F;验证&#x2F;导出&#x2F;部署，从网络结构的讲解从模型的网络结构讲解到模型的部署都有详细介绍，同时在本专栏中还包括YOLOv8模型系列的改进包<strong>括个人提出的创新点，传统卷积、注意力机制、损失函数的修改教程，能够帮助你的论文获得创新点。</strong></p><h2 id="二、YOLOv8相对于Yolov5的核心改动"><a href="#二、YOLOv8相对于Yolov5的核心改动" class="headerlink" title="二、YOLOv8相对于Yolov5的核心改动"></a>二、YOLOv8相对于Yolov5的核心改动</h2><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/39fa749365bc4a6e87a8e63563bca5cc.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/39fa749365bc4a6e87a8e63563bca5cc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="39fa749365bc4a6e87a8e63563bca5cc.png"></p><hr><p>从YOLOv8的网络结构可以看出,其延用了YOLOv5的网络结构思想，<strong>包括基于CSP（紧凑和分离）的骨干网络(backbone)和Neck部分的设计，以及对于不同尺度模型的考虑。</strong></p><p><strong>改进总结：</strong></p><blockquote><ol><li><p>Backbone的改进：使用C2f模块代替C3模块，进一步轻量化，同时保持了CSP的思想，同时采用了SPPF模块。</p></li><li><p>PAN-FPN的改进：保留了PAN的思想，但删除了上采样阶段中的卷积结构，同时将C3模块替换为C2f模块。</p></li><li><p>Decoupled-Head的引入：采用了Decoupled-Head的思想，使得网络的训练和推理更加高效。</p></li><li><p>Anchor-Free的思想：抛弃了Anchor-Base，采用了Anchor-Free的思想。</p></li><li><p>损失函数的改进：采用VFL Loss作为分类损失，同时使用DFL Loss和CIOU Loss作为回归损失。</p></li><li><p>样本匹配方式的改进：采用了Task-Aligned Assigner匹配方式。</p></li></ol></blockquote><p>这些改进使得YOLOv8在目标检测方面具有更高的精度和更快的速度，同时保持了轻量化的特点。</p><p><strong>具体来说</strong>，YOLOv8的Backbone部分使用了C2f模块来替代了YOLOv5中的C3模块，实现了进一步的轻量化。同时，它也保留了YOLOv5等架构中使用的SPPF（空间金字塔池化）模块。</p><p>在PAN-FPN（路径聚合网络-特征金字塔网络）部分，虽然YOLOv8依旧采用了PAN的思想，但是在结构上，它删除了YOLOv5中PAN-FPN上采样阶段中的卷积结构，并将C3模块替换为了C2f模块。</p><p>这些改进使得YOLOv8在保持了YOLOv5网络结构的优点的同时，进行了更加精细的调整和优化，提高了模型在不同场景下的性能。</p><h2 id="三、YOLOv8的网络结构"><a href="#三、YOLOv8的网络结构" class="headerlink" title="三、YOLOv8的网络结构"></a><strong>三、YOLOv8的网络结构</strong></h2><p>YOLOv8的网络结构主要由以下三个大部分组成：</p><blockquote><ol><li><p>Backbone：它采用了一系列卷积和反卷积层来提取特征，同时也使用了残差连接和瓶颈结构来减小网络的大小和提高性能。该部分采用了C2f模块作为基本构成单元，与YOLOv5的C3模块相比，C2f模块具有更少的参数量和更优秀的特征提取能力。</p></li><li><p>Neck：它采用了多尺度特征融合技术，将来自Backbone的不同阶段的特征图进行融合，以增强特征表示能力。具体来说，YOLOv8的Neck部分包括一个SPPF模块、一个PAA模块和两个PAN模块。</p></li><li><p>Head：它负责最终的目标检测和分类任务，包括一个检测头和一个分类头。检测头包含一系列卷积层和反卷积层，用于生成检测结果；分类头则采用全局平均池化来对每个特征图进行分类。</p></li></ol></blockquote><p>下面我们来针对于YOLOv8的三个组成部分进行详细讲解。</p><h4 id="3-1-Backbone"><a href="#3-1-Backbone" class="headerlink" title="3.1 Backbone"></a>3.1 Backbone</h4><p>由最上面的YOLOv8网络结构图我们可以看出在其中的Backbone部分，由5个卷积模块和4个C2f模块和一个SPPF模块组成，</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a744491cd5a14bcf9b33015b18c6c6c8.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a744491cd5a14bcf9b33015b18c6c6c8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="a744491cd5a14bcf9b33015b18c6c6c8.png"></p><p>(其中浅蓝色为卷积模块,黄色为C2f模块深蓝色为SPPF模块 )</p><p>如果上图看的不够直观,我们来看一下YOLOv8的文件中的yaml文件,看一下它backbone部分的结构组成部分，会更加直观。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">backbone:</span><br><span class="line">  <span class="comment"># [from, repeats, module, args]</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">64</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 0-P1/2</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 1-P2/4</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">128</span>, <span class="literal">True</span>]]</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 3-P3/8</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">6</span>, C2f, [<span class="number">256</span>, <span class="literal">True</span>]]</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 5-P4/16</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">6</span>, C2f, [<span class="number">512</span>, <span class="literal">True</span>]]</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 7-P5/32</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">1024</span>, <span class="literal">True</span>]]</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, SPPF, [<span class="number">1024</span>, <span class="number">5</span>]]  <span class="comment"># 9</span></span><br></pre></td></tr></table></figure><p>上面的部分就是YOLOv8的yaml文件的Backbone部分，可以看到其由5个Conv模块，四个C2f模块以及一个SPPF模块组成，<strong>下面我们来根据每个模块的组成来进行讲解。</strong></p><h5 id="3-1-1-卷积模块-Conv"><a href="#3-1-1-卷积模块-Conv" class="headerlink" title="3.1.1 卷积模块(Conv)"></a>3.1.1 卷积模块(Conv)</h5><p>在其中卷积模块的结构主要为下图</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/56694f12be0d4664905561c9438e2850.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/56694f12be0d4664905561c9438e2850.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="56694f12be0d4664905561c9438e2850.png"></p><p>在其中主要结构为一个2D的卷积一个BatchNorm2d和一个SiLU激活函数，整个<strong>卷积模块</strong>的作用为：</p><ol><li><strong>降采样：每个卷积模块中的卷积层都采用步长为2的卷积核进行降采样操作，以减小特征图的尺寸并增加通道数。</strong></li><li><strong>非线性表示：每个卷积层之后都添加了Batch Normalization（批标准化）层和ReLU激活函数，以增强模型的非线性表示能力。</strong></li></ol><blockquote><p>在其中Batch Normalization（批标准化）是深度学习中常用的一种技术，用于加速神经网络的训练。Batch Normalization通过对每个小批量数据进行标准化，使得神经网络在训练过程中更加稳定，可以使用更高的学习率，并且减少了对初始化权重的依赖。Batch Normalization的基本思想是：对每个小批量数据进行标准化，使得每个特征的均值为0，方差为1，然后再通过一个可学习的缩放因子和平移因子来调整数据的分布，从而使得神经网络更容易训练。</p></blockquote><h5 id="3-1-2-C2f模块"><a href="#3-1-2-C2f模块" class="headerlink" title="3.1.2 C2f模块"></a><strong>3.1.2 C2f模块</strong></h5><p>在YOLOv8的网络结构中C2f模块算是YOLOv8的一个较大的改变，与YOLOv5的C3模块相比，C2f模块具有更少的参数量和更优秀的特征提取能力。<strong>下图为C2f的内部网络结构图。</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/3fa4855f3d38447b93e5faf40cd59169.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/3fa4855f3d38447b93e5faf40cd59169.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="3fa4855f3d38447b93e5faf40cd59169.png"></p><p>在C2f模块中我们可以看到输入首先经过<strong>一个k&#x3D;1，s&#x3D;1，p&#x3D;0，c&#x3D;c_out</strong>的卷积模块进行了处理，然后经过一个split处理**(在这里split和后面的concat的组成其实就是所谓的残差模块处理)**经过数量为n的DarknetBottleneck模块处理以后将残差模块和主干模块的结果进行Concat拼接在经过一个卷积模块处理进行输出。 </p><blockquote><p>在其中提到的残差连接（residual connections）是一种用于构建深层神经网络的技术。它的核心思想是通过跳过层级连接来传递残差或误差。</p><p>在传统的神经网络中，信息流通过一层层的网络层，每一层都通过非线性激活函数进行转换和提取特征。然而，随着神经网络的加深，可能会出现”梯度消失”或”梯度爆炸”的问题，导致网络收敛困难或性能下降。</p><p>残差连接通过引入跨层级的连接，将输入的原始信息直接传递到后续层级，以解决梯度消失和爆炸问题。具体而言，它将网络的输入与中间层的输出相加，形成了一个”捷径”或”跳跃连接”，从而允许梯度更容易地传播。</p><p>数学上，假设我们有一个输入x，通过多个网络层进行处理后得到预测值H(x)。那么残差连接的表达式为：</p><p>F(x) &#x3D; H(x) + x</p><p>其中，F(x)为残差块的输出，H(x)为经过一系列网络层处理后得到的特征表示，x为输入直接连接到残差块中的跳跃连接。</p><p>通过残差连接，网络可以更容易地学习残差或误差，从而使网络更深层次的特征表达更准确。这对于训练深层神经网络非常有用，可以提高网络的性能和收敛速度。</p></blockquote><blockquote><p> 在C2f模块中用到的DarknetBottleneck模块其中使用多个3x3卷积核进行卷积操作，提取特征信息。同时其具有add是否进行残差链接的选项。</p></blockquote><p> <strong>其实整个C2f模块就是一个改良版本的Darknet</strong></p><ol><li><p>首先，使用1x1卷积核将输入通道数减少到原来的1&#x2F;2，以减少计算量和内存消耗。</p></li><li><p>然后，使用多个3x3卷积核进行卷积操作，提取特征信息。</p></li><li><p>接着，使用残差链接，将输入直接加到输出中，从而形成了一条跨层连接。</p></li><li><p>接着，再次使用1x1卷积核恢复特征图的通道数。</p></li></ol><p>SPPF模块 </p><p>YOLOv8的SPPF模块相对于YOLOv5的SPPF模块并没有任何的改变。</p><h4 id="3-2-Neck"><a href="#3-2-Neck" class="headerlink" title="3.2 Neck"></a>3.2 Neck</h4><p>YOLOv8的Neck部分是该模型中的一个关键组件，<strong>它在特征提取和融合方面起着重要作用</strong>。Neck的详细描述如下：</p><p>Neck部分主要起到一个特征融合的操作, YOLOv8的Neck部分依然采用PAN-FPN的思想，下图的a，b，c为一个Neck部分的流程示意图。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a3aeff6d8f0542a79efbd5e95c0b10b9.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a3aeff6d8f0542a79efbd5e95c0b10b9.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="a3aeff6d8f0542a79efbd5e95c0b10b9.png"></p><blockquote><p>整个Neck部分的步骤如下：：将特征提取网络(Backbone)的输出P3，P4，P5输入进PAN-FPN网络结构，使得多个尺度的特征图进行融合；将P5经过上采样与P4进行融合得到F1，将F1经过C2f层和一次上采样与P3进行融合得到T1，将T1经过一次卷积层与F1经过融合得到F2，将F2经过一次C2f层得到T2，将T2经过一次卷积层与P5融合得到F3，将F3经过一次C2f层得到T3，最终得到T1、T2、T3就是整个Neck的产物； </p></blockquote><p>上述过程可以描述为下图，我在图片上做了一些标准方便理解。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4b480765acd947879588f6d132704eb8.jpeg" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4b480765acd947879588f6d132704eb8.jpeg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="4b480765acd947879588f6d132704eb8.jpeg"></p><p>上述的过程可以在代码部分看到,我们同样看YOLOv8的yaml文件，能够更直观的看到这个步骤,大家可以看代码同时对应图片来进行分析:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">head:</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]]</span><br><span class="line">  - [[-<span class="number">1</span>, <span class="number">6</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]]  <span class="comment"># cat backbone P4</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">512</span>]]  <span class="comment"># 12</span></span><br><span class="line"> </span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]]</span><br><span class="line">  - [[-<span class="number">1</span>, <span class="number">4</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]]  <span class="comment"># cat backbone P3</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">256</span>]]  <span class="comment"># 15 (P3/8-small)</span></span><br><span class="line"> </span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]]</span><br><span class="line">  - [[-<span class="number">1</span>, <span class="number">12</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]]  <span class="comment"># cat head P4</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">512</span>]]  <span class="comment"># 18 (P4/16-medium)</span></span><br><span class="line"> </span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]]</span><br><span class="line">  - [[-<span class="number">1</span>, <span class="number">9</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]]  <span class="comment"># cat head P5</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">1024</span>]]  <span class="comment"># 21 (P5/32-large)</span></span><br></pre></td></tr></table></figure><p><strong>Neck部分的整体功能的详细分析如下:</strong></p><p>1. Neck的作用：<br>Neck部分在YOLOv8模型中<strong>负责对来自Backbone的特征进行进一步处理和融合</strong>，以提高目标检测的准确性和鲁棒性。它通过引入不同的结构和技术，将多尺度的特征图进行融合，以便更好地捕捉不同尺度目标的信息。</p><p>2. 特征金字塔网络（Feature Pyramid Network, FPN）：<br>YOLOv8的Neck部分通常采用特征金字塔网络结构，用于处理来自Backbone的多尺度特征图。<strong>FPN通过在不同层级上建立特征金字塔</strong>，使得模型能够在不同尺度上进行目标检测。它通过上采样和下采样操作，将低层级的细节特征与高层级的语义特征进行融合，以获取更全面和丰富的特征表示。</p><p>3. 特征融合（Feature Fusion）：<br>Neck部分还包括特征融合的操作，<strong>用于将来自不同层级的特征进行融合</strong>。这种特征融合有助于提高模型对目标的检测准确性，尤其是对于不同尺度的目标。</p><p>4. 上采样和下采样：<br>Neck部分通常会使用上采样和下采样操作，以调整特征图的尺度和分辨率。上采样操作可以将低分辨率的特征图放大到与高分辨率特征图相同的尺寸，<strong>以保留更多的细节信息</strong>。而下采样操作则可以将高分辨率的特征图降低尺寸，<strong>以减少计算量和内存消耗</strong>。</p><p>YOLOv8的Neck部分通过特征金字塔网络和特征融合等操作，<strong>有效地提取和融合多尺度的特征</strong>，从而提高了目标检测的性能和鲁棒性。这使得模型能够更好地适应不同尺度和大小的目标，并在复杂场景下取得更准确的检测结果。</p><blockquote><p>PAN-FPN（具有特征金字塔网络的路径聚合网络）是一种用于计算机视觉中对象检测的神经网络架构。它将特征金字塔网络（FPN）与路径聚合网络（PAN）相结合，以提高目标检测的准确性和效率。</p><p>FPN 用于从不同比例的图像中提取特征，而 PAN 用于跨网络的不同层聚合这些特征。这允许网络检测不同大小和分辨率的对象，并处理具有多个对象的复杂场景。</p></blockquote><h4 id="3-3-Head"><a href="#3-3-Head" class="headerlink" title="3.3 Head"></a>3.3 Head</h4><p>如果Backbone和Neck部分可以理解为准备工作，那么Head部分就是收获的部分，经过前面的准备工作我们得到了Neck部分的输出T1、T2、T3分别代表不同层级的特征图，<strong>Head部分就是对这三个特征图进行处理以产生模型的的输出结果的一个过程。</strong></p><p>YOLOv8的Head部分我们先来看一下它的网络结构。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bc05b2293026433985d4152e8a116634.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bc05b2293026433985d4152e8a116634.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="bc05b2293026433985d4152e8a116634.png"></p><p>可以看到在YOLOv8的Head部分，体现了最核心的改动——&gt;解耦头(Decoupled-Head)，顾名思义就是将原先的一个检测头分解成两个部分。</p><p>在Head部分的三个解耦头分别对应着Neck部分的特征图输出T1、T2、T3。、</p><p><strong>解耦头的工作流程是：</strong></p><blockquote><p>将网络得到的特征图T1，T2，T3分别输入解耦头头进行预测，检测头的结构如下图所示其中包含4个3×3卷积与2个1×1卷积，同时在检测头的回归分支中添加WIOU损失函数如图4所示，回归头部需要计算预测框与真实框之间的位置偏移量，然后将偏移量送入回归头部进行损失计算，然后输出一个四维向量，分别表示目标框的左上角坐标x、y和右下角坐标x、y。分类头部针对于每个Anchor Free提取的候选框对其进行RoI Pooling和卷积操作得到一个分类器输出张量每个位置上的值表示该候选框属于每个类别的概率，在最后通过极大值抑制方式筛选出最终的检测结果 </p></blockquote><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ddf8b2f464a348868513ba3488ece02b.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ddf8b2f464a348868513ba3488ece02b.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="ddf8b2f464a348868513ba3488ece02b.png"></p><p>我们再从YOLOv8的yaml文件来看Head部分的作用</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/16099ed50b934e5ba7100ab8a381c1cd.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/16099ed50b934e5ba7100ab8a381c1cd.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="16099ed50b934e5ba7100ab8a381c1cd.png"></p><p><strong>可以看到检测头部分的输出为15,18，21分别对应着Neck部分的三个输出特征图。</strong> </p><p>到此YOLOv8的网络结构部分讲解就已经完成，下面我们来看如何利用YOLOv8进行训练操作。  </p><hr><h2 id="四、环境搭建"><a href="#四、环境搭建" class="headerlink" title="四、环境搭建"></a>四、环境搭建</h2><p>在我们配置好环境之后，在之后模型获取完成之后，我们可以进行配置的安装我们可以在命令行下输入如下命令进行环境的配置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>输入如上命令之后我们就可以看到命令行在安装模型所需的库了。 </p><h2 id="五、数据集获取"><a href="#五、数据集获取" class="headerlink" title="五、数据集获取"></a>五、数据集获取</h2><p>我在上面随便下载了一个 数据集用它导出yolov8的数据集，以及自动给转换成txt的格式yaml文件也已经配置好了，我们直接用就可以。 </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8673527d34eb42348770158c69de678f.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8673527d34eb42348770158c69de678f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="8673527d34eb42348770158c69de678f.png"></p><hr><h2 id="六、模型获取"><a href="#六、模型获取" class="headerlink" title="六、模型获取"></a>六、模型获取</h2><p>到这里假设你已经搭建好了环境和有了数据集，那么我们就可以进行模型的下载，因为yolov8目前还存在BUG并不稳定随时都有可能进行更新，所以不推荐大家通过其它的途径下载，最好通过下面的方式进行下载。</p><p>我们可以直接在终端命令下</p><p><strong>(PS：这里需要注意的是我们需要在你总项目文件目录下输入这个命令，因为他会下载到当前目录下)</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install ultralytics</span><br></pre></td></tr></table></figure><p> 如果大家去github上直接下载zip文件到本地可能会遇到报错如下，识别不了yolo命令，所以推荐大家用这种方式下载，</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c89d06161cd149c0ac0488e90188bcfc.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c89d06161cd149c0ac0488e90188bcfc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="c89d06161cd149c0ac0488e90188bcfc.png"></p><hr><h2 id="七、模型训练"><a href="#七、模型训练" class="headerlink" title="七、模型训练"></a>七、模型训练</h2><p>我们来看一下主要的ultralytics目录结构，</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a900c1d0d16f45e2b8c3829aec6c2499.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a900c1d0d16f45e2b8c3829aec6c2499.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="a900c1d0d16f45e2b8c3829aec6c2499.png"></p><p> 我门打开cfg目录下的default.yaml文件可以配置模型的参数，</p><p>在其中和模型训练有关的参数及其解释如下:</p><table><thead><tr><th></th><th>参数名</th><th>输入类型</th><th>参数解释</th></tr></thead><tbody><tr><td>0</td><td>task</td><td>str</td><td>YOLO模型的任务选择，选择你是要进行检测、分类等操作</td></tr><tr><td>1</td><td>mode</td><td>str</td><td>YOLO模式的选择，选择要进行训练、推理、输出、验证等操作</td></tr><tr><td>2</td><td>model</td><td>str&#x2F;optional</td><td>模型的文件，可以是官方的预训练模型，也可以是训练自己模型的yaml文件</td></tr><tr><td>3</td><td>data</td><td>str&#x2F;optional</td><td>模型的地址，可以是文件的地址，也可以是配置好地址的yaml文件</td></tr><tr><td>4</td><td>epochs</td><td>int</td><td>训练的轮次，将你的数据输入到模型里进行训练的次数</td></tr><tr><td>5</td><td>patience</td><td>int</td><td>早停机制，当你的模型精度没有改进了就提前停止训练</td></tr><tr><td>6</td><td>batch</td><td>int</td><td>我们输入的数据集会分解为多个子集，一次向模型里输入多少个子集</td></tr><tr><td>7</td><td>imgsz</td><td>int&#x2F;list</td><td>输入的图片的大小，可以是整数就代表图片尺寸为int*int，或者list分别代表宽和高[w，h]</td></tr><tr><td>8</td><td>save</td><td>bool</td><td>是否保存模型以及预测结果</td></tr><tr><td>9</td><td>save_period</td><td>int</td><td>在训练过程中多少次保存一次模型文件,就是生成的pt文件</td></tr><tr><td>10</td><td>cache</td><td>bool</td><td>参数cache用于控制是否启用缓存机制。</td></tr><tr><td>11</td><td>device</td><td>int&#x2F;str&#x2F;list&#x2F;optional</td><td>GPU设备的选择：cuda device&#x3D;0 or device&#x3D;0,1,2,3 or device&#x3D;cpu</td></tr><tr><td>12</td><td>workers</td><td>int</td><td>工作的线程，Windows系统一定要设置为0否则很可能会引起线程报错</td></tr><tr><td>13</td><td>name</td><td>str&#x2F;optional</td><td>模型保存的名字，结果会保存到’project&#x2F;name’ 目录下</td></tr><tr><td>14</td><td>exist_ok</td><td>bool</td><td>如果模型存在的时候是否进行覆盖操作</td></tr><tr><td>15</td><td>prepetrained</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr></tbody></table><h3 id="7-1-训练的三种方式"><a href="#7-1-训练的三种方式" class="headerlink" title="7.1 训练的三种方式"></a>7.1 训练的三种方式</h3><h4 id="7-1-1-方式一"><a href="#7-1-1-方式一" class="headerlink" title="7.1.1 方式一"></a>7.1.1 方式一</h4><p>我们可以通过命令直接进行训练在其中指定参数，但是这样的方式，我们每个参数都要在其中打出来。命令如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yolo task=detect mode=train model=yolov8n.pt data=data.yaml batch=<span class="number">16</span> epochs=<span class="number">100</span> imgsz=<span class="number">640</span> workers=<span class="number">0</span> device=<span class="number">0</span></span><br></pre></td></tr></table></figure><p>需要注意的是如果你是Windows系统的电脑其中的Workers最好设置成0否则容易报线程的错误。</p><h4 id="7-1-2-方式二（推荐）"><a href="#7-1-2-方式二（推荐）" class="headerlink" title="7.1.2 方式二（推荐）"></a><strong>7.1.2 方式二（推荐）</strong></h4><p>通过指定cfg直接进行训练，我们配置好ultralytics&#x2F;cfg&#x2F;default.yaml这个文件之后，可以直接执行这个文件进行训练，这样就不用在命令行输入其它的参数了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yolo cfg=ultralytics/cfg/default.yaml</span><br></pre></td></tr></table></figure><h4 id="7-1-3-方式三"><a href="#7-1-3-方式三" class="headerlink" title="7.1.3 方式三"></a><strong>7.1.3 方式三</strong></h4><p> 我们可以通过创建py文件来进行训练，这样的好处就是不用在终端上打命令，这也能省去一些工作量，我们在根目录下创建一个名字为run.py的文件，在其中输入代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO model = YOLO(<span class="string">&quot;权重的地址&quot;</span>) data = <span class="string">&quot;文件的地址&quot;</span> model.train(data=data, epochs=<span class="number">100</span>, batch=<span class="number">16</span>)</span><br></pre></td></tr></table></figure><p> 无论通过上述的哪一种方式在控制台输出如下图片的内容就代表着开始训练成功了！</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4f1fbc25c60f44bd980ee215b5866d12.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4f1fbc25c60f44bd980ee215b5866d12.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="4f1fbc25c60f44bd980ee215b5866d12.png"></p><hr><h2 id="八、模型验证-测试"><a href="#八、模型验证-测试" class="headerlink" title="八、模型验证&#x2F;测试 "></a>八、模型验证&#x2F;测试 </h2><table><thead><tr><th></th><th>参数名</th><th>类型</th><th>参数讲解</th></tr></thead><tbody><tr><td>1</td><td>val</td><td>bool</td><td>用于控制是否在训练过程中进行验证&#x2F;测试。</td></tr><tr><td>2</td><td>split</td><td>str</td><td>用于指定用于验证&#x2F;测试的数据集划分。可以选择 ‘val’、’test’ 或 ‘train’ 中的一个作为验证&#x2F;测试数据集</td></tr><tr><td>3</td><td>save_json</td><td>bool</td><td>用于控制是否将结果保存为 JSON 文件</td></tr><tr><td>4</td><td>save_hybird</td><td>bool</td><td>用于控制是否保存标签和附加预测结果的混合版本</td></tr><tr><td>5</td><td>conf</td><td>float&#x2F;optional</td><td>用于设置检测时的目标置信度阈值</td></tr><tr><td>6</td><td>iou</td><td>float</td><td>用于设置非极大值抑制（NMS）的交并比（IoU）阈值。</td></tr><tr><td>7</td><td>max_det</td><td>int</td><td>用于设置每张图像的最大检测数。</td></tr><tr><td>8</td><td>half</td><td>bool</td><td>用于控制是否使用半精度（FP16）进行推断。</td></tr><tr><td>9</td><td>dnn</td><td>bool</td><td>，用于控制是否使用 OpenCV DNN 进行 ONNX 推断。</td></tr><tr><td>10</td><td>plots</td><td>bool</td><td>用于控制在训练&#x2F;验证过程中是否保存绘图结果。</td></tr></tbody></table><p> 验证我们划分的验证集&#x2F;测试集的情况，也就是评估我们训练出来的best.pt模型好与坏</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yolo task=detect mode=val model=best.pt data=data.yaml device=<span class="number">0</span></span><br></pre></td></tr></table></figure><hr><h2 id="九、模型推理"><a href="#九、模型推理" class="headerlink" title="九、模型推理"></a>九、模型推理</h2><p>我们训练好自己的模型之后，都会生成一个模型文件,保存在你设置的目录下,当我们再次想要实验该模型的效果之后就可以调用该模型进行推理了，我们也可以用官方的预训练权重来进行推理。</p><p>推理的方式和训练一样我们这里就选一种来进行举例其它的两种方式都是一样的操作只是需要改一下其中的一些参数即可:</p><p><strong>参数讲解</strong></p><table><thead><tr><th></th><th>参数名</th><th>类型</th><th>参数讲解</th></tr></thead><tbody><tr><td>0</td><td>source</td><td>str&#x2F;optinal</td><td>用于指定图像或视频的目录</td></tr><tr><td>1</td><td>show</td><td>bool</td><td>用于控制是否在可能的情况下显示结果</td></tr><tr><td>2</td><td>save_txt</td><td>bool</td><td>用于控制是否将结果保存为 <code>.txt</code> 文件</td></tr><tr><td>3</td><td>save_conf</td><td>bool</td><td>用于控制是否在保存结果时包含置信度分数</td></tr><tr><td>4</td><td>save_crop</td><td>bool</td><td>用于控制是否将带有结果的裁剪图像保存下来</td></tr><tr><td>5</td><td>show_labels</td><td>bool</td><td>用于控制在绘图结果中是否显示目标标签</td></tr><tr><td>6</td><td>show_conf</td><td>bool</td><td>用于控制在绘图结果中是否显示目标置信度分数</td></tr><tr><td>7</td><td>vid_stride</td><td>int&#x2F;optional</td><td>用于设置视频的帧率步长</td></tr><tr><td>8</td><td>stream_buffer</td><td>bool</td><td>用于控制是否缓冲所有流式帧（True）或返回最新的帧（False）</td></tr><tr><td>9</td><td>line_width</td><td>int&#x2F;list[int]&#x2F;optional</td><td>用于设置边界框的线宽度，如果缺失则自动设置</td></tr><tr><td>10</td><td>visualize</td><td>bool</td><td>用于控制是否可视化模型的特征</td></tr><tr><td>11</td><td>augment</td><td>bool</td><td>用于控制是否对预测源应用图像增强</td></tr><tr><td>12</td><td>agnostic_nms</td><td>bool</td><td>用于控制是否使用无关类别的非极大值抑制（NMS）</td></tr><tr><td>13</td><td>classes</td><td>int&#x2F;list[int]&#x2F;optional</td><td>用于按类别筛选结果</td></tr><tr><td>14</td><td>retina_masks</td><td>bool</td><td>用于控制是否使用高分辨率分割掩码</td></tr><tr><td>15</td><td>boxes</td><td>bool</td><td>用于控制是否在分割预测中显示边界框。</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yolo task=detect mode=predict model=best.pt source=images device=<span class="number">0</span></span><br></pre></td></tr></table></figure><p> 这里需要需要注意的是我们用模型进行推理的时候可以选择照片也可以选择一个视频的格式都可以。支持的视频格式有 </p><blockquote><ul><li><p>MP4（.mp4）：这是一种常见的视频文件格式，通常具有较高的压缩率和良好的视频质量</p></li><li><p>AVI（.avi）：这是一种较旧但仍广泛使用的视频文件格式。它通常具有较大的文件大小</p></li><li><p>MOV（.mov）：这是一种常见的视频文件格式，通常与苹果设备和QuickTime播放器相关</p></li><li><p>MKV（.mkv）：这是一种开放的多媒体容器格式，可以容纳多个视频、音频和字幕轨道</p></li><li><p>FLV（.flv）：这是一种用于在线视频传输的流式视频文件格式</p></li></ul></blockquote><hr><h2 id="十、模型输出"><a href="#十、模型输出" class="headerlink" title="十、模型输出"></a>十、模型输出</h2><p>当我们进行部署的时候可以进行文件导出，然后在进行部署。</p><p>YOLOv8支持的输出格式有如下</p><blockquote><p>1. ONNX（Open Neural Network Exchange）：ONNX 是一个开放的深度学习模型表示和转换的标准。它允许在不同的深度学习框架之间共享模型，并支持跨平台部署。导出为 ONNX 格式的模型可以在支持 ONNX 的推理引擎中进行部署和推理。</p><p>2. TensorFlow SavedModel：TensorFlow SavedModel 是 TensorFlow 框架的标准模型保存格式。它包含了模型的网络结构和参数，可以方便地在 TensorFlow 的推理环境中加载和使用。</p><p>3. PyTorch JIT（Just-In-Time）：PyTorch JIT 是 PyTorch 的即时编译器，可以将 PyTorch 模型导出为优化的 Torch 脚本或 Torch 脚本模型。这种格式可以在没有 PyTorch 环境的情况下进行推理，并且具有更高的性能。</p><p>4. Caffe Model：Caffe 是一个流行的深度学习框架，它使用自己的模型表示格式。导出为 Caffe 模型的文件可以在 Caffe 框架中进行部署和推理。</p><p>5. TFLite（TensorFlow Lite）：TFLite 是 TensorFlow 的移动和嵌入式设备推理框架，支持在资源受限的设备上进行高效推理。模型可以导出为 TFLite 格式，以便在移动设备或嵌入式系统中进行部署。</p><p>6. Core ML（Core Machine Learning）：Core ML 是苹果的机器学习框架，用于在 iOS 和 macOS 上进行推理。模型可以导出为 Core ML 格式，以便在苹果设备上进行部署。</p><p>这些格式都提供了不同的优势和适用场景。选择合适的导出格式应该考虑到目标平台和部署环境的要求，以及所使用的深度学习框架的支持情况。</p></blockquote><p>模型输出的参数有如下</p><table><thead><tr><th></th><th>参数名</th><th>类型</th><th>参数解释</th></tr></thead><tbody><tr><td>0</td><td>format</td><td>str</td><td>导出模型的格式</td></tr><tr><td>1</td><td>keras</td><td>bool</td><td>表示是否使用Keras</td></tr><tr><td>2</td><td>optimize</td><td>bool</td><td>用于在导出TorchScript模型时进行优化，以便在移动设备上获得更好的性能</td></tr><tr><td>3</td><td>int8</td><td>bool</td><td>用于在导出CoreML或TensorFlow模型时进行INT8量化</td></tr><tr><td>4</td><td>dynamic</td><td>bool</td><td>用于在导出CoreML或TensorFlow模型时进行INT8量化</td></tr><tr><td>5</td><td>simplify</td><td>bool</td><td>用于在导出ONNX模型时进行模型简化</td></tr><tr><td>6</td><td>opset</td><td>int&#x2F;optional</td><td>用于指定导出ONNX模型时的opset版本</td></tr><tr><td>7</td><td>workspace</td><td>int</td><td>用于指定TensorRT模型的工作空间大小，以GB为单位</td></tr><tr><td>8</td><td>nms</td><td>bool</td><td>用于在导出CoreML模型时添加非极大值抑制（NMS）</td></tr></tbody></table><p>命令行命令如下: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yolo task=detect mode=export model=best.pt <span class="built_in">format</span>=onnx  </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> Computer Vision </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>恒源云</title>
      <link href="/2024/09/25/article-2/"/>
      <url>/2024/09/25/article-2/</url>
      
        <content type="html"><![CDATA[<h1 id="恒源云"><a href="#恒源云" class="headerlink" title="恒源云"></a>恒源云</h1><p>为当涉及到深度学习的训练任务时，GPU的计算能力是不可或缺的。相对于传统的中央处理器（CPU），图形处理器（GPU）具有更强大的并行计算能力，能够显著加速深度学习模型的训练过程。深度学习算法通常涉及大量的矩阵运算和张量操作，而GPU的并行计算架构使得它们能够高效地执行这些计算，从而加速模型训练的速度。</p><p>恒源云是一个经济高效的云计算平台，您可以通过恒源云的控制台或者命令行界面来管理实例、上传和下载数据、执行训练任务等。恒源云还提供了高度可定制的实例规格，您可以根据自己的需求选择适合的实例类型和配置，以最大程度地优化性能和成本。</p><p>另一个恒源云的优势是其<strong>经济实惠的价格</strong>。相对于购买和维护专门的GPU设备，利用恒源云进行云端模型训练可以大大节省成本。恒源云提供了多种付费模式，包括按需付费和预付费套餐，使您能够根据自己的预算和需求进行灵活选择。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/3d1ee5ffbd434e55b5d844b892b57423.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/3d1ee5ffbd434e55b5d844b892b57423.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h2 id="上传数据集"><a href="#上传数据集" class="headerlink" title="上传数据集"></a>上传数据集</h2><p>在恒源云中我们需要通过终端来上传数据集文件，当在本地处理好了数据集文件以后，我们将其解压缩成zip文件的格式当然tar压缩包等格式的都可以。 </p><p>这里推荐大家用OSS命令上传数据集,可以支持大规模的数据上传。</p><p>在利用OSS进行上传之前我们需要下载一个文件，下载方式如下。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2e6a644b805c4ab491ffc9a06b4d0acc.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2e6a644b805c4ab491ffc9a06b4d0acc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>完成之后，我们点击下载好的文件，会弹出命令行。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c9daf9ea8fef41edb01f7dfd6a420e28.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c9daf9ea8fef41edb01f7dfd6a420e28.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>在这里我们可以输入指令,我们先来输入version来检验下我们是否安装成功。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/490f8eb1388b4ccd9d79a464de20960c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/490f8eb1388b4ccd9d79a464de20960c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>当我们安装成功之后，我们先远程登录我们的账号和密码，输入Login</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">login</span><br></pre></td></tr></table></figure><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8c9b62f6cf8a47789acca1a7079fb06f.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8c9b62f6cf8a47789acca1a7079fb06f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p> 当我们登录成功之后,我们就远程登录了我们的恒源云账号和密码,我们就可以在我们的账号下面建立存储我们数据的文件了。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/059efdcfd75548f9912456c145124dc7.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/059efdcfd75548f9912456c145124dc7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> 按照下图操作即可。<img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bf26c45c981f4f3a824245a7cf03a354.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bf26c45c981f4f3a824245a7cf03a354.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>当我们上传好一个文件之后,该文件就保存到我们的系统内了,我们可以随时在该终端页面下载该数据到我们后面步骤中创建的任何实例当中，利用如下命令</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0910b808ea634c318316c93eaf7e694a.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0910b808ea634c318316c93eaf7e694a.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> (PS:最后一步需要我们经过下面的’利用云端训练YOLOv8模型’之后才可以进行，在我们创建完实例之后进行的操作步骤)</p><h2 id="利用云端训练YOLOv8模型"><a href="#利用云端训练YOLOv8模型" class="headerlink" title="利用云端训练YOLOv8模型"></a>利用云端训练YOLOv8模型</h2><p>首先进入恒源云的官方网站</p><p><a href="https://www.gpushare.com/" title="恒源云官方网站">恒源云官方网站</a></p><p>然后进行注册和登录操作此步骤省略</p><p> 当我们注册和登录之后会进到控制台界面,然后点击创建实例进入到如下界面。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0f55027db1194e14abc71c9bcf5bfa0d.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0f55027db1194e14abc71c9bcf5bfa0d.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>在其中根据你的需求选择你的GPU型号,</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/dc99d3b2734e493aa405e8b80dc69dae.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/dc99d3b2734e493aa405e8b80dc69dae.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> 之后在同页面的最下面有一个实例镜像，可以在其中的下拉滚动条中选择你需要的PyTorch、TensorFlow或者其它框架的版本</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8f54226cfeaa498594522102f26048a5.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8f54226cfeaa498594522102f26048a5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>然后之后我们创建实例即可。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5f764bb992ca476689322218d7c84146.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5f764bb992ca476689322218d7c84146.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> 首先开始时需要创建一会,然后才可以进行操作，等待一会创建成功后就会变成如下图的状态情况。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/da777e8327cd43cd8c9962b2d1307e17.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/da777e8327cd43cd8c9962b2d1307e17.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> 我们按照图片的操作点击其中的”JupyterLab” 然后会弹出新的网页如下图。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/aa99c7769ca1457da7300c73277351e4.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/aa99c7769ca1457da7300c73277351e4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>在其中hy-tmp是一个存放我们文件的文件夹,我们点击进去点击图片上的上传本地文件操作即可上传你的模型文件。终端就是一个输入命令的地方，<strong>我们点击终端命令，如下图所示。</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4fc533b4a44645a19c95b04380f76afb.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4fc533b4a44645a19c95b04380f76afb.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>我们初始的时候是在系统的根目录下面,我们进行模型训练等操作进入hy-tmp目录也就是你上传文件的目录下面。</p><p>我们利用cd 命令进入hy-tmp目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> hy-tmp</span><br></pre></td></tr></table></figure><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bec73eccac7a47dbbd6af209ab67edee.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bec73eccac7a47dbbd6af209ab67edee.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>进入其中以后，上传我们的文件。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8e52743f93b343bab86ff0e68b67c5dd.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8e52743f93b343bab86ff0e68b67c5dd.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> 可以看到我把YOLOv8的官方下载的压缩包上传了进去，其为zip格式的压缩包。</p><p>此时在命令行输入命令解压缩该文件</p><p>输入unzip 文件名.zip解压文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip 文件名.<span class="built_in">zip</span></span><br></pre></td></tr></table></figure><p>cd到该文件目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> 文件名</span><br></pre></td></tr></table></figure><p>输入ll 看文件目录下的结构 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll</span><br></pre></td></tr></table></figure><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a7ed129b0bf440e3b596b1962f61336a.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a7ed129b0bf440e3b596b1962f61336a.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>这里我们演示的是利用YOLOv8进行目标检测时候的训练流程进行演示,我们进入ultralytics\cfg文件目录利用cd进入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ultralytics\cfg</span><br></pre></td></tr></table></figure><p>同理我们输入ll看该文件下的目录结构</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/1835b338dc514718ae30ecd9bf9229bc.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/1835b338dc514718ae30ecd9bf9229bc.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>可以看到其中有一个default.yaml文件,该文件就是我们进行训练模型的文件,我们可以在左侧的目录下看该文件的代码。 </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/536cbabd66be4ad9aa74729c5ff09b7c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/536cbabd66be4ad9aa74729c5ff09b7c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>当然其中的配置,我就不在这里描述了,如果有需要可以看我的YOLOv8详细训练教程里面有具体的配置以及教程。当我们配置好了数据集以及选择的模型之后就可以在官方的模型基础上进行训练了de。 </p><p>此时我们需要退到ultralytics-main的目录下面执行下面的文件就可以进行训练了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yolo task=detect mode=train model=datasets/yolo8n.yaml  data=datasets/data.yaml epochs=<span class="number">100</span> batch=<span class="number">64</span> device=<span class="number">0</span> single_cls=<span class="literal">True</span> pretrained=yolov8n.pt</span><br></pre></td></tr></table></figure><p>PS：在我们的系统中python解释器已经默认帮我们配置好了,如果你想要执行一个py格式文件，我们只需要输入python  文件名.py文件即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python 文件名.py</span><br></pre></td></tr></table></figure><p>到此本教程就结束,希望对你有所帮助。大家如有任何问题可以在评论区进行提问。 </p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 恒源云 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据集</title>
      <link href="/2024/08/19/article-13/"/>
      <url>/2024/08/19/article-13/</url>
      
        <content type="html"><![CDATA[<p>YoloV8。YoloV8是一种高效的目标检测算法，它的训练需要高质量的数据集。然而，获取高质量的数据集是一项耗时且费力的任务。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ad4f0d35d5a24785bdf9b5d0517be144.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ad4f0d35d5a24785bdf9b5d0517be144.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>YoloV8官方推荐了一个数据集网站，就是Roboflow。Roboflow是一个数据集管理平台，提供了免费的数据集，同时也支持上传自己的数据集进行格式转换。使用Roboflow，开发者可以方便地获取所需格式的数据集，无需手动转换格式。此外，Roboflow还提供了多种数据预处理、数据增强等功能，可帮助开发者更好地优化训练数据，<strong>从下面官方获取的图片上来YOLOv8官方指定的数据集获取网站就是Roboflow。</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f1d1f09f485f423ba47df662c9c4f451.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f1d1f09f485f423ba47df662c9c4f451.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>因此，如果你正在使用YoloV8进行目标检测算法的训练，Roboflow是一个非常好的选择，可以帮助你快速获取高质量的数据集，从而加快训练效率。同时，Roboflow也是YoloV8官方推荐的数据集网站，保证了数据集的质量和可靠性。</p><h3 id="下面首先分享Roboflow的官方地址"><a href="#下面首先分享Roboflow的官方地址" class="headerlink" title="下面首先分享Roboflow的官方地址"></a><strong>下面首先分享Roboflow的官方地址</strong></h3><p><strong><a href="https://roboflow.com/" title="请点击此处跳转">请点击此处跳转</a></strong></p><h3 id="搜索自己想要的数据集流程"><a href="#搜索自己想要的数据集流程" class="headerlink" title="搜索自己想要的数据集流程"></a>搜索自己想要的数据集流程</h3><p>成功利用神秘力量以后并点击连接后会跳转下面的网址,</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2330ab877e144be58a4264f69457bce1.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2330ab877e144be58a4264f69457bce1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>点击Get Started之后如果你没有之前登录过该网站就会跳转登录和注册的页面</p><p><img src="https://img-blog.csdnimg.cn/a054b6098518427d8ecb840d46f7cf63.png" class="lazyload placeholder" data-srcset="https://img-blog.csdnimg.cn/a054b6098518427d8ecb840d46f7cf63.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> 这里有三个登录方式我推荐的是用Google账号也就是第一个选项，点击之后跳转如下界面,</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/83af5512f3b048189a971c3ca94e4bed.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/83af5512f3b048189a971c3ca94e4bed.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>  <strong>如果你有Google账户那么就直接登录即可,如果你没有Google账户那么就需要创建一个账号，点击Create account按照操作流程输入即可需要注意的是这里需要一个手机号验证相比于chatgpt的不同这里的Google账户是可以输入中国的手机号的，但是你用中国手机号注册的账户的Google是登陆不了chatgpt的。</strong></p><p><strong>当注册完账号并登录之后就跳转以下界面</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4116ba4cba7a43feaa3ae597e950bf19.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4116ba4cba7a43feaa3ae597e950bf19.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>在开始之前我们需要创建一个工作组,就是左上角所显示的Workspaces流程如下图所示 </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/18f99ea2585240a68a9be1f457693ef3.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/18f99ea2585240a68a9be1f457693ef3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p> 按照上面操作之后就建立完成了我们的Workspaces</p><p>点击下面图示选项</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/725df3223aaf49aa8f065a60aca9db97.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/725df3223aaf49aa8f065a60aca9db97.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>跳转如下界面</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5b62b21f8616430088b28f006e8ff810.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5b62b21f8616430088b28f006e8ff810.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p> 在上图所示位置输入你想要搜索的数据集**(需要注意的是这里需要输入英文的名称不像Github那样你输入中文名字它可以给你对应搜索中文的，)** </p><p>这里假如我想搜索mask(口罩数据集)他就会跳出一堆数据集提供给你选择</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f9b8fb22d99a48b99393ee39f6eed8a8.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f9b8fb22d99a48b99393ee39f6eed8a8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>我们随便选择一个点击进去</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/d39aeb842f7f47f5a3e411b62f1727cd.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/d39aeb842f7f47f5a3e411b62f1727cd.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> 然后跳出选项框操作流程如下图所示</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/682b82d399054b718f8e0a5c0ca0ac7c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/682b82d399054b718f8e0a5c0ca0ac7c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"> 根据你想要的格式进行选择,然后记得选择Zip格式进行下载到本地(下载到你的浏览器默认下载地址)跳出第三个框即代表你下载完成了。图二中的第二个选项是你进行一些在线训练时候所用的code代码,如果有需要我后期也会出教程，除此之外roboflow还有需要强大的功能如下：</p><ol><li><p>数据增强：Roboflow支持多种数据增强的选项，如旋转、翻转、缩放等，可以帮助开发者扩充数据集，提高模型的泛化能力和准确率。</p></li><li><p>数据预处理：Roboflow提供了多种数据预处理的选项，如去除背景、裁剪、缩放等，可以帮助开发者更好地优化训练数据，提高模型的准确率。</p></li><li><p>数据集管理：Roboflow可以帮助开发者管理数据集，包括上传、下载、删除等操作，方便管理和使用数据集。</p></li><li><p>API支持：Roboflow提供了API支持，可以与其他工具和平台进行集成，方便开发者在不同的应用场景中使用数据集。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> YOLO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> Ultralytics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv8目录结构</title>
      <link href="/2024/08/19/article-3/"/>
      <url>/2024/08/19/article-3/</url>
      
        <content type="html"><![CDATA[<h1 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h1><h2 id="一、本文介绍"><a href="#一、本文介绍" class="headerlink" title="一、本文介绍"></a>一、本文介绍</h2><p>Hello，大家好这次给大家带来的不是改进，<strong>是整个YOLOv8项目的分析</strong>，<strong>整个系列大概会更新7-10篇左右的文章</strong>，从项目的目录到每一个功能代码的都会进行详细的讲解，同时YOLOv8改进系列也突破了三十篇文章，最后预计本专栏持续更新会在年底更新上百篇的改进教程， 所以大家如果没有订阅专栏可以提前订阅以下。下面开始进行YOLOv8逐行解析的第一篇——<strong>项目目录构造分析</strong></p><h2 id="二、项目目录构造分析"><a href="#二、项目目录构造分析" class="headerlink" title="二、项目目录构造分析"></a>二、项目目录构造分析</h2><p>开始之前先把源代码的地址分析给大家-&gt;</p><blockquote><p><strong>官方代码地址：</strong><a href="https://github.com/ultralytics/ultralytics" title="YOLO仓库下载地址">YOLO仓库下载地址</a></p></blockquote><p>下面的图片是我们从仓库上下载整个打开之后的图片，左边的部分是文件，右面呢就是展示窗口。 </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/df2b0cc18959403993dcc63056305aa2.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/df2b0cc18959403993dcc63056305aa2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><strong>下面的是文件部分的清晰截图-&gt;</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/b56eceb48b814fb89370fa557e6da0b6.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/b56eceb48b814fb89370fa557e6da0b6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><strong>下面我们来逐个分析左边的文件各个都是什么作用-&gt;</strong></p><hr><h3 id="2-1-github"><a href="#2-1-github" class="headerlink" title="2.1 .github"></a><strong>2.1 .github</strong></h3><p><strong>该目录包含以下内容：</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/b6f4dfdb894a451289b00660e468521e.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/b6f4dfdb894a451289b00660e468521e.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><blockquote><p>ISSUE_TEMPLATE：提供不同类型的问题报告模板，包括 bug-report.yml、config.yml、feature-request.yml和 question.yml。这些模板帮助用户以结构化的方式报告错误、提出功能请求或提问。  </p></blockquote><blockquote><p>workflows：包含多个工作流文件，如 ci.yml（持续集成）、cla.yml（贡献者许可协议）、codeql.yml（代码质量检查）、docker.yml（Docker配置）、greetings.yml（自动问候新贡献者）、links.yml、publish.yml（自动发布）、stale.yml（处理陈旧问题）。</p></blockquote><p>dependabot.yml（自动依赖更新）</p><p>这些文件共同支持项目的自动化管理，包括代码质量保证、持续集成和部署、社区互动和依赖项维护。</p><hr><h3 id="2-2-docker"><a href="#2-2-docker" class="headerlink" title="2.2  docker"></a>2.2  docker</h3><p><strong>该目录包含以下内容：</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/1b9c076093ff49e6abf177bca6b1ee6b.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/1b9c076093ff49e6abf177bca6b1ee6b.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>docker 目录包含多个 Dockerfile，每个文件都是为不同环境或平台配置的，例如：</p><ul><li>Dockerfile: 主要的Docker配置文件，用于构建项目的默认Docker镜像。</li><li>Dockerfile-arm64: 针对ARM64架构的设备（如某些类型的服务器或高级嵌入式设备）定制的Docker配置。</li><li>Dockerfile-conda: 使用Conda包管理器配置环境的Docker配置文件。</li><li>Dockerfile-cpu: 为不支持GPU加速的环境配置的Docker配置文件。</li><li>Dockerfile-jetson: 专为NVIDIA Jetson平台定制的Docker配置。</li><li>Dockerfile-python: 可能是针对纯Python环境的简化Docker配置。</li><li>Dockerfile-runner: 可能用于配置持续集成&#x2F;持续部署（CI&#x2F;CD）运行环境的Docker配置。</li></ul><p>这些配置文件是用来部署用的，用户可以根据自己的需要选择合适的环境来部署和运行项目。</p><hr><h3 id="2-3-docs"><a href="#2-3-docs" class="headerlink" title="2.3 docs"></a>2.3 docs</h3><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/6895d5eb8af94fa7af4e0d571d845203.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/6895d5eb8af94fa7af4e0d571d845203.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>docs目录通常用于存放文档资料，包括多种语言的翻译。例如，此目录下有多个文件夹，每个文件夹代表一种语言（如en代表英语文档）。除此之外，还有几个重要的Python脚本和配置文件给大家说一下：</p><blockquote><p>build_docs.py：一个Python脚本，用于自动化构建和编译文档的过程。<br>mkdocs.yml：MkDocs配置文件，用于指定文档网站的结构和设置。</p></blockquote><p>以mkdocs_es.yml为例，这是用于构建西班牙语文档的MkDocs配置文件。类似的，mkdocs_zh.yml用于构建中文文档。所以这些文档其实和我们学习YOLOv8没啥太大的关系，<strong>大家了解以下就可以了</strong>。</p><hr><h3 id="2-4-examples"><a href="#2-4-examples" class="headerlink" title="2.4 examples"></a>2.4 examples</h3><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8d4825a9f0e84cdb8e7b664860d1d342.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/8d4825a9f0e84cdb8e7b664860d1d342.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>在examples文件夹中，大家可以找到不同编程语言和平台的YOLOv8实现示例：</p><p>YOLOv8-CPP-Inference：包含C++语言实现的YOLOv8推理示例，内有CMakeLists.txt（用于项目构建的CMake配置文件），inference.cpp和inference.h（推理相关的源代码和头文件），main.cpp（主程序入口）以及README.md（使用说明）。</p><p>YOLOv8-ONNXRuntime：提供Python语言与ONNX Runtime结合使用的YOLOv8推理示例，其中main.py是主要的脚本文件，README.md提供了如何使用该示例的指南。</p><p>YOLOv8-ONNXRuntime-CPP：与上述ONNX Runtime类似，但是是用C++编写的，包含了相应的CMakeLists.txt，inference.cpp，inference.h和main.cpp文件，以及用于解释如何运行示例的README.md。</p><p>每个示例都配有相应的文档，是当我们进行模型部署的时候在不同环境中部署和使用YOLOv8的示例。</p><hr><h3 id="2-5-tests"><a href="#2-5-tests" class="headerlink" title="2.5 tests"></a>2.5 tests</h3><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f0bdd6022b9043bbaad7e85d9b2c2979.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f0bdd6022b9043bbaad7e85d9b2c2979.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>tests目录包含了项目的自动化测试脚本，每个脚本针对项目的不同部分进行测试：</p><p>conftest.py：包含测试配置选项或共享的测试助手函数。<br>test_cli.py：用于测试命令行界面（CLI）的功能和行为。<br>test_cuda.py：专门测试项目是否能正确使用NVIDIA的CUDA技术，确保GPU加速功能正常。<br>test_engine.py：测试底层推理引擎，如模型加载和数据处理等。<br>test_integrations.py：测试项目与其他服务或库的集成是否正常工作。<br>test_python.py：用于测试项目的Python API接口是否按预期工作。</p><p>这些测试脚本确保大家在改进了文件之后更新或添加的新功能后仍能运行的文件。</p><hr><h3 id="2-6-runs"><a href="#2-6-runs" class="headerlink" title="2. 6 runs"></a>2. 6 runs</h3><p>这个文件我们在上面目录构造没有看到是因为，这是我们成功训练了一次模型之后生成的文件，里面保存我们每一次训练之后的各种信息。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2bb4fc2a037047629dc81e480bf7331b.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2bb4fc2a037047629dc81e480bf7331b.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>下面的是训练成功之后的一个完整保存文件:</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bcccc7ee5d5144c08788e20d33166cc1.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bcccc7ee5d5144c08788e20d33166cc1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><hr><h3 id="2-6-utlralytics-重点"><a href="#2-6-utlralytics-重点" class="headerlink" title="2.6 utlralytics(重点)"></a>2.6 utlralytics(重点)</h3><p>上面讲的大部分文件其实对于大部分读者都用不上，这里的<strong>utralytics文件才是重点</strong>，包含了YOLOv8的所有功能都集成在这个文件目录下面，这里我只介绍每一个目录的功能，每一个文件的内部代码我会在接下来的几个博客里面详细的讲到。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0e171e9dca9c48fcb96510e2e6cd8726.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0e171e9dca9c48fcb96510e2e6cd8726.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h4 id="2-6-1-assets"><a href="#2-6-1-assets" class="headerlink" title="2.6.1 assets"></a><strong>2.6.1 assets</strong></h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/87f3ca08eac94fca888baa2f09e60a54.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/87f3ca08eac94fca888baa2f09e60a54.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>这个文件下面保存了YOLO历史上可以说最最最经典的两张图片了，这个是大家用来基础推理时候的图片，给大家测试用的。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e624e36a10ae49b891b8045333ab6f5c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e624e36a10ae49b891b8045333ab6f5c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h4 id="2-6-2-cfg（重点）"><a href="#2-6-2-cfg（重点）" class="headerlink" title="2.6.2 cfg（重点）"></a>2.6.2 cfg（重点）</h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0c08501716d94128a14644311c8accf7.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0c08501716d94128a14644311c8accf7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>这个文件下面保存了我们的模型配置文件，cfg目录是项目配置的集中地，其中包括：</p><p><strong>datasets文件夹</strong>：包含数据集的配置文件，如数据路径、类别信息等（就是我们训练YOLO模型的时候需要一个数据集，这里面就保存部分数据集的yaml文件，如果我们训练的时候没有指定数据集则会自动下载其中的数据集文件，但是很容易失败！）。<br><strong>models文件夹</strong>：存放模型配置文件，定义了模型结构和训练参数等，这个是我们改进或者就基础版本的一个yaml文件配置的地方，截图如下:</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c7117aced6e44708a1df19915508c59d.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c7117aced6e44708a1df19915508c59d.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>models文件夹中的每个.yaml文件代表了不同的YOLOv8模型配置，具体包括：</p><p><strong>yolov8.yaml:</strong>   这是YOLOv8模型的标准配置文件，定义了模型的基础架构和参数。<br><strong>yolov8-cls.yaml:</strong> 配置文件调整了YOLOv8模型，专门用于图像分类任务。<br><strong>yolov8-ghost.yaml:</strong> 应用Ghost模块的YOLOv8变体，旨在提高计算效率。<br><strong>yolov8-ghost-p2.yaml 和 yolov8-ghost-p6.yaml:</strong> 这些文件是针对特定大小输入的Ghost模型变体配置。<br><strong>yolov8-p2.yaml和 yolov8-p6.yaml:</strong> 针对不同处理级别（例如不同的输入分辨率或模型深度）的YOLOv8模型配置。<br><strong>yolov8-pose.yaml:</strong> 为姿态估计任务定制的YOLOv8模型配置。<br><strong>yolov8-pose-p6.yaml:</strong> 针对更大的输入分辨率或更复杂的模型架构姿态估计任务。<br><strong>yolov8-rtdetr.yaml:</strong> 可能表示实时检测和跟踪的YOLOv8模型变体。<br><strong>yolov8-seg.yaml 和 yolov8-seg-p6.yaml:</strong> 这些是为语义分割任务定制的YOLOv8模型配置。</p><p>这些配置文件是模型训练和部署的核心，同时大家如果进行改进也是修改其中的对应文件来优化 网络结构。</p><p><strong>trackers文件夹</strong>：用于追踪算法的配置。<br><strong>__init__.py文件</strong>：表明`cfg`是一个Python包。<br><strong>default.yaml</strong>：项目的默认配置文件，包含了被多个模块共享的通用配置项。</p><p>这个文件就是配置训练的时候进行用的然后一些任务选择部分</p><h4 id="2-6-3-data"><a href="#2-6-3-data" class="headerlink" title="2.6.3 data"></a>2.6.3 data</h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/dc76024ccabc4de3982b1e7f37620708.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/dc76024ccabc4de3982b1e7f37620708.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>在data&#x2F;scripts文件夹中，包括了一系列脚本和Python文件：</p><p>- download_weights.sh: 用来下载预训练权重的脚本。<br>- get_coco.sh, get_coco128.sh, get_imagenet.sh: 用于下载COCO数据集完整版、128张图片版以及ImageNet数据集的脚本。<br>  <br><strong>在data文件夹中，包括：</strong></p><p><strong>annotator.py:</strong> 用于数据注释的工具。<br><strong>augment.py:</strong> 数据增强相关的函数或工具。<br><strong>base.py, build.py, converter.py:</strong> 包含数据处理的基础类或函数、构建数据集的脚本以及数据格式转换工具。<br><strong>dataset.py:</strong> 数据集加载和处理的相关功能。<br><strong>loaders.py:</strong> 定义加载数据的方法。<br><strong>utils.py:</strong> 各种数据处理相关的通用工具函数。</p><h4 id="2-6-4-engine"><a href="#2-6-4-engine" class="headerlink" title="2.6.4  engine"></a>2.6.4  engine</h4><p>engine文件夹包含与模型训练、评估和推理有关的核心代码：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/7800024fbeae41cc8f009745c4101fc5.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/7800024fbeae41cc8f009745c4101fc5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><strong>exporter.py:</strong> 用于将训练好的模型导出到其他格式，例如ONNX或TensorRT。<br><strong>model.py:</strong> 包含模型定义，还包括模型初始化和加载的方法。<br><strong>predictor.py:</strong> 包含推理和预测的逻辑，如加载模型并对输入数据进行预测。<br><strong>results.py:</strong> 用于存储和处理模型输出的结果。<br><strong>trainer.py:</strong> 包含模型训练过程的逻辑。<br><strong>tuner.py:</strong> 用于模型超参数调优。<br><strong>validator.py:</strong> 包含模型验证的逻辑，如在验证集上评估模型性能。</p><h4 id="2-6-5-hub"><a href="#2-6-5-hub" class="headerlink" title="2.6.5 hub"></a>2.6.5 hub</h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5942a5cb41504caaa71e9d1017c6b0bb.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5942a5cb41504caaa71e9d1017c6b0bb.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>hub文件夹通常用于处理与平台或服务集成相关的操作，包括：</p><p><strong>auth.py:</strong> 处理认证流程，如API密钥验证或OAuth流程。<br><strong>session.py:</strong> 管理会话，包括创建和维护持久会话。<br><strong>utils.py:</strong> 包含一些通用工具函数，可能用于支持认证和会话管理功能。</p><h4 id="2-6-6-models-重点"><a href="#2-6-6-models-重点" class="headerlink" title="2.6.6 models(重点)"></a>2.6.6 models(重点)</h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e29f4a22943e4ce7ad1cc84b247d99e3.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e29f4a22943e4ce7ad1cc84b247d99e3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>这个目录下面是YOLO仓库包含的一些模型的方法实现，我们这里之说YOLO的，同时这里只是简单介绍，后面的博客针对于其中的任意一个都会进行单独的讲解。</p><p>这个models&#x2F;yolo目录中包含了YOLO模型的不同任务特定实现：</p><p><strong>classify:</strong> 这个目录可能包含用于图像分类的YOLO模型。<br><strong>detect:</strong> 包含用于物体检测的YOLO模型。<br><strong>pose:</strong> 包含用于姿态估计任务的YOLO模型。<br><strong>segment:</strong> 包含用于图像分割的YOLO模型，</p><h4 id="2-6-7-nn-重点"><a href="#2-6-7-nn-重点" class="headerlink" title="2.6.7 nn(重点)"></a>2.6.7 nn(重点)</h4><p>这个文件目录下的所有文件，就是定义我们模型中的一些组成构建，之后我们进行改进和优化，增加其它结构的时候都要在对应的文件下面进行改动。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/22a54c754e424b2d808cc532e7a23c47.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/22a54c754e424b2d808cc532e7a23c47.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><strong>modules文件夹:</strong><br>   <strong>__init__.py:</strong> 表明此目录是Python包。<br>   <strong>block.py:</strong> 包含定义神经网络中的基础块，如残差块或瓶颈块。<br>   <strong>conv.py:</strong> 包含卷积层相关的实现。<br>   <strong>head.py:</strong> 定义网络的头部，用于预测。<br>   <strong>transformer.py:</strong> 包含Transformer模型相关的实现。<br>   <strong>utils.py:</strong> 提供构建神经网络时可能用到的辅助函数。</p><p><strong>__init__.py:</strong> 同样标记这个目录为Python包。</p><p><strong>autobackend.py:</strong> 用于自动选择最优的计算后端。</p><p><strong>tasks.py</strong>: 定义了使用神经网络完成的不同任务的流程，例如分类、检测或分割，所有的流程基本上都定义在这里，定义模型前向传播都在这里。</p><h4 id="2-6-8-solutions"><a href="#2-6-8-solutions" class="headerlink" title="2.6.8 solutions"></a>2.6.8 solutions</h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/b4b0a147cae94419b8e094c2d0c2c6e9.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/b4b0a147cae94419b8e094c2d0c2c6e9.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><strong>__init__.py:</strong> 标识这是一个Python包。<br><strong>ai_gym.py:</strong> 与强化学习相关，例如在OpenAI Gym环境中训练模型的代码。<br><strong>heatmap.py:</strong> 用于生成和处理热图数据，这在物体检测和事件定位中很常见。<br><strong>object_counter.py:</strong> 用于物体计数的脚本，包含从图像中检测和计数实例的逻辑。</p><h4 id="2-6-9-trackers"><a href="#2-6-9-trackers" class="headerlink" title="2.6.9 trackers"></a>2.6.9 trackers</h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/db2b42c30d7c4db29f9fc02b3c114c47.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/db2b42c30d7c4db29f9fc02b3c114c47.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><strong>trackers</strong>文件夹包含了实现目标跟踪功能的脚本和模块：</p><p><strong>__init__.py:</strong> 指示该文件夹是一个Python包。<br><strong>basetrack.py:</strong> 包含跟踪器的基础类或方法。<br><strong>bot_sort.py:</strong> 实现了SORT算法（Simple Online and Realtime Tracking）的版本。<br><strong>byte_tracker.py:</strong> 是一个基于深度学习的跟踪器，使用字节为单位跟踪目标。<br><strong>track.py:</strong> 包含跟踪单个或多个目标的具体逻辑。<br><strong>README.md:</strong> 提供该目录内容和用法的说明。</p><h4 id="2-6-10-utils"><a href="#2-6-10-utils" class="headerlink" title="2.6.10 utils"></a>2.6.10 utils</h4><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/7267573c5a5940a796e373dbdbcda494.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/7267573c5a5940a796e373dbdbcda494.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>这个utils目录包含了多个Python脚本，每个脚本都有特定的功能：</p><p><strong>callbacks.py:</strong> 包含在训练过程中被调用的回调函数。<br><strong>autobatch.py:</strong> 用于实现批处理优化，以提高训练或推理的效率。<br><strong>benchmarks.py:</strong> 包含性能基准测试相关的函数。<br><strong>checks.py</strong>: 用于项目中的各种检查，如参数验证或环境检查。<br><strong>dist.py:</strong> 涉及分布式计算相关的工具。<br><strong>downloads.py:</strong> 包含下载数据或模型等资源的脚本。<br><strong>errors.py:</strong> 定义错误处理相关的类和函数。<br><strong>files.py:</strong> 包含文件操作相关的工具函数。<br><strong>instance.py:</strong> 包含实例化对象或模型的工具。<br><strong>loss.py:</strong> 定义损失函数。<br><strong>metrics.py:</strong> 包含评估模型性能的指标计算函数。<br><strong>ops.py:</strong> 包含自定义操作，如特殊的数学运算或数据转换。<br><strong>patches.py:</strong> 用于实现修改或补丁应用的工具。<br><strong>plotting.py:</strong> 包含数据可视化相关的绘图工具。<br><strong>tal.py:</strong> 一些损失函数的功能应用<br><strong>torch_utils.py:</strong> 提供PyTorch相关的工具和辅助函数，包括GFLOPs的计算。<br><strong>triton.py:</strong> 可能与NVIDIA Triton Inference Server集成相关。<br><strong>tuner.py:</strong> 包含模型或算法调优相关的工具。</p><p><strong>到这里重点的ultralytics文件目录下的所有功能都介绍完毕了，这里只是简单的介绍，后面的博客会详细的介绍一些重要的功能。</strong></p><hr><h3 id="2-7-同级目录下的文件"><a href="#2-7-同级目录下的文件" class="headerlink" title="2.7 同级目录下的文件"></a>2.7 同级目录下的文件</h3><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/91ff9a17779d4019ada156f9fca35155.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/91ff9a17779d4019ada156f9fca35155.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><strong>这个里是项目的根本配置和文档文件：</strong></p><p><strong>.gitignore:</strong> Git配置文件，指定了Git版本控制要忽略的文件。<br><strong>.pre-commit-config.yaml:</strong> 预提交钩子的配置文件，用于在提交前自动执行代码质量检查。<br><strong>CITATION.cff:</strong> 提供了如何引用该项目的格式说明。<br><strong>CONTRIBUTING.md:</strong> 说明如何为项目贡献代码的指南。<br><strong>LICENSE:</strong> 包含了项目的许可证信息。<br><strong>MANIFEST.in:</strong> 列出了在构建和分发Python包时需要包含的文件。<br><strong>README.md 和 README.zh-CN.md:</strong> 项目的说明文件，分别为英文和中文版本。<br><strong>requirements.txt:</strong> 列出了项目运行所需的Python依赖。<br><strong>setup.cfg 和 setup.py:</strong> 包含了设置项目安装和分发的脚本。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv8文件分析</title>
      <link href="/2024/08/19/article-4/"/>
      <url>/2024/08/19/article-4/</url>
      
        <content type="html"><![CDATA[<h1 id="文件分析"><a href="#文件分析" class="headerlink" title="文件分析"></a>文件分析</h1><h2 id="一、本文介绍"><a href="#一、本文介绍" class="headerlink" title="一、本文介绍"></a>一、本文介绍</h2><p>本文给大家带来的是<strong>YOLOv8项目的解读</strong>，之前给大家分析了YOLOv8的项目文件分析，这一篇文章给大家带来的是模型训练从我们的yaml文件定义到模型的定义部分的讲解，我们一般只知道如何去训练模型，和配置yaml文件，但是对于yaml文件是如何输入到模型里，模型如何将yaml文件解析出来的确是不知道的，本文的内容接上一篇的代码逐行解析(一) 项目目录分析，本文对于小白来说非常友好，非常推荐大家进行阅读，深度的了解模型的工作原理已经流程，下面我们从yaml文件来讲解。</p><p>本文的讲解全部在代码的对应位置进行注释介绍非常详细，<strong>以下为部分内容的截图。</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/591c0efe630e4e51b8059bf9e8b197c6.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/591c0efe630e4e51b8059bf9e8b197c6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="591c0efe630e4e51b8059bf9e8b197c6.png"></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/af9d4d78be4d448a98554c9265832fb0.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/af9d4d78be4d448a98554c9265832fb0.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="af9d4d78be4d448a98554c9265832fb0.png"></p><hr><h2 id="二、yaml文件的定义"><a href="#二、yaml文件的定义" class="headerlink" title="二、yaml文件的定义"></a>二、yaml文件的定义</h2><p>我们训练模型的第一步是需要配置yaml文件，我们的讲解第一步也从yaml文件来开始讲解，YOLOv8的yaml文件存放在我们的如下目录内’ultralytics&#x2F;cfg&#x2F;models&#x2F;v8’，在其中我们可以定义各种模型配置的文件组合不同的模块，我们拿最基础的YOLOv8yaml文件来讲解一下。</p><p><strong>注释部分的内容我就不介绍了，我只介绍一下其中有用的部分，我已经在代码中对应的位置注释上了解释，大家可以看这样看起来也直观一些。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Ultralytics YOLO 🚀, AGPL-3.0 license</span></span><br><span class="line"><span class="comment"># YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">nc: <span class="number">80</span>  <span class="comment"># 数据集的类别数，我们默认的数据COCO是80类别（YOLOv8提供的权重也是由此数据集训练出来的），有的读者喜欢修改nc此处其实不需要修改，</span></span><br><span class="line">        <span class="comment"># 模型会自动根据我们数据集的yaml文件获取此处的数量，同时我们8.1版本之前的ultralytics仓库打印两边的网络结构，唯一的区别就是nc的数量不一样（实际运行的是第二遍的网络结构）。</span></span><br><span class="line"> </span><br><span class="line">scales:  <span class="comment"># model compound scaling constants, i.e. &#x27;model=yolov8n.yaml&#x27; will call yolov8.yaml with scale &#x27;n&#x27;</span></span><br><span class="line">         <span class="comment"># 此处的含义大概就是如果我们在训练的指令时候使用model=yolov8.yaml 则对应的是v8n，如果使用model=yolov8s.yaml则对应的是v8s</span></span><br><span class="line">         <span class="comment"># 当然了大家如果不想使用上面的方式指定模型，我们只需要将下面想要使用的模型移到最前端即可，或者将其余不想用的注释掉都可以。</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment"># [depth, width, max_channels]</span></span><br><span class="line">  n: [<span class="number">0.33</span>, <span class="number">0.25</span>, <span class="number">1024</span>]  <span class="comment"># YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs</span></span><br><span class="line">  s: [<span class="number">0.33</span>, <span class="number">0.50</span>, <span class="number">1024</span>]  <span class="comment"># YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs</span></span><br><span class="line">  m: [<span class="number">0.67</span>, <span class="number">0.75</span>, <span class="number">768</span>]   <span class="comment"># YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs</span></span><br><span class="line">  l: [<span class="number">1.00</span>, <span class="number">1.00</span>, <span class="number">512</span>]   <span class="comment"># YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs</span></span><br><span class="line">  x: [<span class="number">1.00</span>, <span class="number">1.25</span>, <span class="number">512</span>]   <span class="comment"># YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># YOLOv8.0n backbone (主干部分的配置)</span></span><br><span class="line">backbone:</span><br><span class="line">  <span class="comment"># [from, repeats, module, args]</span></span><br><span class="line">  <span class="comment"># 这里需要多介绍一下，from, repeats, module, args</span></span><br><span class="line">  <span class="comment"># from 此处有三种可能的值分别是 -1、具体的数值、list存放数值。分别含义如下  (1)、-1的含义就是代表此层的输入就是上一层的输出，</span></span><br><span class="line">  <span class="comment">#                                                                (2)、如果是具体的某个数字比如4那么则代表本层的输入来自于模型的第四层，</span></span><br><span class="line">  <span class="comment">#                                                                (3)、有的层是list存放两个值也可能是多个值，则代表对应两个值的输出为本层的输入</span></span><br><span class="line">  <span class="comment"># repeats 这个参数是为了C2f设置的其它的模块都用不到，代表着C2f当中Bottleneck重复的次数，比如当我们的模型用的是l的时候，那么repeats=3那么则代表C2f当中的Bottleneck串行3个。</span></span><br><span class="line">  <span class="comment"># module 此处则代表模型的名称</span></span><br><span class="line">  <span class="comment"># args 此处代表输入到对应模块的参数，此处和parse_model函数中的定义方法有关，对于C2f来说传入的参数-&gt;第一个参数是上一个模型的输出通道数，第二个参数就是args的第一个参数，然后以此类推。</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">64</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 0-P1/2</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 1-P2/4</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">128</span>, <span class="literal">True</span>]]</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 3-P3/8</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">6</span>, C2f, [<span class="number">256</span>, <span class="literal">True</span>]]</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 5-P4/16</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">6</span>, C2f, [<span class="number">512</span>, <span class="literal">True</span>]]</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">1024</span>, <span class="number">3</span>, <span class="number">2</span>]]  <span class="comment"># 7-P5/32</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">1024</span>, <span class="literal">True</span>]]</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, SPPF, [<span class="number">1024</span>, <span class="number">5</span>]]  <span class="comment"># 9</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># YOLOv8.0n head</span></span><br><span class="line">head:</span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]]</span><br><span class="line">  - [[-<span class="number">1</span>, <span class="number">6</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]]  <span class="comment"># cat backbone P4</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">512</span>]]  <span class="comment"># 12</span></span><br><span class="line"> </span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, nn.Upsample, [<span class="literal">None</span>, <span class="number">2</span>, <span class="string">&#x27;nearest&#x27;</span>]]</span><br><span class="line">  - [[-<span class="number">1</span>, <span class="number">4</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]]  <span class="comment"># cat backbone P3</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">256</span>]]  <span class="comment"># 15 (P3/8-small)</span></span><br><span class="line"> </span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>]]</span><br><span class="line">  - [[-<span class="number">1</span>, <span class="number">12</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]]  <span class="comment"># cat head P4</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">512</span>]]  <span class="comment"># 18 (P4/16-medium)</span></span><br><span class="line"> </span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">1</span>, Conv, [<span class="number">512</span>, <span class="number">3</span>, <span class="number">2</span>]]</span><br><span class="line">  - [[-<span class="number">1</span>, <span class="number">9</span>], <span class="number">1</span>, Concat, [<span class="number">1</span>]]  <span class="comment"># cat head P5</span></span><br><span class="line">  - [-<span class="number">1</span>, <span class="number">3</span>, C2f, [<span class="number">1024</span>]]  <span class="comment"># 21 (P5/32-large)</span></span><br><span class="line"> </span><br><span class="line">  - [[<span class="number">15</span>, <span class="number">18</span>, <span class="number">21</span>], <span class="number">1</span>, Detect, [nc]]  <span class="comment"># Detect(P3, P4, P5)</span></span><br></pre></td></tr></table></figure><p>其中的Conv和C2f的结构我就不过多解释了，网上教程已经很多了，其中详细的结构在下图中都能够看到。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/de838aaf62ff43df9cf3a6786cb1ec8f.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/de838aaf62ff43df9cf3a6786cb1ec8f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="de838aaf62ff43df9cf3a6786cb1ec8f.png"></p><hr><h2 id="三、yaml文件的输入"><a href="#三、yaml文件的输入" class="headerlink" title="三、yaml文件的输入 "></a>三、yaml文件的输入 </h2><p>上面我们解释了yaml文件中的参数含义，然后提供了一个结构图（其中能够获取到每个模块的详细结构，该结构图来源于官方）。然后我们下一步介绍当定义好了一个ymal文件其是如何传入到模型的内部的，模型的开始在哪里。</p><h3 id="3-1-模型的定义"><a href="#3-1-模型的定义" class="headerlink" title="3.1 模型的定义"></a>3.1 模型的定义</h3><p>我们通过命令行的命令或者创建py文件运行模型之后，模型最开始的工作是模型的定义操作。模型存放于文件’ultralytics&#x2F;engine&#x2F;model.py’内部，首先需要通过’__init__‘来定义模型的一些变量。</p><p><strong>此处我将模型的定义部分的代码解释了一下，大家有兴趣的可以和自己的文件对比着看。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        一个统一所有模型API的基类。</span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            model (str, Path): 要加载或创建的模型文件的路径。</span></span><br><span class="line"><span class="string">            task (Any, 可选): YOLO模型的任务类型。默认为None。</span></span><br><span class="line"><span class="string">        属性:</span></span><br><span class="line"><span class="string">            predictor (Any): 预测器对象。</span></span><br><span class="line"><span class="string">            model (Any): 模型对象。</span></span><br><span class="line"><span class="string">            trainer (Any): 训练器对象。</span></span><br><span class="line"><span class="string">            task (str): 模型任务类型。</span></span><br><span class="line"><span class="string">            ckpt (Any): 如果从*.pt文件加载的模型，则为检查点对象。</span></span><br><span class="line"><span class="string">            cfg (str): 如果从*.yaml文件加载的模型，则为模型配置。</span></span><br><span class="line"><span class="string">            ckpt_path (str): 检查点文件路径。</span></span><br><span class="line"><span class="string">            overrides (dict): 训练器对象的覆盖。</span></span><br><span class="line"><span class="string">            metrics (Any): 用于度量的数据。</span></span><br><span class="line"><span class="string">        方法:</span></span><br><span class="line"><span class="string">            __call__(source=None, stream=False, **kwargs):</span></span><br><span class="line"><span class="string">                预测方法的别名。</span></span><br><span class="line"><span class="string">            _new(cfg:str, verbose:bool=True) -&gt; None:</span></span><br><span class="line"><span class="string">                初始化一个新模型，并从模型定义中推断任务类型。</span></span><br><span class="line"><span class="string">            _load(weights:str, task:str=&#x27;&#x27;) -&gt; None:</span></span><br><span class="line"><span class="string">                初始化一个新模型，并从模型头中推断任务类型。</span></span><br><span class="line"><span class="string">            _check_is_pytorch_model() -&gt; None:</span></span><br><span class="line"><span class="string">                如果模型不是PyTorch模型，则引发TypeError。</span></span><br><span class="line"><span class="string">            reset() -&gt; None:</span></span><br><span class="line"><span class="string">                重置模型模块。</span></span><br><span class="line"><span class="string">            info(verbose:bool=False) -&gt; None:</span></span><br><span class="line"><span class="string">                记录模型信息。</span></span><br><span class="line"><span class="string">            fuse() -&gt; None:</span></span><br><span class="line"><span class="string">                为了更快的推断，融合模型。</span></span><br><span class="line"><span class="string">            predict(source=None, stream=False, **kwargs) -&gt; List[ultralytics.engine.results.Results]:</span></span><br><span class="line"><span class="string">                使用YOLO模型进行预测。</span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">            list(ultralytics.engine.results.Results): 预测结果。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model: <span class="type">Union</span>[<span class="built_in">str</span>, Path] = <span class="string">&quot;yolov8n.pt&quot;</span>, task=<span class="literal">None</span>, verbose=<span class="literal">False</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Initializes the YOLO model.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            model (Union[str, Path], optional): Path or name of the model to load or create. Defaults to &#x27;yolov8n.pt&#x27;.</span></span><br><span class="line"><span class="string">            task (Any, optional): Task type for the YOLO model. Defaults to None.</span></span><br><span class="line"><span class="string">            verbose (bool, optional): Whether to enable verbose mode.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        此处为上面的解释</span></span><br><span class="line"><span class="string">               初始化 YOLO 模型。</span></span><br><span class="line"><span class="string">               参数:</span></span><br><span class="line"><span class="string">                   model (Union[str, Path], 可选): 要加载或创建的模型的路径或名称。默认为&#x27;yolov8n.pt&#x27;。</span></span><br><span class="line"><span class="string">                   task (Any, 可选): YOLO 模型的任务类型。默认为 None。</span></span><br><span class="line"><span class="string">                   verbose (bool, 可选): 是否启用详细模式。</span></span><br><span class="line"><span class="string">               &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="string">&quot;&quot;&quot;此处就是读取我们的yaml文件的地方，callbacks.get_default_callbacks()会将我们的yaml文件进行解析然后将名称返回回来存放在self.callbacks中&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.callbacks = callbacks.get_default_callbacks()</span><br><span class="line">        <span class="string">&quot;&quot;&quot; 下面的部分就是一些模型的参数定义，我大概解释了一下，大家其实也不用太了解，一篇文章也介绍不了太多&quot;&quot;&quot;</span></span><br><span class="line"> </span><br><span class="line">        <span class="variable language_">self</span>.predictor = <span class="literal">None</span>  <span class="comment"># 重用预测器</span></span><br><span class="line">        <span class="variable language_">self</span>.model = <span class="literal">None</span>  <span class="comment"># 模型对象</span></span><br><span class="line">        <span class="variable language_">self</span>.trainer = <span class="literal">None</span>  <span class="comment"># 训练器对象</span></span><br><span class="line">        <span class="variable language_">self</span>.ckpt = <span class="literal">None</span>  <span class="comment"># 如果从*.pt文件加载的检查点对象</span></span><br><span class="line">        <span class="variable language_">self</span>.cfg = <span class="literal">None</span>  <span class="comment"># 如果从*.yaml文件加载的模型配置</span></span><br><span class="line">        <span class="variable language_">self</span>.ckpt_path = <span class="literal">None</span>  <span class="comment"># 检查点文件路径</span></span><br><span class="line">        <span class="variable language_">self</span>.overrides = &#123;&#125;  <span class="comment"># 训练器对象的覆盖设置</span></span><br><span class="line">        <span class="variable language_">self</span>.metrics = <span class="literal">None</span>  <span class="comment"># 验证/训练指标</span></span><br><span class="line">        <span class="variable language_">self</span>.session = <span class="literal">None</span>  <span class="comment"># HUB 会话</span></span><br><span class="line">        <span class="variable language_">self</span>.task = task  <span class="comment"># 任务类型</span></span><br><span class="line">        <span class="variable language_">self</span>.model_name = model = <span class="built_in">str</span>(model).strip()  <span class="comment"># 去除空格</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 检查是否为来自 https://hub.ultralytics.com 的 Ultralytics HUB 模型</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.is_hub_model(model):</span><br><span class="line">            <span class="comment"># 从 HUB 获取模型</span></span><br><span class="line">            checks.check_requirements(<span class="string">&quot;hub-sdk&gt;0.0.2&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.session = <span class="variable language_">self</span>._get_hub_session(model)</span><br><span class="line">            model = <span class="variable language_">self</span>.session.model_file</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 检查是否为 Triton 服务器模型</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>.is_triton_model(model):</span><br><span class="line">            <span class="variable language_">self</span>.model = model</span><br><span class="line">            <span class="variable language_">self</span>.task = task</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 加载或创建新的 YOLO 模型</span></span><br><span class="line">        model = checks.check_model_file_from_stem(model)  <span class="comment"># 添加后缀，例如 yolov8n -&gt; yolov8n.pt</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; 此处比较重要,如果我们没有指定模型的权重.pt那么模型会根据yaml文件创建一个新的模型，如果指定了权重那么模型这回加载pt文件中的模型&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> Path(model).suffix <span class="keyword">in</span> (<span class="string">&quot;.yaml&quot;</span>, <span class="string">&quot;.yml&quot;</span>):</span><br><span class="line">            <span class="variable language_">self</span>._new(model, task=task, verbose=verbose)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>._load(model, task=task)</span><br><span class="line"> </span><br><span class="line">        <span class="variable language_">self</span>.model_name = model <span class="comment"># 返回的模型则保存在self.model_name中</span></span><br></pre></td></tr></table></figure><hr><h3 id="3-2-模型的训练"><a href="#3-2-模型的训练" class="headerlink" title="3.2 模型的训练"></a>3.2 模型的训练</h3><p>我们上面讲完了模型的定义，然后模型就会根据你指定的参数来进行调用对应的函数，比如我这里指定的是detect，和train，如下图所示，然后模型就会根据指定的参数进行对应任务的训练。</p><p><strong>图片来源于文件’ultralytics&#x2F;cfg&#x2F;default.yaml’ 截图。</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ba833c58a10243b7b3a30fdc9c137c3e.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ba833c58a10243b7b3a30fdc9c137c3e.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="ba833c58a10243b7b3a30fdc9c137c3e.png"></p><p>此处执行的是ultralytics&#x2F;engine&#x2F;model.py’文件中class Model(nn.Module):类别的def train(self, trainer&#x3D;None, **kwargs):函数，具体的解释我已经在代码中标记了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, trainer=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在给定的数据集上训练模型。</span></span><br><span class="line"><span class="string">参数:</span></span><br><span class="line"><span class="string">    trainer (BaseTrainer, 可选): 自定义的训练器。</span></span><br><span class="line"><span class="string">    **kwargs (Any): 表示训练配置的任意数量的参数。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="variable language_">self</span>._check_is_pytorch_model()  <span class="comment"># 检查模型是否为 PyTorch 模型</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>.session, <span class="string">&quot;model&quot;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.session.model.<span class="built_in">id</span>:  <span class="comment"># Ultralytics HUB session with loaded model</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">any</span>(kwargs):</span><br><span class="line">        LOGGER.warning(<span class="string">&quot;WARNING ⚠️ 使用 HUB 训练参数，忽略本地训练参数。&quot;</span>)</span><br><span class="line">    kwargs = <span class="variable language_">self</span>.session.train_args  <span class="comment"># 覆盖 kwargs</span></span><br><span class="line"> </span><br><span class="line">checks.check_pip_update_available()  <span class="comment"># 检查 pip 是否有更新</span></span><br><span class="line"> </span><br><span class="line">overrides = yaml_load(checks.check_yaml(kwargs[<span class="string">&quot;cfg&quot;</span>])) <span class="keyword">if</span> kwargs.get(<span class="string">&quot;cfg&quot;</span>) <span class="keyword">else</span> <span class="variable language_">self</span>.overrides</span><br><span class="line">custom = &#123;<span class="string">&quot;data&quot;</span>: DEFAULT_CFG_DICT[<span class="string">&quot;data&quot;</span>] <span class="keyword">or</span> TASK2DATA[<span class="variable language_">self</span>.task]&#125;  <span class="comment"># 方法的默认设置</span></span><br><span class="line">args = &#123;**overrides, **custom, **kwargs, <span class="string">&quot;mode&quot;</span>: <span class="string">&quot;train&quot;</span>&#125;  <span class="comment"># 最高优先级的参数在右侧</span></span><br><span class="line"><span class="keyword">if</span> args.get(<span class="string">&quot;resume&quot;</span>):</span><br><span class="line">    args[<span class="string">&quot;resume&quot;</span>] = <span class="variable language_">self</span>.ckpt_path</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 实例化或加载训练器</span></span><br><span class="line"><span class="string">&quot;&quot;&quot; 此处将一些参数加载到模型的内部&quot;&quot;&quot;</span></span><br><span class="line"><span class="variable language_">self</span>.trainer = (trainer <span class="keyword">or</span> <span class="variable language_">self</span>._smart_load(<span class="string">&quot;trainer&quot;</span>))(overrides=args, _callbacks=<span class="variable language_">self</span>.callbacks)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> args.get(<span class="string">&quot;resume&quot;</span>):  <span class="comment"># 仅在不续训的时候手动设置模型</span></span><br><span class="line">    <span class="comment"># 获取模型并设置训练器</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    此处比较重要,为开始定义我们的对应任务的模型了比如我这里task设置的为Detect,那么此处会实例化DetectModel模型。</span></span><br><span class="line"><span class="string">    模型存放在ultralytics/nn/tasks.py内（就是我们修改模型时候的用到的那个task.py文件）</span></span><br><span class="line"><span class="string">    此处就会跳转到&#x27;ultralytics/nn/tasks.py&#x27;文化内的class DetectionModel(BaseModel):类中进行初始化和模型的定义工作</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="variable language_">self</span>.trainer.model = <span class="variable language_">self</span>.trainer.get_model(weights=<span class="variable language_">self</span>.model <span class="keyword">if</span> <span class="variable language_">self</span>.ckpt <span class="keyword">else</span> <span class="literal">None</span>, cfg=<span class="variable language_">self</span>.model.yaml)</span><br><span class="line">    <span class="variable language_">self</span>.model = <span class="variable language_">self</span>.trainer.model</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> SETTINGS[<span class="string">&quot;hub&quot;</span>] <span class="keyword">is</span> <span class="literal">True</span> <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.session:</span><br><span class="line">        <span class="comment"># 如果开启了 HUB 并且没有 HUB 会话</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 创建一个 HUB 中的模型</span></span><br><span class="line">            <span class="variable language_">self</span>.session = <span class="variable language_">self</span>._get_hub_session(<span class="variable language_">self</span>.model_name)</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.session:</span><br><span class="line">                <span class="variable language_">self</span>.session.create_model(args)</span><br><span class="line">                <span class="comment"># 检查模型是否创建成功</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">getattr</span>(<span class="variable language_">self</span>.session.model, <span class="string">&quot;id&quot;</span>, <span class="literal">None</span>):</span><br><span class="line">                    <span class="variable language_">self</span>.session = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">except</span> (PermissionError, ModuleNotFoundError):</span><br><span class="line">            <span class="comment"># 忽略 PermissionError 和 ModuleNotFoundError，表示 hub-sdk 未安装</span></span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将可选的 HUB 会话附加到训练器</span></span><br><span class="line"><span class="variable language_">self</span>.trainer.hub_session = <span class="variable language_">self</span>.session</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 进行模型训练</span></span><br><span class="line"><span class="variable language_">self</span>.trainer.train()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 训练结束后更新模型和配置信息</span></span><br><span class="line"><span class="keyword">if</span> RANK <span class="keyword">in</span> (-<span class="number">1</span>, <span class="number">0</span>):</span><br><span class="line">    ckpt = <span class="variable language_">self</span>.trainer.best <span class="keyword">if</span> <span class="variable language_">self</span>.trainer.best.exists() <span class="keyword">else</span> <span class="variable language_">self</span>.trainer.last</span><br><span class="line">    <span class="variable language_">self</span>.model, _ = attempt_load_one_weight(ckpt)</span><br><span class="line">    <span class="variable language_">self</span>.overrides = <span class="variable language_">self</span>.model.args</span><br><span class="line">    <span class="variable language_">self</span>.metrics = <span class="built_in">getattr</span>(<span class="variable language_">self</span>.trainer.validator, <span class="string">&quot;metrics&quot;</span>, <span class="literal">None</span>)  <span class="comment"># <span class="doctag">TODO:</span> DDP 模式下没有返回指标</span></span><br><span class="line"><span class="keyword">return</span> <span class="variable language_">self</span>.metrics</span><br></pre></td></tr></table></figure><hr><h3 id="3-3-模型的网络结构打印"><a href="#3-3-模型的网络结构打印" class="headerlink" title="3.3 模型的网络结构打印"></a>3.3 模型的网络结构打印</h3><p>第三步比较重要的就是来到了’ultralytics&#x2F;nn&#x2F;tasks.py’（就是我们改进模型时候的那个文件）文化内的class DetectionModel(BaseModel):类中进行初始化和模型的定义工作。</p><p>这里涉及到了模型的定义和校验工作（在模型的正式开始训练之前检测模型是否能够运行的工作！）。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DetectionModel</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;YOLOv8 目标检测模型。&quot;&quot;&quot;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cfg=<span class="string">&quot;yolov8n.yaml&quot;</span>, ch=<span class="number">3</span>, nc=<span class="literal">None</span>, verbose=<span class="literal">True</span></span>):  <span class="comment"># model, input channels, number of classes</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;使用给定的配置和参数初始化 YOLOv8 目标检测模型。&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.yaml = cfg <span class="keyword">if</span> <span class="built_in">isinstance</span>(cfg, <span class="built_in">dict</span>) <span class="keyword">else</span> yaml_model_load(cfg)  <span class="comment"># cfg 字典</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 定义模型</span></span><br><span class="line">        ch = <span class="variable language_">self</span>.yaml[<span class="string">&quot;ch&quot;</span>] = <span class="variable language_">self</span>.yaml.get(<span class="string">&quot;ch&quot;</span>, ch)  <span class="comment"># 输入通道数</span></span><br><span class="line">        <span class="keyword">if</span> nc <span class="keyword">and</span> nc != <span class="variable language_">self</span>.yaml[<span class="string">&quot;nc&quot;</span>]:</span><br><span class="line">            LOGGER.info(<span class="string">f&quot;覆盖 model.yaml nc=<span class="subst">&#123;self.yaml[<span class="string">&#x27;nc&#x27;</span>]&#125;</span> 为 nc=<span class="subst">&#123;nc&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.yaml[<span class="string">&quot;nc&quot;</span>] = nc  <span class="comment"># 覆盖 YAML 中的值</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; 此处最为重要，涉及到了我们修改模型的配置的那个函数parse_model,</span></span><br><span class="line"><span class="string">            这里返回了我们的每一个模块的定义，也就是self.model保存了我们的ymal文件所有模块的实例化模型</span></span><br><span class="line"><span class="string">            self.save保存列表 | 也就是除了from部分为-1的部分比如from为4那么就将第四层的索引保存这里留着后面备用，</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.model, <span class="variable language_">self</span>.save = parse_model(deepcopy(<span class="variable language_">self</span>.yaml), ch=ch, verbose=verbose)  <span class="comment"># 模型，保存列表</span></span><br><span class="line">        <span class="variable language_">self</span>.names = &#123;i: <span class="string">f&quot;<span class="subst">&#123;i&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.yaml[<span class="string">&quot;nc&quot;</span>])&#125;  <span class="comment"># 默认名称字典</span></span><br><span class="line">        <span class="variable language_">self</span>.inplace = <span class="variable language_">self</span>.yaml.get(<span class="string">&quot;inplace&quot;</span>, <span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 构建步长</span></span><br><span class="line">        m = <span class="variable language_">self</span>.model[-<span class="number">1</span>]  <span class="comment"># Detect()</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, (Detect, Segment, Pose, Detect_AFPN4, Detect_AFPN3, Detect_ASFF, Detect_FRM, Detect_dyhead,</span><br><span class="line">                          CLLAHead, Detect_dyhead3, Detect_DySnakeConv, Segment_DySnakeConv,</span><br><span class="line">                          Segment_DBB, Detect_DBB, Pose_DBB, OBB, Detect_FASFF)):</span><br><span class="line">            s = <span class="number">640</span>  <span class="comment"># 2x 最小步长</span></span><br><span class="line">            m.inplace = <span class="variable language_">self</span>.inplace</span><br><span class="line">            forward = <span class="keyword">lambda</span> x: <span class="variable language_">self</span>.forward(x)[<span class="number">0</span>] <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, (Segment, Segment_DySnakeConv, Pose, Pose_DBB, Segment_DBB, OBB)) <span class="keyword">else</span> <span class="variable language_">self</span>.forward(x)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                m.stride = torch.tensor([s / x.shape[-<span class="number">2</span>] <span class="keyword">for</span> x <span class="keyword">in</span> forward(torch.zeros(<span class="number">1</span>, ch, s, s))])  <span class="comment"># 在 CPU 上进行前向传播</span></span><br><span class="line">            <span class="keyword">except</span> RuntimeError:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.model.to(torch.device(<span class="string">&#x27;cuda&#x27;</span>))</span><br><span class="line">                    m.stride = torch.tensor([s / x.shape[-<span class="number">2</span>] <span class="keyword">for</span> x <span class="keyword">in</span> forward(</span><br><span class="line">                        torch.zeros(<span class="number">1</span>, ch, s, s).to(torch.device(<span class="string">&#x27;cuda&#x27;</span>)))])  <span class="comment"># 在 CUDA 上进行前向传播</span></span><br><span class="line">                <span class="keyword">except</span> RuntimeError <span class="keyword">as</span> error:</span><br><span class="line">                    <span class="keyword">raise</span> error</span><br><span class="line">            <span class="variable language_">self</span>.stride = m.stride</span><br><span class="line">            m.bias_init()  <span class="comment"># 仅运行一次</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.stride = torch.Tensor([<span class="number">32</span>])  <span class="comment"># 默认步长，例如 RTDETR</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 初始化权重和偏置</span></span><br><span class="line">        initialize_weights(<span class="variable language_">self</span>)</span><br><span class="line">        <span class="keyword">if</span> verbose: <span class="comment"># 此处为获取模型参数量和打印的地方。</span></span><br><span class="line">            <span class="variable language_">self</span>.info()</span><br><span class="line">            LOGGER.info(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><hr><h3 id="3-4-parse-model的解析"><a href="#3-4-parse-model的解析" class="headerlink" title="3.4 parse_model的解析"></a>3.4 parse_model的解析</h3><p>这里涉及到yaml文件中模块的定义和，通道数放缩的地方，此处大家可以仔细看看比较重要涉及到模块的改动。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_model</span>(<span class="params">d, ch, verbose=<span class="literal">True</span></span>):  <span class="comment"># model_dict, input_channels(3)</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;解析 YOLO 模型.yaml 字典为 PyTorch 模型。&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">import</span> ast</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 参数设置</span></span><br><span class="line">    max_channels = <span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>) <span class="comment"># 设置一个最大的通道数inf,防止后面的通道数有的超出了范围，没什么作用其实。</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;下面一行代码比较重要，为获取我们yaml文件中的参数,nc=类别数（前面解释过了） act=激活函数， scales=模型的大小&quot;&quot;&quot;</span></span><br><span class="line">    nc, act, scales = (d.get(x) <span class="keyword">for</span> x <span class="keyword">in</span> (<span class="string">&quot;nc&quot;</span>, <span class="string">&quot;activation&quot;</span>, <span class="string">&quot;scales&quot;</span>))</span><br><span class="line">    <span class="string">&quot;&quot;&quot;此处为获取模型的通道数放缩比例假如  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs&quot;&quot;&quot;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;那么此处对应的就是 0.33 , 0.25, 1024&quot;&quot;&quot;</span></span><br><span class="line">    depth, width, kpt_shape = (d.get(x, <span class="number">1.0</span>) <span class="keyword">for</span> x <span class="keyword">in</span> (<span class="string">&quot;depth_multiple&quot;</span>, <span class="string">&quot;width_multiple&quot;</span>, <span class="string">&quot;kpt_shape&quot;</span>))</span><br><span class="line">    <span class="string">&quot;&quot;&quot;下面这个判断主要的功能就是我们指定yaml文件的时候如果不指定n或者其它模型尺度则默认用n然后提出一个警告，细心的读者应该会遇到过这个警告，群里也有人问过&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> scales:</span><br><span class="line">        scale = d.get(<span class="string">&quot;scale&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> scale:</span><br><span class="line">            scale = <span class="built_in">tuple</span>(scales.keys())[<span class="number">0</span>]</span><br><span class="line">            LOGGER.warning(<span class="string">f&quot;WARNING ⚠️ 没有传递模型比例。假定 scale=&#x27;<span class="subst">&#123;scale&#125;</span>&#x27;。&quot;</span>)</span><br><span class="line">        depth, width, max_channels = scales[scale]</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> act:</span><br><span class="line">        Conv.default_act = <span class="built_in">eval</span>(act)  <span class="comment"># 重新定义默认激活函数，例如 Conv.default_act = nn.SiLU()</span></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            LOGGER.info(<span class="string">f&quot;<span class="subst">&#123;colorstr(<span class="string">&#x27;activation:&#x27;</span>)&#125;</span> <span class="subst">&#123;act&#125;</span>&quot;</span>)  <span class="comment"># 打印</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> verbose:</span><br><span class="line">        LOGGER.info(<span class="string">f&quot;\n<span class="subst">&#123;<span class="string">&#x27;&#x27;</span>:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;from&#x27;</span>:&gt;<span class="number">20</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;n&#x27;</span>:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;params&#x27;</span>:&gt;<span class="number">10</span>&#125;</span>  <span class="subst">&#123;<span class="string">&#x27;module&#x27;</span>:&lt;<span class="number">45</span>&#125;</span><span class="subst">&#123;<span class="string">&#x27;arguments&#x27;</span>:&lt;<span class="number">30</span>&#125;</span>&quot;</span>)</span><br><span class="line">    ch = [ch] <span class="comment"># 存放第一个输入的通道数,这个ch后面会存放所有层的通道数，第一层为通道数是ch=3也就是对应我们一张图片的RGB图片的三基色三个通道，分别对应红绿蓝！</span></span><br><span class="line">    layers, save, c2 = [], [], ch[-<span class="number">1</span>]  <span class="comment"># 提前定义一些之后存放的容器分别为，模型层，保存列表，输出通道数</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;下面开始正式解析模型的yaml文件然后进行定义的操作用for训练便利yaml文件&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> i, (f, n, m, args) <span class="keyword">in</span> <span class="built_in">enumerate</span>(d[<span class="string">&quot;backbone&quot;</span>] + d[<span class="string">&quot;head&quot;</span>]):  <span class="comment"># from, number, module, args</span></span><br><span class="line">        m = <span class="built_in">getattr</span>(torch.nn, m[<span class="number">3</span>:]) <span class="keyword">if</span> <span class="string">&quot;nn.&quot;</span> <span class="keyword">in</span> m <span class="keyword">else</span> <span class="built_in">globals</span>()[m]  <span class="comment"># 获取模块</span></span><br><span class="line">        <span class="keyword">for</span> j, a <span class="keyword">in</span> <span class="built_in">enumerate</span>(args):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(a, <span class="built_in">str</span>):</span><br><span class="line">                <span class="keyword">with</span> contextlib.suppress(ValueError):</span><br><span class="line">                    args[j] = <span class="built_in">locals</span>()[a] <span class="keyword">if</span> a <span class="keyword">in</span> <span class="built_in">locals</span>() <span class="keyword">else</span> ast.literal_eval(a)</span><br><span class="line">        <span class="string">&quot;&quot;&quot; 此处为repeat那个参数的放缩操作,不过多解释了,最小的n是1（就是是说你yaml文件里定义的是3，然后和放缩系数相乘然后和1比那个小取那个）&quot;&quot;&quot;</span></span><br><span class="line">        n = n_ = <span class="built_in">max</span>(<span class="built_in">round</span>(n * depth), <span class="number">1</span>) <span class="keyword">if</span> n &gt; <span class="number">1</span> <span class="keyword">else</span> n</span><br><span class="line">        <span class="string">&quot;&quot;&quot;下面是一些具体模块的定义操作了&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> m <span class="keyword">in</span> (Classify, Conv, ConvTranspose, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, Focus,</span><br><span class="line">                 BottleneckCSP, C1, C2, C2f, C2fAttn, C3, C3TR, C3Ghost, nn.ConvTranspose2d, DWConvTranspose2d, C3x, RepC3):</span><br><span class="line">            c1, c2 = ch[f], args[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> c2 != nc:  <span class="comment"># 如果 c2 不等于类别数（即 Classify() 输出）</span></span><br><span class="line">                <span class="string">&quot;&quot;&quot; 绝大多数情况下都不等，我们放缩通道数，也就是为什么不同大小的模型参数量不一致的地方因为参数量主要由通道数决定，GFLOPs主要有图像的宽和高决定&quot;&quot;&quot;</span></span><br><span class="line">                c2 = make_divisible(<span class="built_in">min</span>(c2, max_channels) * width, <span class="number">8</span>)</span><br><span class="line">            <span class="keyword">if</span> m <span class="keyword">is</span> C2fAttn:</span><br><span class="line">                args[<span class="number">1</span>] = make_divisible(<span class="built_in">min</span>(args[<span class="number">1</span>], max_channels // <span class="number">2</span>) * width, <span class="number">8</span>)  <span class="comment"># 嵌入通道数</span></span><br><span class="line">                args[<span class="number">2</span>] = <span class="built_in">int</span>(</span><br><span class="line">                    <span class="built_in">max</span>(<span class="built_in">round</span>(<span class="built_in">min</span>(args[<span class="number">2</span>], max_channels // <span class="number">2</span> // <span class="number">32</span>)) * width, <span class="number">1</span>) <span class="keyword">if</span> args[<span class="number">2</span>] &gt; <span class="number">1</span> <span class="keyword">else</span> args[<span class="number">2</span>]</span><br><span class="line">                )  <span class="comment"># 头部数量</span></span><br><span class="line">            <span class="string">&quot;&quot;&quot;此处需要解释一下，大家需要仔细注意此处&quot;&quot;&quot;</span></span><br><span class="line">            <span class="string">&quot;&quot;&quot; 这个args就是传入到我们模型的参数,C1就是上一层的或者指定层的输出的通道数，C2就是本层的输出通道数， *args[1:]就是其它的一些参数比如卷积核步长什么的&quot;&quot;&quot;</span></span><br><span class="line">            <span class="string">&quot;&quot;&quot; 此处和注意力机制不同的是，为什么注意力机制不在此处添加因为注意力机制不改变模型的维度，所以一般只需要指定一个输入通道数就行，</span></span><br><span class="line"><span class="string">                所以这也是为什么我们在后面定义注意力需要额外添加代码的原因有兴趣的读者可以对比一下&quot;&quot;&quot;</span></span><br><span class="line">            args = [c1, c2, *args[<span class="number">1</span>:]]</span><br><span class="line">            <span class="string">&quot;&quot;&quot; 此处就是涉及的上面求出的实际的n然后插入的参数列表中去，然后准备在最下面进行传参&quot;&quot;&quot;</span></span><br><span class="line">            <span class="keyword">if</span> m <span class="keyword">in</span> (BottleneckCSP, C1, C2, C2f, C2fAttn, C3, C3TR, C3Ghost, C3x, RepC3):</span><br><span class="line">                args.insert(<span class="number">2</span>, n)  <span class="comment"># 重复次数</span></span><br><span class="line">                n = <span class="number">1</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;这些都是一些具体的模块定义的方法，不多解释了&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> AIFI:</span><br><span class="line">            args = [ch[f], *args]</span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">in</span> (HGStem, HGBlock):</span><br><span class="line">            c1, cm, c2 = ch[f], args[<span class="number">0</span>], args[<span class="number">1</span>]</span><br><span class="line">            args = [c1, cm, c2, *args[<span class="number">2</span>:]]</span><br><span class="line">            <span class="keyword">if</span> m <span class="keyword">is</span> HGBlock:</span><br><span class="line">                args.insert(<span class="number">4</span>, n)  <span class="comment"># 重复次数</span></span><br><span class="line">                n = <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> ResNetLayer:</span><br><span class="line">            c2 = args[<span class="number">1</span>] <span class="keyword">if</span> args[<span class="number">3</span>] <span class="keyword">else</span> args[<span class="number">1</span>] * <span class="number">4</span></span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> nn.BatchNorm2d:</span><br><span class="line">            args = [ch[f]]</span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> Concat:</span><br><span class="line">            c2 = <span class="built_in">sum</span>(ch[x] <span class="keyword">for</span> x <span class="keyword">in</span> f)</span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">in</span> (Detect, WorldDetect, Segment, Pose, OBB, ImagePoolingAttn):</span><br><span class="line">            args.append([ch[x] <span class="keyword">for</span> x <span class="keyword">in</span> f])</span><br><span class="line">            <span class="keyword">if</span> m <span class="keyword">is</span> Segment:</span><br><span class="line">                args[<span class="number">2</span>] = make_divisible(<span class="built_in">min</span>(args[<span class="number">2</span>], max_channels) * width, <span class="number">8</span>)</span><br><span class="line">        <span class="keyword">elif</span> m <span class="keyword">is</span> RTDETRDecoder:  <span class="comment"># 特殊情况，channels 参数必须在索引 1 中传递</span></span><br><span class="line">            args.insert(<span class="number">1</span>, [ch[x] <span class="keyword">for</span> x <span class="keyword">in</span> f])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            c2 = ch[f]</span><br><span class="line">        <span class="string">&quot;&quot;&quot;此处就是模型的正式定义和传参的操作&quot;&quot;&quot;</span></span><br><span class="line">        m_ = nn.Sequential(*(m(*args) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n))) <span class="keyword">if</span> n &gt; <span class="number">1</span> <span class="keyword">else</span> m(*args)  <span class="comment"># 模块</span></span><br><span class="line">        t = <span class="built_in">str</span>(m)[<span class="number">8</span>:-<span class="number">2</span>].replace(<span class="string">&quot;__main__.&quot;</span>, <span class="string">&quot;&quot;</span>)  <span class="comment"># 模块类型</span></span><br><span class="line">        m.np = <span class="built_in">sum</span>(x.numel() <span class="keyword">for</span> x <span class="keyword">in</span> m_.parameters())  <span class="comment"># 参数数量</span></span><br><span class="line">        m_.i, m_.f, m_.<span class="built_in">type</span> = i, f, t  <span class="comment"># 附加索引，&#x27;from&#x27; 索引，类型</span></span><br><span class="line">        <span class="keyword">if</span> verbose:</span><br><span class="line">            LOGGER.info(<span class="string">f&quot;<span class="subst">&#123;i:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;<span class="built_in">str</span>(f):&gt;<span class="number">20</span>&#125;</span><span class="subst">&#123;n_:&gt;<span class="number">3</span>&#125;</span><span class="subst">&#123;m.np:<span class="number">10.0</span>f&#125;</span>  <span class="subst">&#123;t:&lt;<span class="number">45</span>&#125;</span><span class="subst">&#123;<span class="built_in">str</span>(args):&lt;<span class="number">30</span>&#125;</span>&quot;</span>)  <span class="comment"># 打印</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;此处就是保存一些索引通道数涉及到from的部分，此处文字很难解释的清楚有兴趣可以自己debug看一下就明白了&quot;&quot;&quot;</span></span><br><span class="line">        save.extend(x % i <span class="keyword">for</span> x <span class="keyword">in</span> ([f] <span class="keyword">if</span> <span class="built_in">isinstance</span>(f, <span class="built_in">int</span>) <span class="keyword">else</span> f) <span class="keyword">if</span> x != -<span class="number">1</span>)  <span class="comment"># 添加到保存列表</span></span><br><span class="line">        layers.append(m_)</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            ch = []</span><br><span class="line">        ch.append(c2)</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers), <span class="built_in">sorted</span>(save)</span><br></pre></td></tr></table></figure><hr><h2 id="四、模型的结构打印"><a href="#四、模型的结构打印" class="headerlink" title="四、模型的结构打印"></a>四、模型的结构打印</h2><p>经过上面的分析之后，我们就会打印了模型的结构，图片如下所示，然后到此本篇文章的分析就到这里了，剩下的下一篇文章讲解。</p><p><strong>（需要注意的是上面的讲解整体是按照顺序但是是以递归的形式介绍，比如3.2是3.1当中的某一行代码的功能而不是结束之后才允许的3.2，而是3.1运行的过程中运行了3.2。）</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/d3d9d7580362433ba08904db10be9ea4.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/d3d9d7580362433ba08904db10be9ea4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="d3d9d7580362433ba08904db10be9ea4.png"></p>]]></content>
      
      
      <categories>
          
          <category> 写作 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/08/19/hello-world/"/>
      <url>/2024/08/19/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a><br>$$<br>i\hbar\frac{\partial}{\partial t}\psi&#x3D;-\frac{\hbar^2}{2m}\nabla^2\psi+V\psi<br>$$</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>说明文档</title>
      <link href="/2024/08/19/shuo-ming-wen-dang/"/>
      <url>/2024/08/19/shuo-ming-wen-dang/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这篇文档主要介绍《基于YOLOv8的农田病虫害检测与分析》的代码实现部分，整篇论文的目的主要是改进YOLOv8的网络结构，使其在检测病虫害的精度和实时性上有所提升。接下来，我将介绍如何从零开始搭建起本项目。</p></blockquote><h1 id="安装Python"><a href="#安装Python" class="headerlink" title="安装Python"></a>安装Python</h1><p>到python的官方网站：<a href="https://www.python.org/">https://www.python.org/</a>下载，安装</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-10-42.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-10-42.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>安装完成后，在命令行窗口运行：python，查看安装的结果，如下图：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-14-22.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-14-22.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>至此，Python安装完成，接下来还需要安装anaconda，这是一个python虚拟环境，特别适合管理python的环境。</p><h1 id="安装anaconda"><a href="#安装anaconda" class="headerlink" title="安装anaconda"></a>安装anaconda</h1><p>到anaconda的官方网站：<a href="https://www.anaconda.com/download/success">https://www.anaconda.com/download/success</a>下载，并安装：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-17-10.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-17-10.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>安装成功后，会在开始菜单出现如下图所示：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-19-17.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-19-17.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>anaconda安装完成，接下来安装pycharm，主要用来编写代码。</p><h1 id="安装Pycharm"><a href="#安装Pycharm" class="headerlink" title="安装Pycharm"></a>安装Pycharm</h1><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-23-47.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-23-47.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>学生可以申请教育版</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-24-59.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-24-59.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>支持，所有的软件安装完成。</p><h1 id="YOLOv8目录结构介绍"><a href="#YOLOv8目录结构介绍" class="headerlink" title="YOLOv8目录结构介绍"></a>YOLOv8目录结构介绍</h1><p>首先介绍整个项目的目录：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-27-47.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-27-47.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-28-07.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-28-07.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>和原来的YOLOv8相比，根目录新增一些训练的脚本和测试的脚本，比如train.py和Detect.py，当然也可以直接通过命令行的方式来实现，两者效果都是一样的。</p><blockquote><p><strong>重点是ultralytics&#x2F;nn目录，所有的改进模块都是在这里进行，在这里我新建了一个Addmodules的目录，里面是改进的各种模块，包括主干网络，颈部网络和检测头的改进。</strong></p></blockquote><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-36-15.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-36-15.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>需要修改的部分我都已经作了修改，不用再做其他的改动</p><blockquote><p><strong>还有一个重要的目录：ultralytics&#x2F;cfg&#x2F;models&#x2F;Add，这里面放的都是yaml文件，其中改进的yaml文件都已经写好，不需要改动。</strong></p></blockquote><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-38-32.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-38-32.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>以下是一个yaml文件的示例，其它的都是类似的结构，只是参数不同：</p><h1 id="安装项目的环境（非常重要）"><a href="#安装项目的环境（非常重要）" class="headerlink" title="安装项目的环境（非常重要）"></a>安装项目的环境（非常重要）</h1><blockquote><p>环境配置非常重要，我当时配环境换了一周左右的时间，中间经历了各种报错，软件包不兼容的问题和显卡驱动匹配的问题，总之就是不好搞。为了方面复现工作，我已经把anaconda的环境导出为environment.yml，位于项目的根目录里面，创建虚拟环境的时候直接使用就可以</p></blockquote><h2 id="anaconda虚拟环境"><a href="#anaconda虚拟环境" class="headerlink" title="anaconda虚拟环境"></a>anaconda虚拟环境</h2><p>再anaconda prompt终端输入conda env create -f environment.yml，就可以根据environment.yml文件创建虚拟环境，创建好后，通过conda env list查看环境是否存在，如下图所示就表明创建成功：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_16-35-14.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_16-35-14.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>如果安装的时候出现torch相关的错误，大概率是你的显卡驱动和这里面的torch包版本不匹配，这个问题需要自行修改即可，网上关于这方面的资料很多。</p><h2 id="使用虚拟环境"><a href="#使用虚拟环境" class="headerlink" title="使用虚拟环境"></a>使用虚拟环境</h2><p>虚拟环境创建完成之后，就可以在pycharm中使用，点击右下角，切换conda环境，选择刚才创建的虚拟环境。如果到了这一步还没有报错的话，恭喜你，已经完成了80%的工作。</p><p>运行Detect.py脚本，测试检测效果，如果没有报错，接下来就是训练模型。</p><h1 id="训练脚本train-py"><a href="#训练脚本train-py" class="headerlink" title="训练脚本train.py"></a>训练脚本train.py</h1><p>找到根目录的train.py文件，注释已经写的很清楚，如下图：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = YOLO(<span class="string">&#x27;yolov8-HSFPN.yaml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model.load(&#x27;yolov8n.pt&#x27;) # 是否加载预训练权重,科研不建议大家加载否则很难提升精度</span></span><br><span class="line"></span><br><span class="line">    model.train(data=<span class="string">r&#x27;D:/Downloads/YOLOv8/datasets/data.yaml&#x27;</span>,</span><br><span class="line">                <span class="comment"># 如果大家任务是其它的&#x27;ultralytics/cfg/default.yaml&#x27;找到这里修改task可以改成detect, segment, classify, pose</span></span><br><span class="line">                cache=<span class="literal">False</span>,</span><br><span class="line">                imgsz=<span class="number">640</span>,</span><br><span class="line">                epochs=<span class="number">150</span>,</span><br><span class="line">                single_cls=<span class="literal">False</span>,  <span class="comment"># 是否是单类别检测</span></span><br><span class="line">                batch=<span class="number">4</span>,</span><br><span class="line">                close_mosaic=<span class="number">10</span>,</span><br><span class="line">                workers=<span class="number">0</span>,</span><br><span class="line">                device=<span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">                optimizer=<span class="string">&#x27;SGD&#x27;</span>, <span class="comment"># using SGD</span></span><br><span class="line">                <span class="comment"># resume=&#x27;runs/train/exp21/weights/last.pt&#x27;, # 如过想续训就设置last.pt的地址</span></span><br><span class="line">                amp=<span class="literal">True</span>,  <span class="comment"># 如果出现训练损失为Nan可以关闭amp</span></span><br><span class="line">                project=<span class="string">&#x27;runs/train&#x27;</span>,</span><br><span class="line">                name=<span class="string">&#x27;exp&#x27;</span>,</span><br><span class="line">                )</span><br></pre></td></tr></table></figure><p>model &#x3D; YOLO(‘yolov8-HSFPN.yaml’)，把里面的yaml文件换成自己的yaml文件，我这里用的是yolov8-HSFPN.yaml，data&#x3D;r’D:&#x2F;Downloads&#x2F;YOLOv8&#x2F;datasets&#x2F;data.yaml，同理，换成自己数据集的yaml文件，我这里的数据集是yolo格式。其它的参数可以按照自己的任务自行调整。</p><p>还有一个检测的脚本，Detect.py:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = YOLO(<span class="string">&#x27;D:/Downloads/YOLOv8/result/result_8_HSFPN/train/exp/weights/best.pt&#x27;</span>) <span class="comment"># select your model.pt path</span></span><br><span class="line">    model.predict(source=<span class="string">&#x27;D:/Downloads/YOLOv8/ultralytics/assets&#x27;</span>,</span><br><span class="line">                  imgsz=<span class="number">640</span>,</span><br><span class="line">                  project=<span class="string">&#x27;runs/detect&#x27;</span>,</span><br><span class="line">                  name=<span class="string">&#x27;exp&#x27;</span>,</span><br><span class="line">                  save=<span class="literal">True</span>,</span><br><span class="line">                )</span><br></pre></td></tr></table></figure><p>同理，把best.pt换成你自己训练好的模型，source里面输入检测图片的路径，运行该脚本就可以开始检测，结果保存在runs&#x2F;detect目录。</p><h1 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h1><p>准备好数据集，最好是yolo格式的，我的数据集项目里自带了，不需要重新下载：</p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-55-44.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-55-44.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" style="zoom:67%;" /><p>datasets目录里面就是我的数据集：有train，test，valid三个目录，分别存放训练集，测试集和验证集的图像和标签：</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-58-01.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-58-01.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-58-32.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_15-58-32.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>准备这些之后，运行train.py文件，开始训练。如果报错的话，请自行上网查找，无非就是找不到数据集，某个包的版本不对，或者是GPU用不了，只能用CPU。</p><h1 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h1><blockquote><p>训练结果会保存在runs&#x2F;train目录下，exp1,exp2,exp3的顺序，表示每一次的训练结果。</p></blockquote><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_16-04-37.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_16-04-37.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>上图就是训练完成后目录的结构，weights目录里面就是我们需要的模型：best.pts是效果最好的，最后也是需要这个，last.pt是最后一次的训练结果。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_16-05-47.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/Snipaste_2024-05-23_16-05-47.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><strong>整个项目的改进工作我已经做好，复现的话只需装好对应的环境，修改train.py的参数，运行train.py就可以开始训练；修改Detect.py的参数，就可以检测。目前项目只针对检测任务，对于分割和分类没有做改进。</strong></p><h1 id="经验之谈"><a href="#经验之谈" class="headerlink" title="经验之谈"></a>经验之谈</h1><p><strong>（1）以下为两个重要库的版本，必须对应下载，否则会报错</strong></p><blockquote><p>python &#x3D;&#x3D; 3.9.7<br>pytorch &#x3D;&#x3D; 1.12.1<br>timm &#x3D;&#x3D; 0.9.12  # 此安装包必须要<br>mmcv-full &#x3D;&#x3D; 1.6.2  # 不安装此包部分关于dyhead的代码运行不了以及Gold-YOLO</p></blockquote><p><strong>（2）mmcv-full会安装失败是因为自身系统的编译工具有问题，也有可能是环境之间安装的有冲突</strong></p><pre><code>推荐大家离线安装的形式,下面的地址中大家可以找找自己的版本,下载到本地进行安装。https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.htmlhttps://download.openmmlab.com/mmcv/dist/index.html</code></pre><p><strong>（3）basicsr安装失败原因,通过pip install basicsr 下载如果失败,大家可以去百度搜一下如何换下载镜像源就可以修复</strong></p><h2 id="针对一些报错的解决办法在这里说一下"><a href="#针对一些报错的解决办法在这里说一下" class="headerlink" title="针对一些报错的解决办法在这里说一下"></a>针对一些报错的解决办法在这里说一下</h2><p><strong>(1)训练过程中loss出现Nan值.</strong><br>   可以尝试关闭AMP混合精度训练.</p><p><strong>(2)多卡训练问题,修改模型以后不能支持多卡训练可以尝试下面的两行命令行操作，两个是不同的操作，是代表不同的版本现尝试第一个不行用第二个</strong></p><pre><code>python -m torch.distributed.run --nproc_per_node 2 train.pypython -m torch.distributed.launch --nproc_per_node 2 train.py</code></pre><p><strong>(3) 针对运行过程中的一些报错解决</strong><br>    1.如果训练的过程中验证报错了(主要是一些形状不匹配的错误这是因为验证集的一些特殊图片导致)<br>    找到ultralytics&#x2F;models&#x2F;yolo&#x2F;detect&#x2F;train.py的DetectionTrainer class中的build_dataset函数中的rect&#x3D;mode &#x3D;&#x3D; ‘val’改为rect&#x3D;False</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2.</span>推理的时候运行detect.py文件报了形状不匹配的错误</span><br><span class="line">找到ultralytics/engine/predictor.py找到函数<span class="keyword">def</span> <span class="title function_">pre_transform</span>(<span class="params">self, im</span>),在LetterBox中的auto改为<span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="number">3.</span>训练的过程中报错类型不匹配的问题</span><br><span class="line">找到<span class="string">&#x27;ultralytics/engine/validator.py&#x27;</span>文件找到 <span class="string">&#x27;class BaseValidator:&#x27;</span> 然后在其<span class="string">&#x27;__call__&#x27;</span>中</span><br><span class="line"><span class="variable language_">self</span>.args.half = <span class="variable language_">self</span>.device.<span class="built_in">type</span> != <span class="string">&#x27;cpu&#x27;</span>  <span class="comment"># force FP16 val during training的一行代码下面加上self.args.half = False</span></span><br></pre></td></tr></table></figure><p><strong>(4) 针对yaml文件中的nc修改</strong><br>    不用修改，模型会自动根据你数据集的配置文件获取。<br>    这也是模型打印两次的区别，第一次打印出来的就是你选择模型的yaml文件结构，第二次打印的就是替换了你数据集的yaml文件，模型使用的是第二种。</p><p><strong>(5) 针对环境的问题</strong><br>    环境的问题每个人遇见的都不一样，可自行上网查找。</p>]]></content>
      
      
      <categories>
          
          <category> YOLO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>评估</title>
      <link href="/2024/08/11/article-11/"/>
      <url>/2024/08/11/article-11/</url>
      
        <content type="html"><![CDATA[<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>这篇博客，<strong>主要给大家讲解我们在训练yolov8时生成的结果文件中各个图片及其中指标的含义</strong>，帮助大家更深入的理解，以及我们在评估模型时和发表论文时主要关注的参数有那些。本文通过举例训练过程中的某一时间的结果来帮助大家理解，大家阅读过程中如有任何问题可以在评论区提问出来，我会帮助大家解答。首先我们来看一个在一次训练完成之后都能生成多少个文件如下图所示，下面的文章讲解都会围绕这个结果文件来介绍。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bdf99b744c6646f6a82b2be30e3e9d92.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/bdf99b744c6646f6a82b2be30e3e9d92.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><hr><h2 id="二、评估用的数据集"><a href="#二、评估用的数据集" class="headerlink" title="二、评估用的数据集 "></a><strong>二、评估用的数据集</strong> </h2><blockquote><p>上面的训练结果，是根据一个检测飞机的数据集训练得来，其中只有个标签就是飞机，对于这种单标签的数据集，其实我们可以将其理解为一个二分类任务，</p><p><strong>一种情况-&gt;检测为飞机，另一种情况-&gt;不是飞机。</strong></p></blockquote><hr><h2 id="三、结果分析"><a href="#三、结果分析" class="headerlink" title="三、结果分析 "></a>三、结果分析 </h2><p>我们可以从结果文件中看到其中<strong>共有文件24个</strong>，后12张图片是根据我们训练过程中的一些检测结果图片，用于我们可以观察检测结果，有哪些被检测出来了，那些没有被检测出来，其不作为指标评估的文件。         </p><h3 id="Weights文件夹"><a href="#Weights文件夹" class="headerlink" title="Weights文件夹"></a>Weights文件夹</h3><p>我们先从第一个weights文件夹来分析，其中有两个文件，分别是<strong>best.pt、last.pt</strong>,其分别为训练过程中的损失最低的结果和模型训练的最后一次结果保存的模型。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/3986c306bb3b4e9893da7f89d2994a88.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/3986c306bb3b4e9893da7f89d2994a88.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h3 id="args-yaml"><a href="#args-yaml" class="headerlink" title="args.yaml"></a>args.yaml</h3><p>第二个文件是args.yaml文件,其中主要保存一些我们训练时指定的参数，内容如下所示。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f464e438dd6f4f0a9c52e7246439295c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/f464e438dd6f4f0a9c52e7246439295c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h3 id="混淆矩阵-ConfusionMatrix"><a href="#混淆矩阵-ConfusionMatrix" class="headerlink" title="混淆矩阵(ConfusionMatrix)"></a>混淆矩阵(ConfusionMatrix)</h3><p>第三个文件就是混淆矩阵，大家都应该听过这个名字，其是一种用于评估分类模型性能的表格形式。它以实际类别（真实值）和模型预测类别为基础，将样本分类结果进行统计和汇总。</p><blockquote><p>对于二分类问题，混淆矩阵通常是一个2×2的矩阵，包括真阳性（True Positive, TP）、真阴性（True Negative, TN）、假阳性（False Positive, FP）和假阴性（False Negative, FN）四个元素。</p></blockquote><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ae117a5a660142f3a44b52834fa04ec3.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/ae117a5a660142f3a44b52834fa04ec3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">True_Label = [1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1 ,0, 1, 0 , 1 , 0, 0 , 1]Predict_Label = [0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1 ,0 , 0 , 1 , 0, 0 , 1, 0]</span><br></pre></td></tr></table></figure><p>我们来分析这个图，其每个格子代表的含义我在图片上标注了出来**,下面我们来拿一个例子来帮助大家来理解这个混淆矩阵。**</p><p>假设我们的数据集预测为飞机标记为数字0、预测不为飞机标记为1，<strong>现在假设我们在模型的训练的某一批次种预测了20次其真实结果和预测结果如下所示。</strong> </p><p>其中True_Label代表真实的标签，Predict_Label代表我们用模型预测的标签。</p><p>那么我们可以进行对比产生如下分析</p><blockquote><ul><li>6个样本的真实标签和预测标签都是0（真阴性，True Negative）。</li><li>1个样本的真实标签是0，但预测标签是1（假阳性，False Positive）。</li><li>8个样本的真实标签是1，但预测标签是0（假阴性，False Negative）。</li><li>5个样本的真实标签和预测标签都是1（真阳性，True Positive）。</li></ul></blockquote><p>下面根据我们的分析结果，我们就能够画出这个预测的混淆矩阵，</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/36c503208f654d06a1ad585e772364a8.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/36c503208f654d06a1ad585e772364a8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>由此我们就能得到那一批次的混淆矩阵，<strong>我们的最终结果生成的混淆矩阵可以理解为多个混淆矩阵的统计结果。</strong> </p><h3 id="混淆矩阵归一化-Confusion-Matrix-Normal"><a href="#混淆矩阵归一化-Confusion-Matrix-Normal" class="headerlink" title="混淆矩阵归一化(Confusion Matrix Normal)"></a>混淆矩阵归一化(Confusion Matrix Normal)</h3><p>这个混淆矩阵的归一化，就是对混淆矩阵做了一个归一化处理，对混淆矩阵进行归一化可以将每个单元格的值除以该类别实际样本数，从而得到表示分类准确率的百分比。这种标准化使得我们可以直观地比较类别间的分类准确率，并识别出模型在哪些类别上表现较好或较差。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4642ed3defe146a3b93999ffbd5d5129.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/4642ed3defe146a3b93999ffbd5d5129.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p><strong>我们可以看到是对于列进行了归一化处理，0.9 + 0.1 &#x3D; 1，1 + 0 &#x3D; 1。</strong> </p><h3 id="计算mAP、Precision、Recall"><a href="#计算mAP、Precision、Recall" class="headerlink" title="计算mAP、Precision、Recall"></a><strong>计算mAP、Precision、Recall</strong></h3><p>在讲解其它的图片之前我们需要来计算三个比较重要的参数，这是其它图片的基础，这里的计算还是利用上面的某一批次举例的分析结果。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/09e2217c78ab4e6ab49eeb2b8f128fed.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/09e2217c78ab4e6ab49eeb2b8f128fed.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><ol><li><p>精确度（Precision）：<strong>预测为正的样本中有多少是正确的</strong>，Precision &#x3D; TP &#x2F; (TP + FP) &#x3D; 5 &#x2F; (5 + 1) &#x3D; 5&#x2F;6 ≈ 0.833</p></li><li><p>召回率（Recall）：真实为正的样本中有多少被正确预测为正，Recall &#x3D; TP &#x2F; (TP + FN) &#x3D; 5 &#x2F; (5 + 8) ≈ 0.385</p></li><li><p>F1值（F1-Score）：**综合考虑精确度和召回率的指标，**F1 &#x3D; 2 * (Precision * Recall) &#x2F; (Precision + Recall) &#x3D; 2 * (0.833 * 0.385) &#x2F; (0.833 + 0.385) ≈ 0.526</p></li><li><p>准确度（Accuracy）：**所有样本中模型正确预测的比例，**Accuracy &#x3D; (TP + TN) &#x2F; (TP + TN + FP + FN) &#x3D; (5 + 6) &#x2F; (5 + 6 + 1 + 8) ≈ 0.565</p></li><li><p>平均精确度（Average Precision, AP）：**用于计算不同类别的平均精确度，对于二分类问题，AP等于精确度。**AP &#x3D; Precision &#x3D; 0.833</p></li><li><p>平均精确度（Mean Average Precision, mAP）：<strong>多类别问题的平均精确度，对于二分类问题，mAP等于AP（精确度）</strong>，所以mAP &#x3D; AP &#x3D; 0.833</p></li></ol><p>这里需要讲解的主要是AP和MAP如果是多分类的问题，AP和mAP怎么计算，首先我们要知道AP的全称就是Average Precision，平均精度所以我们AP的计算公式如下？</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5a9f270d50ce4bbfb76e800f4553200c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/5a9f270d50ce4bbfb76e800f4553200c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>mAP就是Mean Average Precision，计算如下，计算每一个没别的AP进行求平均值处理就是mAP。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a7ef1cd0cb924112acfa07084524a7a8.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/a7ef1cd0cb924112acfa07084524a7a8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h3 id="F1-Curve"><a href="#F1-Curve" class="headerlink" title="F1_Curve"></a>F1_Curve</h3><p>F1_Curve这个文件，我们点击去的图片的标题是F1-Confidence Curve它显示了在不同分类阈值下的F1值变化情况。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/97f8c2e20dd24d59a954bd43c4644c0f.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/97f8c2e20dd24d59a954bd43c4644c0f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>我们可以这么理解，先看它的横纵坐标，横坐标是置信度，纵坐标是F1-Score，F1-Score在前面我们以及讲解过了，那什么是置信度？</p><p>**置信度(Confidence)-&gt;**在我们模型的识别过程中会有一个概率，就是模型判定一个物体并不是百分百判定它是属于某一个分类，它会给予它以个概率，Confidence就是我们设置一个阈值，如果超过这个概率那么就确定为某一分类，<strong>假如我模型判定一个物体由0.7的概率属于飞机，此时我们设置的阈值如果为0.7以下那么模型就会输出该物体为飞机，如果我们设置的阈值大于0.7那么模型就不会输出该物体为飞机。</strong></p><p><strong>F1-Confidence Curve就是随着F1-Score随着Confience的逐渐增高而变化的一个曲线。</strong></p><h3 id="Labels"><a href="#Labels" class="headerlink" title="Labels"></a>Labels</h3><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/521ff0b11be64fcbbbd711c3de43ddcd.jpeg" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/521ff0b11be64fcbbbd711c3de43ddcd.jpeg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>Labels图片代表每个检测到的目标的类别和边界框信息。每个目标都由一个矩形边界框和一个类别标签表示，<strong>我们逆时针来看这个图片！！！</strong></p><ol><li>目标类别：该像素点所检测到的目标类别，例如飞机等。</li><li>目标位置：该像素点所检测到的目标在图像中的位置，即该像素点在图像中的坐标。</li><li>目标大小：该像素点所检测到的目标的大小，即该像素点所覆盖的区域的大小。</li><li>其他信息：例如目标的旋转角度等其他相关信息。</li></ol><h3 id="labels-correlogram"><a href="#labels-correlogram" class="headerlink" title="labels_correlogram"></a>labels_correlogram</h3><p>labels_correlogram是一个在**机器学习领域中使用的术语，**它指的是一种图形，<strong>用于显示目标检测算法在训练过程中预测标签之间的相关性</strong>。</p><p>具体来说，labels_correlogram是一张<strong>颜色矩阵图</strong>，它展示了训练集数据标签之间的相关性。它可以帮助我们理解目标检测算法在训练过程中的行为和表现，以及预测标签之间的相互影响。</p><p>通过观察labels_correlogram，我们可以了解到目标检测算法在不同类别之间的区分能力，以及对于不同类别的预测精度。此外，我们还可以通过比较不同算法或不同数据集labels_correlogram，来评估算法的性能和数据集的质量。</p><p>总之，labels_correlogram是一种有用的工具，可以帮助我们更好地理解目标检测算法在训练过程中的行为和表现，以及评估算法的性能和数据集的质量。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0f1e5f82a532423dae3a4e8b897e6165.jpeg" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0f1e5f82a532423dae3a4e8b897e6165.jpeg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h3 id="P-curve"><a href="#P-curve" class="headerlink" title="P_curve"></a>P_curve</h3><p>这个图的分析和F1_Curve一样，不同的是关于的是Precision和Confidence之间的关系，<strong>可以看出我们随着置信度的越来越高检测的准确率按理来说是越来越高的。</strong> </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/7ac794c6f34b418c95dfc7951382171c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/7ac794c6f34b418c95dfc7951382171c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h3 id="R-curve"><a href="#R-curve" class="headerlink" title="R_curve"></a>R_curve</h3><p>这个图的分析和F1_Curve一样，不同的是关于的是Recall和Confidence之间的关系，<strong>可以看出我们随着置信度的越来越高召回率的准确率按理来说是越来越低的。</strong> </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e72c4546e65d445c9831567e12d55df0.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e72c4546e65d445c9831567e12d55df0.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h3 id="PR-curve"><a href="#PR-curve" class="headerlink" title="PR_curve"></a>PR_curve</h3><p>它显示了在不同分类阈值下模型的精确度（Precision）和召回率（Recall）之间的关系。</p><p><strong>PR曲线越靠近坐标轴的右上角，模型性能越好，越能够正确识别正样本，正确分类正样本的Precision值越高，而靠近右侧则说明模型对正样本的识别能力较差，即召回能力较差。</strong></p><blockquote><p>PR曲线的特点是随着分类阈值的变化，精确度和召回率会有相应的改变。通常情况下，当分类模型能够同时保持较高的精确度和较高的召回率时，PR曲线处于较高的位置。当模型偏向于高精确度或高召回率时，曲线则相应地向低精确度或低召回率的方向移动。</p><p>PR曲线可以帮助我们评估模型在不同阈值下的性能，并选择适当的阈值来平衡精确度和召回率。对于模型比较或选择，我们可以通过比较PR曲线下方的面积（称为平均精确度均值，Average Precision, AP）来进行定量评估。AP值越大，模型的性能越好。</p><p>总结：PR曲线是一种展示分类模型精确度和召回率之间关系的可视化工具，通过绘制精确度-召回率曲线，我们可以评估和比较模型在不同分类阈值下的性能，并计算平均精确度均值（AP）来定量衡量模型的好坏。</p></blockquote><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c00378b5866f44978bf907f4b92d6a2c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/c00378b5866f44978bf907f4b92d6a2c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><h3 id="results-csv"><a href="#results-csv" class="headerlink" title="results.csv"></a>results.csv</h3><p>results.csv记录了一些我们训练过程中的参数信息，包括损失和学习率等，这里没有什么需要理解大家可以看一看，我们后面的results图片就是根据这个文件绘画出来的。</p><h3 id="results"><a href="#results" class="headerlink" title="results"></a><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/9af828676f704aada0b9b18797ba75ce.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/9af828676f704aada0b9b18797ba75ce.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp">results</h3><p>这个图片就是生成结果的最后一个了，我们可以看出其中标注了许多小的图片包括训练过程在的各种损失，我们主要看的其实就是后面的四幅图mAP50、mAP50-95、metrics&#x2F;precision、metrics&#x2F;recall四张图片。 </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0108b195b2e04b46811b44dc9f5f351f.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0108b195b2e04b46811b44dc9f5f351f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><blockquote><ol><li>mAP50：mAP是mean Average Precision的缩写，表示在多个类别上的平均精度。mAP50表示在50%的IoU阈值下的mAP值。</li><li>mAP50-95：这是一个更严格的评价指标，它计算了在50-95%的IoU阈值范围内的mAP值，然后取平均。这能够更准确地评估模型在不同IoU阈值下的性能。</li><li>metrics&#x2F;precision：精度（Precision）是评估模型预测正确的正样本的比例。在目标检测中，如果模型预测的边界框与真实的边界框重合，则认为预测正确。</li><li>metrics&#x2F;recall：召回率（Recall）是评估模型能够找出所有真实正样本的比例。在目标检测中，如果真实的边界框与预测的边界框重合，则认为该样本被正确召回。</li></ol></blockquote><h3 id="检测效果图"><a href="#检测效果图" class="headerlink" title="检测效果图"></a>检测效果图</h3><p> 最后的十四张图片就是检测效果图了，给大家看一下这里没什么好讲解的了。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/7dbceef24f184435b49dd7480b2cc2b3.jpeg" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/7dbceef24f184435b49dd7480b2cc2b3.jpeg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><hr><h2 id="四、其它参数"><a href="#四、其它参数" class="headerlink" title="四、其它参数"></a>四、其它参数</h2><p>FPS和IoU是目标检测领域中使用的两个重要指标，分别表示每秒处理的图片数量和交并比。</p><blockquote><ol><li>FPS：全称为Frames Per Second，即每秒帧率。它用于评估模型在给定硬件上的处理速度，即每秒可以处理的图片数量。该指标对于实现实时检测非常重要，因为只有处理速度快，才能满足实时检测的需求。</li><li>IoU：全称为Intersection over Union，表示交并比。在目标检测中，它用于衡量模型生成的候选框与原标记框之间的重叠程度。IoU值越大，表示两个框之间的相似性越高。通常，当IoU值大于0.5时，认为可以检测到目标物体。这个指标常用于评估模型在特定数据集上的检测准确度。</li></ol></blockquote><p>在目标检测领域中，处理速度和准确度是两个重要的性能指标。在实际应用中，我们需要根据具体需求来平衡这两个指标。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 评估 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>绘图</title>
      <link href="/2024/08/09/article-12/"/>
      <url>/2024/08/09/article-12/</url>
      
        <content type="html"><![CDATA[<h2 id="一、本文介绍"><a href="#一、本文介绍" class="headerlink" title="一、本文介绍"></a>一、本文介绍</h2><p>本文给大家带来的是<strong>YOLOv8系列的绘图功能</strong>，我将向大家介绍YOLO系列的绘图功能。我们在进行实验时，经常需要比较多个结果，针对这一问题，我写了点代码来解决这个问题，它可以根据训练结果绘制损失(loss)和mAP（平均精度均值）的对比图。这个工具不仅支持多个文件的对比分析，还允许大家在现有代码的基础上进行修，从而达到数据可视化的功能，大家也可以将对比图来放在论文中进行对比也是非常不错的选择。</p><p><strong>先展示一下效果图-&gt;</strong> </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/059f9bb891c3424aaf012d14e370287b.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/059f9bb891c3424aaf012d14e370287b.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>  </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/059f9bb891c3424aaf012d14e370287b.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/059f9bb891c3424aaf012d14e370287b.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp">​</p><p><strong>损失对比图象-&gt;</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0b93636a9f29432fadb3f0aeacd3406c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0b93636a9f29432fadb3f0aeacd3406c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp">​</p><hr><h2 id="二、绘图工具核心代码"><a href="#二、绘图工具核心代码" class="headerlink" title="二、绘图工具核心代码 "></a>二、绘图工具核心代码 </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_metrics_and_loss</span>(<span class="params">experiment_names, metrics_info, loss_info, metrics_subplot_layout, loss_subplot_layout,</span></span><br><span class="line"><span class="params">                          metrics_figure_size=(<span class="params"><span class="number">15</span>, <span class="number">10</span></span>), loss_figure_size=(<span class="params"><span class="number">15</span>, <span class="number">10</span></span>), base_directory=<span class="string">&#x27;runs/train&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># Plot metrics</span></span><br><span class="line">    plt.figure(figsize=metrics_figure_size)</span><br><span class="line">    <span class="keyword">for</span> i, (metric_name, title) <span class="keyword">in</span> <span class="built_in">enumerate</span>(metrics_info):</span><br><span class="line">        plt.subplot(*metrics_subplot_layout, i + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> experiment_names:</span><br><span class="line">            file_path = os.path.join(base_directory, name, <span class="string">&#x27;results.csv&#x27;</span>)</span><br><span class="line">            data = pd.read_csv(file_path)</span><br><span class="line">            column_name = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col.strip() == metric_name][<span class="number">0</span>]</span><br><span class="line">            plt.plot(data[column_name], label=name)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">        plt.title(title)</span><br><span class="line">        plt.legend()</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    metrics_filename = <span class="string">&#x27;metrics_curves.png&#x27;</span></span><br><span class="line">    plt.savefig(metrics_filename)</span><br><span class="line">    plt.show()</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Plot loss</span></span><br><span class="line">    plt.figure(figsize=loss_figure_size)</span><br><span class="line">    <span class="keyword">for</span> i, (loss_name, title) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loss_info):</span><br><span class="line">        plt.subplot(*loss_subplot_layout, i + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> experiment_names:</span><br><span class="line">            file_path = os.path.join(base_directory, name, <span class="string">&#x27;results.csv&#x27;</span>)</span><br><span class="line">            data = pd.read_csv(file_path)</span><br><span class="line">            column_name = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col.strip() == loss_name][<span class="number">0</span>]</span><br><span class="line">            plt.plot(data[column_name], label=name)</span><br><span class="line">        plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">        plt.title(title)</span><br><span class="line">        plt.legend()</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    loss_filename = <span class="string">&#x27;loss_curves.png&#x27;</span></span><br><span class="line">    plt.savefig(loss_filename)</span><br><span class="line">    plt.show()</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> metrics_filename, loss_filename</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># Metrics to plot</span></span><br><span class="line">metrics_info = [</span><br><span class="line">    (<span class="string">&#x27;metrics/precision(B)&#x27;</span>, <span class="string">&#x27;Precision&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;metrics/recall(B)&#x27;</span>, <span class="string">&#x27;Recall&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;metrics/mAP50(B)&#x27;</span>, <span class="string">&#x27;mAP at IoU=0.5&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;metrics/mAP50-95(B)&#x27;</span>, <span class="string">&#x27;mAP for IoU Range 0.5-0.95&#x27;</span>)</span><br><span class="line">]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Loss to plot</span></span><br><span class="line">loss_info = [</span><br><span class="line">    (<span class="string">&#x27;train/box_loss&#x27;</span>, <span class="string">&#x27;Training Box Loss&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;train/cls_loss&#x27;</span>, <span class="string">&#x27;Training Classification Loss&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;train/dfl_loss&#x27;</span>, <span class="string">&#x27;Training DFL Loss&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;val/box_loss&#x27;</span>, <span class="string">&#x27;Validation Box Loss&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;val/cls_loss&#x27;</span>, <span class="string">&#x27;Validation Classification Loss&#x27;</span>),</span><br><span class="line">    (<span class="string">&#x27;val/dfl_loss&#x27;</span>, <span class="string">&#x27;Validation DFL Loss&#x27;</span>)</span><br><span class="line">]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Plot the metrics and loss from multiple experiments</span></span><br><span class="line">metrics_filename, loss_filename = plot_metrics_and_loss(</span><br><span class="line">    experiment_names=[<span class="string">&#x27;exp294&#x27;</span>, <span class="string">&#x27;exp297&#x27;</span>, <span class="string">&#x27;exp293&#x27;</span>, <span class="string">&#x27;exp291&#x27;</span>, <span class="string">&#x27;exp287&#x27;</span>],</span><br><span class="line">    metrics_info=metrics_info,</span><br><span class="line">    loss_info=loss_info,</span><br><span class="line">    metrics_subplot_layout=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">    loss_subplot_layout=(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><hr><h2 id="三、使用讲解"><a href="#三、使用讲解" class="headerlink" title="三、使用讲解 "></a>三、使用讲解 </h2><p>使用方式非常简单，我们首先创建一个文件，将核心代码粘贴进去，其中experiment_names这个参数就代表我们的每个训练结果的名字， 我们只需要修改这个即可，我这里就是五个结果进行对比，修改完成之后大家运行该文件即可。<img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e7d9ce0ce8004e178f1386272eb6c319.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e7d9ce0ce8004e178f1386272eb6c319.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp">​</p><h2 id="五、热力图代码"><a href="#五、热力图代码" class="headerlink" title="五、热力图代码 "></a>五、热力图代码 </h2><p>使用方式我会单独更一篇，这个热力图代码的进阶版，这里只是先放一下。 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">warnings.simplefilter(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> torch, yaml, cv2, os, shutil</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> trange</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> ultralytics.nn.tasks <span class="keyword">import</span> DetectionModel <span class="keyword">as</span> Model</span><br><span class="line"><span class="keyword">from</span> ultralytics.utils.torch_utils <span class="keyword">import</span> intersect_dicts</span><br><span class="line"><span class="keyword">from</span> ultralytics.utils.ops <span class="keyword">import</span> xywh2xyxy</span><br><span class="line"><span class="keyword">from</span> pytorch_grad_cam <span class="keyword">import</span> GradCAMPlusPlus, GradCAM, XGradCAM</span><br><span class="line"><span class="keyword">from</span> pytorch_grad_cam.utils.image <span class="keyword">import</span> show_cam_on_image</span><br><span class="line"><span class="keyword">from</span> pytorch_grad_cam.activations_and_gradients <span class="keyword">import</span> ActivationsAndGradients</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">letterbox</span>(<span class="params">im, new_shape=(<span class="params"><span class="number">640</span>, <span class="number">640</span></span>), color=(<span class="params"><span class="number">114</span>, <span class="number">114</span>, <span class="number">114</span></span>), auto=<span class="literal">True</span>, scaleFill=<span class="literal">False</span>, scaleup=<span class="literal">True</span>, stride=<span class="number">32</span></span>):</span><br><span class="line">    <span class="comment"># Resize and pad image while meeting stride-multiple constraints</span></span><br><span class="line">    shape = im.shape[:<span class="number">2</span>]  <span class="comment"># current shape [height, width]</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(new_shape, <span class="built_in">int</span>):</span><br><span class="line">        new_shape = (new_shape, new_shape)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Scale ratio (new / old)</span></span><br><span class="line">    r = <span class="built_in">min</span>(new_shape[<span class="number">0</span>] / shape[<span class="number">0</span>], new_shape[<span class="number">1</span>] / shape[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> scaleup:  <span class="comment"># only scale down, do not scale up (for better val mAP)</span></span><br><span class="line">        r = <span class="built_in">min</span>(r, <span class="number">1.0</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Compute padding</span></span><br><span class="line">    ratio = r, r  <span class="comment"># width, height ratios</span></span><br><span class="line">    new_unpad = <span class="built_in">int</span>(<span class="built_in">round</span>(shape[<span class="number">1</span>] * r)), <span class="built_in">int</span>(<span class="built_in">round</span>(shape[<span class="number">0</span>] * r))</span><br><span class="line">    dw, dh = new_shape[<span class="number">1</span>] - new_unpad[<span class="number">0</span>], new_shape[<span class="number">0</span>] - new_unpad[<span class="number">1</span>]  <span class="comment"># wh padding</span></span><br><span class="line">    <span class="keyword">if</span> auto:  <span class="comment"># minimum rectangle</span></span><br><span class="line">        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  <span class="comment"># wh padding</span></span><br><span class="line">    <span class="keyword">elif</span> scaleFill:  <span class="comment"># stretch</span></span><br><span class="line">        dw, dh = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">        new_unpad = (new_shape[<span class="number">1</span>], new_shape[<span class="number">0</span>])</span><br><span class="line">        ratio = new_shape[<span class="number">1</span>] / shape[<span class="number">1</span>], new_shape[<span class="number">0</span>] / shape[<span class="number">0</span>]  <span class="comment"># width, height ratios</span></span><br><span class="line"> </span><br><span class="line">    dw /= <span class="number">2</span>  <span class="comment"># divide padding into 2 sides</span></span><br><span class="line">    dh /= <span class="number">2</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> shape[::-<span class="number">1</span>] != new_unpad:  <span class="comment"># resize</span></span><br><span class="line">        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)</span><br><span class="line">    top, bottom = <span class="built_in">int</span>(<span class="built_in">round</span>(dh - <span class="number">0.1</span>)), <span class="built_in">int</span>(<span class="built_in">round</span>(dh + <span class="number">0.1</span>))</span><br><span class="line">    left, right = <span class="built_in">int</span>(<span class="built_in">round</span>(dw - <span class="number">0.1</span>)), <span class="built_in">int</span>(<span class="built_in">round</span>(dw + <span class="number">0.1</span>))</span><br><span class="line">    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  <span class="comment"># add border</span></span><br><span class="line">    <span class="keyword">return</span> im, ratio, (dw, dh)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">yolov8_heatmap</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, weight, cfg, device, method, layer, backward_type, conf_threshold, ratio</span>):</span><br><span class="line">        device = torch.device(device)</span><br><span class="line">        ckpt = torch.load(weight)</span><br><span class="line">        model_names = ckpt[<span class="string">&#x27;model&#x27;</span>].names</span><br><span class="line">        csd = ckpt[<span class="string">&#x27;model&#x27;</span>].<span class="built_in">float</span>().state_dict()  <span class="comment"># checkpoint state_dict as FP32</span></span><br><span class="line">        model = Model(cfg, ch=<span class="number">3</span>, nc=<span class="built_in">len</span>(model_names)).to(device)</span><br><span class="line">        csd = intersect_dicts(csd, model.state_dict(), exclude=[<span class="string">&#x27;anchor&#x27;</span>])  <span class="comment"># intersect</span></span><br><span class="line">        model.load_state_dict(csd, strict=<span class="literal">False</span>)  <span class="comment"># load</span></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Transferred <span class="subst">&#123;<span class="built_in">len</span>(csd)&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(model.state_dict())&#125;</span> items&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        target_layers = [<span class="built_in">eval</span>(layer)]</span><br><span class="line">        method = <span class="built_in">eval</span>(method)</span><br><span class="line"> </span><br><span class="line">        colors = np.random.uniform(<span class="number">0</span>, <span class="number">255</span>, size=(<span class="built_in">len</span>(model_names), <span class="number">3</span>)).astype(np.<span class="built_in">int</span>)</span><br><span class="line">        <span class="variable language_">self</span>.__dict__.update(<span class="built_in">locals</span>())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">post_process</span>(<span class="params">self, result</span>):</span><br><span class="line">        logits_ = result[:, <span class="number">4</span>:]</span><br><span class="line">        boxes_ = result[:, :<span class="number">4</span>]</span><br><span class="line">        <span class="built_in">sorted</span>, indices = torch.sort(logits_.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>], descending=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.transpose(logits_[<span class="number">0</span>], dim0=<span class="number">0</span>, dim1=<span class="number">1</span>)[indices[<span class="number">0</span>]], torch.transpose(boxes_[<span class="number">0</span>], dim0=<span class="number">0</span>, dim1=<span class="number">1</span>)[indices[<span class="number">0</span>]], xywh2xyxy(torch.transpose(boxes_[<span class="number">0</span>], dim0=<span class="number">0</span>, dim1=<span class="number">1</span>)[indices[<span class="number">0</span>]]).cpu().detach().numpy()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw_detections</span>(<span class="params">self, box, color, name, img</span>):</span><br><span class="line">        xmin, ymin, xmax, ymax = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">list</span>(box)))</span><br><span class="line">        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), <span class="built_in">tuple</span>(<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> color), <span class="number">2</span>)</span><br><span class="line">        cv2.putText(img, <span class="built_in">str</span>(name), (xmin, ymin - <span class="number">5</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.8</span>, <span class="built_in">tuple</span>(<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> color), <span class="number">2</span>, lineType=cv2.LINE_AA)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, img_path, save_path</span>):</span><br><span class="line">        <span class="comment"># remove dir if exist</span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(save_path):</span><br><span class="line">            shutil.rmtree(save_path)</span><br><span class="line">        <span class="comment"># make dir if not exist</span></span><br><span class="line">        os.makedirs(save_path, exist_ok=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># img process</span></span><br><span class="line">        img = cv2.imread(img_path)</span><br><span class="line">        img = letterbox(img)[<span class="number">0</span>]</span><br><span class="line">        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">        img = np.float32(img) / <span class="number">255.0</span></span><br><span class="line">        tensor = torch.from_numpy(np.transpose(img, axes=[<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])).unsqueeze(<span class="number">0</span>).to(<span class="variable language_">self</span>.device)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># init ActivationsAndGradients</span></span><br><span class="line">        grads = ActivationsAndGradients(<span class="variable language_">self</span>.model, <span class="variable language_">self</span>.target_layers, reshape_transform=<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># get ActivationsAndResult</span></span><br><span class="line">        result = grads(tensor)</span><br><span class="line">        activations = grads.activations[<span class="number">0</span>].cpu().detach().numpy()</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># postprocess to yolo output</span></span><br><span class="line">        post_result, pre_post_boxes, post_boxes = <span class="variable language_">self</span>.post_process(result[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> trange(<span class="built_in">int</span>(post_result.size(<span class="number">0</span>) * <span class="variable language_">self</span>.ratio)):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">float</span>(post_result[i].<span class="built_in">max</span>()) &lt; <span class="variable language_">self</span>.conf_threshold:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"> </span><br><span class="line">            <span class="variable language_">self</span>.model.zero_grad()</span><br><span class="line">            <span class="comment"># get max probability for this prediction</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;class&#x27;</span> <span class="keyword">or</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;all&#x27;</span>:</span><br><span class="line">                score = post_result[i].<span class="built_in">max</span>()</span><br><span class="line">                score.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;box&#x27;</span> <span class="keyword">or</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;all&#x27;</span>:</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                    score = pre_post_boxes[i, j]</span><br><span class="line">                    score.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">            <span class="comment"># process heatmap</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;class&#x27;</span>:</span><br><span class="line">                gradients = grads.gradients[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;box&#x27;</span>:</span><br><span class="line">                gradients = grads.gradients[<span class="number">0</span>] + grads.gradients[<span class="number">1</span>] + grads.gradients[<span class="number">2</span>] + grads.gradients[<span class="number">3</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gradients = grads.gradients[<span class="number">0</span>] + grads.gradients[<span class="number">1</span>] + grads.gradients[<span class="number">2</span>] + grads.gradients[<span class="number">3</span>] + grads.gradients[<span class="number">4</span>]</span><br><span class="line">            b, k, u, v = gradients.size()</span><br><span class="line">            weights = <span class="variable language_">self</span>.method.get_cam_weights(<span class="variable language_">self</span>.method, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, activations, gradients.detach().numpy())</span><br><span class="line">            weights = weights.reshape((b, k, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">            saliency_map = np.<span class="built_in">sum</span>(weights * activations, axis=<span class="number">1</span>)</span><br><span class="line">            saliency_map = np.squeeze(np.maximum(saliency_map, <span class="number">0</span>))</span><br><span class="line">            saliency_map = cv2.resize(saliency_map, (tensor.size(<span class="number">3</span>), tensor.size(<span class="number">2</span>)))</span><br><span class="line">            saliency_map_min, saliency_map_max = saliency_map.<span class="built_in">min</span>(), saliency_map.<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">if</span> (saliency_map_max - saliency_map_min) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            saliency_map = (saliency_map - saliency_map_min) / (saliency_map_max - saliency_map_min)</span><br><span class="line"> </span><br><span class="line">            <span class="comment"># add heatmap and box to image</span></span><br><span class="line">            cam_image = show_cam_on_image(img.copy(), saliency_map, use_rgb=<span class="literal">True</span>)</span><br><span class="line">            cam_image = <span class="variable language_">self</span>.draw_detections(post_boxes[i], <span class="variable language_">self</span>.colors[<span class="built_in">int</span>(post_result[i, :].argmax())], <span class="string">f&#x27;<span class="subst">&#123;self.model_names[<span class="built_in">int</span>(post_result[i, :].argmax())]&#125;</span> <span class="subst">&#123;<span class="built_in">float</span>(post_result[i].<span class="built_in">max</span>()):<span class="number">.2</span>f&#125;</span>&#x27;</span>, cam_image)</span><br><span class="line">            cam_image = Image.fromarray(cam_image)</span><br><span class="line">            cam_image.save(<span class="string">f&#x27;<span class="subst">&#123;save_path&#125;</span>/<span class="subst">&#123;i&#125;</span>.png&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_params</span>():</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;weight&#x27;</span>: <span class="string">&#x27;yolov8n.pt&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;cfg&#x27;</span>: <span class="string">&#x27;ultralytics/cfg/models/v8/yolov8n.yaml&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;method&#x27;</span>: <span class="string">&#x27;GradCAM&#x27;</span>, <span class="comment"># GradCAMPlusPlus, GradCAM, XGradCAM</span></span><br><span class="line">        <span class="string">&#x27;layer&#x27;</span>: <span class="string">&#x27;model.model[9]&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;backward_type&#x27;</span>: <span class="string">&#x27;all&#x27;</span>, <span class="comment"># class, box, all</span></span><br><span class="line">        <span class="string">&#x27;conf_threshold&#x27;</span>: <span class="number">0.6</span>, <span class="comment"># 0.6</span></span><br><span class="line">        <span class="string">&#x27;ratio&#x27;</span>: <span class="number">0.02</span> <span class="comment"># 0.02-0.1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> params</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = yolov8_heatmap(**get_params())</span><br><span class="line">    model(<span class="string">r&#x27;ultralytics/assets/bus.jpg&#x27;</span>, <span class="string">&#x27;result&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 写作 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> 论文 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>报错</title>
      <link href="/2024/08/01/article-14/"/>
      <url>/2024/08/01/article-14/</url>
      
        <content type="html"><![CDATA[<h2 id="一、本文介绍"><a href="#一、本文介绍" class="headerlink" title="一、本文介绍"></a>一、本文介绍</h2><p>本文为专栏内读者和我个人在训练<strong>YOLOv8时遇到的各种错误解决方案</strong>，你遇到的问题本文基本上都能够解决。</p><h2 id="二、-报错问题"><a href="#二、-报错问题" class="headerlink" title="二、 报错问题 "></a>二、 报错问题 </h2><p># 以下为两个重要库的版本，大家可以对应下载，使用教程我会更新，时间还没来得及大家可以先看视频使用。</p><blockquote><p><strong>项目环境：</strong></p><p>python &#x3D;&#x3D; 3.9.7</p><p>pytorch &#x3D;&#x3D; 1.12.1</p><p>timm &#x3D;&#x3D; 0.9.12</p><p>mmcv-full &#x3D;&#x3D; 1.6.2</p></blockquote><hr><h3 id="1-训练过程中loss出现Nan值"><a href="#1-训练过程中loss出现Nan值" class="headerlink" title="(1)训练过程中loss出现Nan值."></a>(1)训练过程中loss出现Nan值.</h3><p>可以尝试关闭AMP混合精度训练，如何关闭amp呢找到如下文件’ultralytics&#x2F;cfg&#x2F;default.yaml’，其中有一个参数是</p><p>amp: False  # (bool) Automatic Mixed Precision (AMP) training, choices&#x3D;[True, False], True runs AMP check</p><p>我们将其设置为False即可，默认时为True。</p><p>.</p><h3 id="2-多卡训练问题-修改模型以后不能支持多卡训练可以尝试下面的两行命令行操作，两个是不同的操作，是代表不同的版本现尝试第一个不行用第二个"><a href="#2-多卡训练问题-修改模型以后不能支持多卡训练可以尝试下面的两行命令行操作，两个是不同的操作，是代表不同的版本现尝试第一个不行用第二个" class="headerlink" title="(2)多卡训练问题,修改模型以后不能支持多卡训练可以尝试下面的两行命令行操作，两个是不同的操作，是代表不同的版本现尝试第一个不行用第二个"></a>(2)多卡训练问题,修改模型以后不能支持多卡训练可以尝试下面的两行命令行操作，两个是不同的操作，是代表不同的版本现尝试第一个不行用第二个</h3><p>    python -m torch.distributed.run –nproc_per_node 2 train.py</p><p>    python -m torch.distributed.launch –nproc_per_node 2 train.py</p><hr><h3 id="3-针对运行过程中的一些报错解决"><a href="#3-针对运行过程中的一些报错解决" class="headerlink" title="(3) 针对运行过程中的一些报错解决"></a>(3) 针对运行过程中的一些报错解决</h3><p>    <strong>1.如果训练的过程中验证报错了(主要是一些形状不匹配的错误这是因为验证集的一些特殊图片导致)</strong></p><p>就是有这种训练第一个epochs完成后开始验证的时候报错，下面的方法基本百分之九十都能够解决。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e61c95278a244aebbe4ac67f07f90466.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/e61c95278a244aebbe4ac67f07f90466.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><p>    找到ultralytics&#x2F;models&#x2F;yolo&#x2F;detect&#x2F;train.py的DetectionTrainer class中的build_dataset函数中的rect&#x3D;mode &#x3D;&#x3D; ‘val’改为rect&#x3D;False</p><p>    <strong>2.推理的时候运行detect.py文件报了形状不匹配的错误</strong></p><p>    找到ultralytics&#x2F;engine&#x2F;predictor.py找到函数def pre_transform(self, im),在LetterBox中的auto改为False</p><p>    <strong>3.训练的过程中报错类型不匹配的问题</strong></p><p>    找到’ultralytics&#x2F;engine&#x2F;validator.py’文件找到 ‘class BaseValidator:’ 然后在其’__call__‘中</p><p>    self.args.half &#x3D; self.device.type !&#x3D; ‘cpu’  # force FP16 val during training的一行代码下面加上self.args.half &#x3D; False</p><hr><h3 id="4-针对yaml文件中的nc修改"><a href="#4-针对yaml文件中的nc修改" class="headerlink" title="(4) 针对yaml文件中的nc修改"></a>(4) 针对yaml文件中的nc修改</h3><p>    不用修改，模型会自动根据你数据集的配置文件获取。</p><p>    这也是模型打印两次的区别，第一次打印出来的就是你选择模型的yaml文件结构，第二次打印的就是替换了你数据集的yaml文件，模型使用的是第二种。</p><hr><h3 id="5-针对环境的问题"><a href="#5-针对环境的问题" class="headerlink" title="(5) 针对环境的问题"></a>(5) 针对环境的问题</h3><p>    环境的问题我实在解决不过来，所以大家可以自行在网上搜索解决方案。  </p><hr><h3 id="6-训练过程中不打印GFLOpS"><a href="#6-训练过程中不打印GFLOpS" class="headerlink" title="(6) 训练过程中不打印GFLOpS"></a>(6) 训练过程中不打印GFLOpS</h3><p>计算的GFLOPs计算异常不打印，所以需要额外修改一处， 我们找到如下文件’ultralytics&#x2F;utils&#x2F;torch_utils.py’文件内有如下的代码按照如下的图片进行修改，大家看好函数就行，其中红框的640可能和你的不一样， 然后用我给的代码替换掉整个代码即可。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/24068f6039b94ceeb91e98642c00e594.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/24068f6039b94ceeb91e98642c00e594.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_flops</span>(<span class="params">model, imgsz=<span class="number">640</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return a YOLO model&#x27;s FLOPs.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        model = de_parallel(model)</span><br><span class="line">        p = <span class="built_in">next</span>(model.parameters())</span><br><span class="line">        <span class="comment"># stride = max(int(model.stride.max()), 32) if hasattr(model, &#x27;stride&#x27;) else 32  # max stride</span></span><br><span class="line">        stride = <span class="number">640</span></span><br><span class="line">        im = torch.empty((<span class="number">1</span>, <span class="number">3</span>, stride, stride), device=p.device)  <span class="comment"># input image in BCHW format</span></span><br><span class="line">        flops = thop.profile(deepcopy(model), inputs=[im], verbose=<span class="literal">False</span>)[<span class="number">0</span>] / <span class="number">1E9</span> * <span class="number">2</span> <span class="keyword">if</span> thop <span class="keyword">else</span> <span class="number">0</span>  <span class="comment"># stride GFLOPs</span></span><br><span class="line">        imgsz = imgsz <span class="keyword">if</span> <span class="built_in">isinstance</span>(imgsz, <span class="built_in">list</span>) <span class="keyword">else</span> [imgsz, imgsz]  <span class="comment"># expand if int/float</span></span><br><span class="line">        <span class="keyword">return</span> flops * imgsz[<span class="number">0</span>] / stride * imgsz[<span class="number">1</span>] / stride  <span class="comment"># 640x640 GFLOPs</span></span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><hr><h3 id="7-mmcv安装的解决方法"><a href="#7-mmcv安装的解决方法" class="headerlink" title="(7) mmcv安装的解决方法"></a>(7) mmcv安装的解决方法</h3><p>有的读者mmcv-full会安装失败是因为自身系统的编译工具有问题，也有可能是环境之间安装的有冲突 推荐大家离线安装的形式,下面的地址中大家可以找找自己的版本,下载到本地进行安装。 <a href="https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html">https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html</a> <a href="https://download.openmmlab.com/mmcv/dist/index.html">https://download.openmmlab.com/mmcv/dist/index.html</a> </p>]]></content>
      
      
      <categories>
          
          <category> YOLO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 论文 </tag>
            
            <tag> Ultralytics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可视化热力图</title>
      <link href="/2024/07/28/article-10/"/>
      <url>/2024/07/28/article-10/</url>
      
        <content type="html"><![CDATA[<h2 id="一、本文介绍"><a href="#一、本文介绍" class="headerlink" title="一、本文介绍"></a>一、本文介绍</h2><p>本文给大家带来的机制是的<strong>可视化热力图功能</strong>，热力图)作为我们论文当中的必备一环，可以展示出我们呈现机制的有效性，本文的内容支持YOLOv8最新版本，同时支持视频讲解，本文的内容是根据检测头的输出内容，然后来绘图，<strong>产生6300张预测图片，从中选取出有效的热力图来绘图。</strong></p><p>在开始之前给大家推荐一下我的专栏，本专栏每周更新3-10篇最新前沿机制 | 包括二次创新全网无重复，以及融合改进(大家拿到之后添加另外一个改进机制在你的数据集上实现涨点即可撰写论文)，还有各种前沿顶会改进机制 |，更有包含我所有附赠的文件（文件内集成我所有的改进机制全部注册完毕可以直接运行）和交流群和视频讲解提供给大家。  </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0a203fd9e3cd4f89b95e419e4fc22f1f.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0a203fd9e3cd4f89b95e419e4fc22f1f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><hr><h2 id="二、项目完整代码"><a href="#二、项目完整代码" class="headerlink" title="二、项目完整代码 "></a>二、项目完整代码 </h2><p><strong>我们将这个代码，复制粘贴到我们YOLOv8的仓库里然后创建一个py文件存放进去即可。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">warnings.simplefilter(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> torch, yaml, cv2, os, shutil</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> trange</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> ultralytics.nn.tasks <span class="keyword">import</span> DetectionModel <span class="keyword">as</span> Model</span><br><span class="line"><span class="keyword">from</span> ultralytics.utils.torch_utils <span class="keyword">import</span> intersect_dicts</span><br><span class="line"><span class="keyword">from</span> ultralytics.utils.ops <span class="keyword">import</span> xywh2xyxy</span><br><span class="line"><span class="keyword">from</span> pytorch_grad_cam <span class="keyword">import</span> GradCAMPlusPlus, GradCAM, XGradCAM</span><br><span class="line"><span class="keyword">from</span> pytorch_grad_cam.utils.image <span class="keyword">import</span> show_cam_on_image</span><br><span class="line"><span class="keyword">from</span> pytorch_grad_cam.activations_and_gradients <span class="keyword">import</span> ActivationsAndGradients</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">letterbox</span>(<span class="params">im, new_shape=(<span class="params"><span class="number">640</span>, <span class="number">640</span></span>), color=(<span class="params"><span class="number">114</span>, <span class="number">114</span>, <span class="number">114</span></span>), auto=<span class="literal">True</span>, scaleFill=<span class="literal">False</span>, scaleup=<span class="literal">True</span>, stride=<span class="number">32</span></span>):</span><br><span class="line">    <span class="comment"># Resize and pad image while meeting stride-multiple constraints</span></span><br><span class="line">    shape = im.shape[:<span class="number">2</span>]  <span class="comment"># current shape [height, width]</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(new_shape, <span class="built_in">int</span>):</span><br><span class="line">        new_shape = (new_shape, new_shape)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Scale ratio (new / old)</span></span><br><span class="line">    r = <span class="built_in">min</span>(new_shape[<span class="number">0</span>] / shape[<span class="number">0</span>], new_shape[<span class="number">1</span>] / shape[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> scaleup:  <span class="comment"># only scale down, do not scale up (for better val mAP)</span></span><br><span class="line">        r = <span class="built_in">min</span>(r, <span class="number">1.0</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Compute padding</span></span><br><span class="line">    ratio = r, r  <span class="comment"># width, height ratios</span></span><br><span class="line">    new_unpad = <span class="built_in">int</span>(<span class="built_in">round</span>(shape[<span class="number">1</span>] * r)), <span class="built_in">int</span>(<span class="built_in">round</span>(shape[<span class="number">0</span>] * r))</span><br><span class="line">    dw, dh = new_shape[<span class="number">1</span>] - new_unpad[<span class="number">0</span>], new_shape[<span class="number">0</span>] - new_unpad[<span class="number">1</span>]  <span class="comment"># wh padding</span></span><br><span class="line">    <span class="keyword">if</span> auto:  <span class="comment"># minimum rectangle</span></span><br><span class="line">        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  <span class="comment"># wh padding</span></span><br><span class="line">    <span class="keyword">elif</span> scaleFill:  <span class="comment"># stretch</span></span><br><span class="line">        dw, dh = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">        new_unpad = (new_shape[<span class="number">1</span>], new_shape[<span class="number">0</span>])</span><br><span class="line">        ratio = new_shape[<span class="number">1</span>] / shape[<span class="number">1</span>], new_shape[<span class="number">0</span>] / shape[<span class="number">0</span>]  <span class="comment"># width, height ratios</span></span><br><span class="line"> </span><br><span class="line">    dw /= <span class="number">2</span>  <span class="comment"># divide padding into 2 sides</span></span><br><span class="line">    dh /= <span class="number">2</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> shape[::-<span class="number">1</span>] != new_unpad:  <span class="comment"># resize</span></span><br><span class="line">        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)</span><br><span class="line">    top, bottom = <span class="built_in">int</span>(<span class="built_in">round</span>(dh - <span class="number">0.1</span>)), <span class="built_in">int</span>(<span class="built_in">round</span>(dh + <span class="number">0.1</span>))</span><br><span class="line">    left, right = <span class="built_in">int</span>(<span class="built_in">round</span>(dw - <span class="number">0.1</span>)), <span class="built_in">int</span>(<span class="built_in">round</span>(dw + <span class="number">0.1</span>))</span><br><span class="line">    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  <span class="comment"># add border</span></span><br><span class="line">    <span class="keyword">return</span> im, ratio, (dw, dh)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">yolov8_heatmap</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, weight, cfg, device, method, layer, backward_type, conf_threshold, ratio</span>):</span><br><span class="line">        device = torch.device(device)</span><br><span class="line">        ckpt = torch.load(weight)</span><br><span class="line">        model_names = ckpt[<span class="string">&#x27;model&#x27;</span>].names</span><br><span class="line">        csd = ckpt[<span class="string">&#x27;model&#x27;</span>].<span class="built_in">float</span>().state_dict()  <span class="comment"># checkpoint state_dict as FP32</span></span><br><span class="line">        model = Model(cfg, ch=<span class="number">3</span>, nc=<span class="built_in">len</span>(model_names)).to(device)</span><br><span class="line">        csd = intersect_dicts(csd, model.state_dict(), exclude=[<span class="string">&#x27;anchor&#x27;</span>])  <span class="comment"># intersect</span></span><br><span class="line">        model.load_state_dict(csd, strict=<span class="literal">False</span>)  <span class="comment"># load</span></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Transferred <span class="subst">&#123;<span class="built_in">len</span>(csd)&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(model.state_dict())&#125;</span> items&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        target_layers = [<span class="built_in">eval</span>(layer)]</span><br><span class="line">        method = <span class="built_in">eval</span>(method)</span><br><span class="line"> </span><br><span class="line">        colors = np.random.uniform(<span class="number">0</span>, <span class="number">255</span>, size=(<span class="built_in">len</span>(model_names), <span class="number">3</span>)).astype(np.int32)</span><br><span class="line">        <span class="variable language_">self</span>.__dict__.update(<span class="built_in">locals</span>())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">post_process</span>(<span class="params">self, result</span>):</span><br><span class="line">        logits_ = result[:, <span class="number">4</span>:]</span><br><span class="line">        boxes_ = result[:, :<span class="number">4</span>]</span><br><span class="line">        <span class="built_in">sorted</span>, indices = torch.sort(logits_.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>], descending=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.transpose(logits_[<span class="number">0</span>], dim0=<span class="number">0</span>, dim1=<span class="number">1</span>)[indices[<span class="number">0</span>]], torch.transpose(boxes_[<span class="number">0</span>], dim0=<span class="number">0</span>, dim1=<span class="number">1</span>)[indices[<span class="number">0</span>]], xywh2xyxy(torch.transpose(boxes_[<span class="number">0</span>], dim0=<span class="number">0</span>, dim1=<span class="number">1</span>)[indices[<span class="number">0</span>]]).cpu().detach().numpy()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">draw_detections</span>(<span class="params">self, box, color, name, img</span>):</span><br><span class="line">        xmin, ymin, xmax, ymax = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">list</span>(box)))</span><br><span class="line">        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), <span class="built_in">tuple</span>(<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> color), <span class="number">2</span>)</span><br><span class="line">        cv2.putText(img, <span class="built_in">str</span>(name), (xmin, ymin - <span class="number">5</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.8</span>, <span class="built_in">tuple</span>(<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> color), <span class="number">2</span>, lineType=cv2.LINE_AA)</span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, img_path, save_path</span>):</span><br><span class="line">        <span class="comment"># remove dir if exist</span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(save_path):</span><br><span class="line">            shutil.rmtree(save_path)</span><br><span class="line">        <span class="comment"># make dir if not exist</span></span><br><span class="line">        os.makedirs(save_path, exist_ok=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># img process</span></span><br><span class="line">        img = cv2.imread(img_path)</span><br><span class="line">        img = letterbox(img)[<span class="number">0</span>]</span><br><span class="line">        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">        img = np.float32(img) / <span class="number">255.0</span></span><br><span class="line">        tensor = torch.from_numpy(np.transpose(img, axes=[<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])).unsqueeze(<span class="number">0</span>).to(<span class="variable language_">self</span>.device)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># init ActivationsAndGradients</span></span><br><span class="line">        grads = ActivationsAndGradients(<span class="variable language_">self</span>.model, <span class="variable language_">self</span>.target_layers, reshape_transform=<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># get ActivationsAndResult</span></span><br><span class="line">        result = grads(tensor)</span><br><span class="line">        activations = grads.activations[<span class="number">0</span>].cpu().detach().numpy()</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># postprocess to yolo output</span></span><br><span class="line">        post_result, pre_post_boxes, post_boxes = <span class="variable language_">self</span>.post_process(result[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> trange(<span class="built_in">int</span>(post_result.size(<span class="number">0</span>) * <span class="variable language_">self</span>.ratio)):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">float</span>(post_result[i].<span class="built_in">max</span>()) &lt; <span class="variable language_">self</span>.conf_threshold:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"> </span><br><span class="line">            <span class="variable language_">self</span>.model.zero_grad()</span><br><span class="line">            <span class="comment"># get max probability for this prediction</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;class&#x27;</span> <span class="keyword">or</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;all&#x27;</span>:</span><br><span class="line">                score = post_result[i].<span class="built_in">max</span>()</span><br><span class="line">                score.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;box&#x27;</span> <span class="keyword">or</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;all&#x27;</span>:</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">                    score = pre_post_boxes[i, j]</span><br><span class="line">                    score.backward(retain_graph=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">            <span class="comment"># process heatmap</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;class&#x27;</span>:</span><br><span class="line">                gradients = grads.gradients[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> <span class="variable language_">self</span>.backward_type == <span class="string">&#x27;box&#x27;</span>:</span><br><span class="line">                gradients = grads.gradients[<span class="number">0</span>] + grads.gradients[<span class="number">1</span>] + grads.gradients[<span class="number">2</span>] + grads.gradients[<span class="number">3</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gradients = grads.gradients[<span class="number">0</span>] + grads.gradients[<span class="number">1</span>] + grads.gradients[<span class="number">2</span>] + grads.gradients[<span class="number">3</span>] + grads.gradients[<span class="number">4</span>]</span><br><span class="line">            b, k, u, v = gradients.size()</span><br><span class="line">            weights = <span class="variable language_">self</span>.method.get_cam_weights(<span class="variable language_">self</span>.method, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, activations, gradients.detach().numpy())</span><br><span class="line">            weights = weights.reshape((b, k, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">            saliency_map = np.<span class="built_in">sum</span>(weights * activations, axis=<span class="number">1</span>)</span><br><span class="line">            saliency_map = np.squeeze(np.maximum(saliency_map, <span class="number">0</span>))</span><br><span class="line">            saliency_map = cv2.resize(saliency_map, (tensor.size(<span class="number">3</span>), tensor.size(<span class="number">2</span>)))</span><br><span class="line">            saliency_map_min, saliency_map_max = saliency_map.<span class="built_in">min</span>(), saliency_map.<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">if</span> (saliency_map_max - saliency_map_min) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            saliency_map = (saliency_map - saliency_map_min) / (saliency_map_max - saliency_map_min)</span><br><span class="line"> </span><br><span class="line">            <span class="comment"># add heatmap and box to image</span></span><br><span class="line">            cam_image = show_cam_on_image(img.copy(), saliency_map, use_rgb=<span class="literal">True</span>)</span><br><span class="line">            <span class="string">&quot;不想在图片中绘画出边界框和置信度，注释下面的一行代码即可&quot;</span></span><br><span class="line">            cam_image = <span class="variable language_">self</span>.draw_detections(post_boxes[i], <span class="variable language_">self</span>.colors[<span class="built_in">int</span>(post_result[i, :].argmax())], <span class="string">f&#x27;<span class="subst">&#123;self.model_names[<span class="built_in">int</span>(post_result[i, :].argmax())]&#125;</span> <span class="subst">&#123;<span class="built_in">float</span>(post_result[i].<span class="built_in">max</span>()):<span class="number">.2</span>f&#125;</span>&#x27;</span>, cam_image)</span><br><span class="line">            cam_image = Image.fromarray(cam_image)</span><br><span class="line">            cam_image.save(<span class="string">f&#x27;<span class="subst">&#123;save_path&#125;</span>/<span class="subst">&#123;i&#125;</span>.png&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_params</span>():</span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;weight&#x27;</span>: <span class="string">&#x27;yolov8n.pt&#x27;</span>,   <span class="comment"># 训练出来的权重文件</span></span><br><span class="line">        <span class="string">&#x27;cfg&#x27;</span>: <span class="string">&#x27;ultralytics/cfg/models/v8/yolov8n.yaml&#x27;</span>,  <span class="comment"># 训练权重对应的yaml配置文件</span></span><br><span class="line">        <span class="string">&#x27;device&#x27;</span>: <span class="string">&#x27;cuda:0&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;method&#x27;</span>: <span class="string">&#x27;GradCAM&#x27;</span>, <span class="comment"># GradCAMPlusPlus, GradCAM, XGradCAM , 使用的热力图库文件不同的效果不一样可以多尝试</span></span><br><span class="line">        <span class="string">&#x27;layer&#x27;</span>: <span class="string">&#x27;model.model[9]&#x27;</span>,  <span class="comment"># 想要检测的对应层</span></span><br><span class="line">        <span class="string">&#x27;backward_type&#x27;</span>: <span class="string">&#x27;all&#x27;</span>, <span class="comment"># class, box, all</span></span><br><span class="line">        <span class="string">&#x27;conf_threshold&#x27;</span>: <span class="number">0.01</span>, <span class="comment"># 0.6  # 置信度阈值，有的时候你的进度条到一半就停止了就是因为没有高于此值的了</span></span><br><span class="line">        <span class="string">&#x27;ratio&#x27;</span>: <span class="number">0.02</span> <span class="comment"># 0.02-0.1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> params</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = yolov8_heatmap(**get_params())</span><br><span class="line">    model(<span class="string">r&#x27;ultralytics/assets/bus.jpg&#x27;</span>, <span class="string">&#x27;result&#x27;</span>)  <span class="comment"># 第一个是检测的文件, 第二个是保存的路径</span></span><br></pre></td></tr></table></figure><h2 id="三、参数解析"><a href="#三、参数解析" class="headerlink" title=" 三、参数解析 "></a> 三、参数解析 </h2><p><strong>下面上面项目核心代码的参数解析，共有7个，能够起到作用的参数并不多。</strong> </p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/6fcc9bb6ec814ab1961efb0c7db5f1a1.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/6fcc9bb6ec814ab1961efb0c7db5f1a1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><table><thead><tr><th></th><th>参数名</th><th>参数类型</th><th>参数讲解</th></tr></thead><tbody><tr><td>0</td><td>weights</td><td>str</td><td>用于检测视频的权重文件地址（可以是你训练好的，也可以是官方提供的）</td></tr><tr><td>1</td><td>cfg</td><td>str</td><td>你选择的权重对应的yaml配置文件，请注意一定要对应否则会报错和不显示图片</td></tr><tr><td>2</td><td>device</td><td>str</td><td>设备的选择可以用GPU也可以用CPU</td></tr><tr><td>3</td><td>method</td><td>str</td><td>使用的热力图第三方库的版本，不同的版本效果也不一样。</td></tr><tr><td>4</td><td>layer</td><td>str</td><td>想要检测的对应层，比如这里设置的是9那么检测的就是第九层</td></tr><tr><td>4</td><td>backward_type</td><td>str</td><td>检测的类别</td></tr><tr><td>5</td><td>conf_threshold</td><td>str</td><td>置信度阈值，有的时候你的进度条没有满就是因为没有大于这个阈值的图片了</td></tr><tr><td>6</td><td>ratio</td><td>int</td><td>YOLOv8一次产生6300张预测框，选择多少比例的图片绘画热力图。</td></tr></tbody></table><h2 id="四、项目的使用教程"><a href="#四、项目的使用教程" class="headerlink" title="四、项目的使用教程"></a>四、项目的使用教程</h2><h3 id="4-1-步骤一"><a href="#4-1-步骤一" class="headerlink" title="4.1 步骤一"></a>4.1 步骤一</h3><p>我们在Yolo仓库的目录下创建一个py文件将代码存放进去，如下图所示。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/6c4bed4cef9a488d8cda62492efa80c7.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/6c4bed4cef9a488d8cda62492efa80c7.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><hr><h3 id="4-2-步骤二"><a href="#4-2-步骤二" class="headerlink" title="4.2 步骤二"></a>4.2 步骤二</h3><p><strong>我们按照参数解析部分的介绍填好大家的参数，主要配置的有两个一个就是权重文件地址另一个就是图片的地址。</strong></p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2bd70b825206498bb8688b90cfa3e12c.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/2bd70b825206498bb8688b90cfa3e12c.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><hr><h3 id="4-3-步骤三"><a href="#4-3-步骤三" class="headerlink" title="4.3 步骤三"></a>4.3 步骤三</h3><p>我们挺好之后运行文件即可，图片就会保存在同级目录下的新的文件夹result内。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0a203fd9e3cd4f89b95e419e4fc22f1f.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/0a203fd9e3cd4f89b95e419e4fc22f1f.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><hr><h3 id="4-4-置信度和检测框"><a href="#4-4-置信度和检测框" class="headerlink" title="4.4 置信度和检测框"></a>4.4 置信度和检测框</h3><p>看下下面的说明就行。</p><p><img src="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/26206bf8e8cb4da4b2f230ac932cd577.png" class="lazyload placeholder" data-srcset="https://yangyang666.oss-cn-chengdu.aliyuncs.com/typoraImages/26206bf8e8cb4da4b2f230ac932cd577.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp"></p><hr>]]></content>
      
      
      <categories>
          
          <category> YOLO </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 热力图 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
